{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Exputils","text":"<p>Version: <code>0.3.8</code></p> <p>The Experiment Utilities (exputils) contain various tools for the management of scientific experiments and their experimental data.  It is especially designed to handle experimental repetitions, including to run different repetitions, to effectively store and load data for them, and to visualize their results.</p> <p>Main features:</p> <ul> <li>Easy definition of default configurations using nested python dictionaries.</li> <li>Setup of experimental configuration parameters with an ODS file for Libreoffice (open-source alternative to MS Excel).</li> <li>Running experiments and their repetitions in parallel.</li> <li>Logging of experimental data (numpy, json) with tensorboard support.</li> <li>Loading and filtering of experimental data.</li> <li>Interactive Jupyter widgets to load, select and plot data as line, box and bar plots.</li> </ul> <p>You can find the project with its source code here: github.com/ChrisReinke/exputils </p> <p>Content:</p> <p>This documentation provides the following information:</p> <ul> <li>Installation: How to install exputils.</li> <li>Tutorial: An introduction to the basic functionality of the exputils. Start here!</li> <li>Reference: The reference for the exputils functions and classes. Look here if you need specific information.</li> </ul>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#1-exputils-package","title":"1) Exputils Package","text":"<p>Two options are available, either via pip or directly from the source code. </p> <p>PIP (recommended)</p> <pre><code>pip install experiment-utilities\n</code></pre> <p>From Source</p> <p>Clone the repository via git and install via pip:</p> <pre><code>git clone https://github.com/ChrisReinke/exputils.git .\npip install ./exputils\n</code></pre> <p>(To install the library as a developer so that changes to the exputils source code are directly usable in other projects use <code>pip install -e ./exputils</code>)</p>"},{"location":"install/#2-jupiter-notebook","title":"2) Jupiter Notebook","text":"<p>For using the exputils GUIs for loading and plotting of data in Jupyter Notebook, the qgrid widget must be activated. (Note: The GUI is currently only working for Jupyter notebooks &lt;= 6.5.) Activate qgrid with:</p> <pre><code>jupyter contrib nbextension install --user\njupyter nbextension enable --py --sys-prefix widgetsnbextension\njupyter nbextension enable --py --sys-prefix qgrid\n</code></pre> <p>It is recommended to use the Jupyter Notebooks Extensions to allow folding of code and headlines. This makes the notebooks more readable. Activate the extensions with:</p> <pre><code>jupyter nbextension enable codefolding/main\njupyter nbextension enable collapsible_headings/main\n</code></pre>"},{"location":"tutorials/","title":"Tutorial","text":""},{"location":"tutorials/#introduction","title":"Introduction","text":"<p>This tutorial introduces the basic functionality of the exputils:</p> <ul> <li>configuring your experiments</li> <li>logging of data</li> <li>running and managing experiments</li> <li>analysis of experimental data</li> </ul> <p>The tutorial uses the pytorch_mnist demo to introduce these concepts. It explains how to use the demo and how it works. The demo itself is based on the PyTorch tutorial that introduces how to train a DNN on the example of classification. If you are new to PyTorch, please follow first the PyTorch tutorial to understand the training procedure. This tutorial will concentrate on the exputils functionality. </p>"},{"location":"tutorials/#setup","title":"Setup","text":"<p>Download the exputils source code from github and navigate to the pytorch_mnist demo.</p> <pre><code>git clone https://github.com/ChrisReinke/exputils.git .\ncd ./exputils/examples/pytorch_mnist\n</code></pre> <p>Create a conda environment (you can also use a venv) and activate it:</p> <pre><code>conda create -n exputils_demo python=3.11\nconda activate exputils_demo\n</code></pre> <p>Install the latest exputils library from PyPI:</p> <pre><code>pip install experiment-utilities\n</code></pre> <p>For using the exputils GUIs to load and plot data in Jupyter Notebook, the qgrid widget must be activated.</p> <pre><code>jupyter contrib nbextension install --user\njupyter nbextension enable --py --sys-prefix widgetsnbextension\njupyter nbextension enable --py --sys-prefix qgrid\n</code></pre> <p>It is recommended to use the Jupyter Notebooks Extensions to allow folding of code and headlines. This makes the notebooks more readable. Activate the extensions with:</p> <pre><code>jupyter nbextension enable codefolding/main\njupyter nbextension enable collapsible_headings/main\n</code></pre> <p>With this we have finished the installation of the exputils package.</p> <p>Now, we have to install your custom python library which contains the code that is used in experiments. In the case of the demo, this is the <code>my_dl_lib</code> which is located under <code>./src</code>. Here we install it in developer mode (<code>-e</code>) so that changes to the code are used when the package is imported by other python code.</p> <pre><code>pip install -e. ./src/my_dl_lib\n</code></pre> <p>Installing the libray will also install missing packages such as PyTorch and torchvision. </p> <p>This concludes setting up the exputils and the demo. We are now ready to use it.</p>"},{"location":"tutorials/#project-structure","title":"Project Structure","text":"<p>The exputils are in their functionality very versatile and allow you to freely structure your code and experiments how you want.  Nonetheless, we recommend to follow a certain project and folder structure for which the default parameters of the exputils functions are configured.</p> <p>A project consists of two main elements: code (under the <code>./src</code> folder) and experiments. Of course other elements such as the datasets in our example are possible. The project has the following folder structure (entries starting with a <code>*</code> can have custom names) where each element will be explained in the following sections in more detail: <pre><code>    pytorch_mnist   \n    \u251c\u2500\u2500 src  # code\n    \u2502   \u2514\u2500\u2500 * my_dl_lib  # python package with code for this demo\n    \u251c\u2500\u2500 experiments  # holds all experimental campaigns\n    \u2502   \u2514\u2500\u2500 * my_campaign \n    \u2514\u2500\u2500 * datasets  # optional datasets\n</code></pre></p>"},{"location":"tutorials/#code","title":"Code","text":"<p>First we have to create our code for which we want to run experiments. The code will be in form of python packages, which we import when running our experiments. If you are unfamiliar with python packages, please have a look at this tutorial.</p> <p>The pytorch_mnist demo is doing classification experiments using its <code>my_dl_lib</code> package under the <code>src</code> folder. The main functionality under <code>./src/my_dl_lib/my_dl_lib</code>  is in the <code>core.py</code> which defines how to train and test a neural network models.  The model itself is defined in the <code>models/neural_network.py</code>.</p> <p>In the following we will first learn how to configure our experiments before going into how to log data.</p>"},{"location":"tutorials/#configuration","title":"Configuration","text":"<p>How you configure your experiments is principle independent of the exputils. However, the package provides functions create configurations in form of a nested dictionaries. Each important function and class of the code takes such a dictionary as input parameter and define its default configuration in form of it.</p>"},{"location":"tutorials/#attrdict-dictionary","title":"AttrDict Dictionary","text":"<p>A special dictionary is provided that makes the configuration easier, the <code>AttrDict</code>. It allows to access its properties similar to properties <code>dict.value</code>, thus making it unnecessary to use the <code>dict['value']</code> expression.</p> <pre><code>import exputils as eu\nconfig = eu.AttrDict()\nconfig.learn_rate = 0.01  # set a value\nprint(config.learn_rate)  # read a value \n</code></pre>"},{"location":"tutorials/#default-configuration","title":"Default Configuration","text":"<p>The main function of our code is <code>run_training(config=None, **kwargs)</code> in <code>core.py</code>. The function loads the dataset, creates the network model, loss function, optimizer and runs the training. It takes as input a <code>config</code> dictionary that contains the configuration of our experiment such as the number of epochs we want to run it.</p> <p>First, the function defines the default configuration.  <pre><code>default_config = eu.AttrDict(\n    seed=None,\n    n_epochs=5,\n    batch_size=10,\n    dataset=eu.AttrDict(\n        cls=datasets.FashionMNIST,\n        root='./mnist',\n    ),\n    model=eu.AttrDict(\n        cls=NeuralNetwork\n    ),\n    loss=eu.AttrDict(\n        cls=torch.nn.CrossEntropyLoss\n    ),\n    optimizer=eu.AttrDict(\n        cls=torch.optim.SGD,\n        lr=0.01\n    )\n)\n</code></pre></p> <p>The default configuration is then compared with the given configuration to create the <code>config</code>: <pre><code>config = eu.combine_dicts(kwargs, config, default_config)\n</code></pre> The <code>combine_dicts</code> function combines its given dictionaries by comparing their elements also taking into account nested dictionaries.  The first given dictionary has priority and overrides the same element of the second dictionary.</p> <ul> <li> <p>Example:   </p> <pre><code>dict_a = eu.AttrDict()\ndict_a.name = 'a'\ndict_a.x_val = '1'\n\ndict_b = eu.AttrDict\ndict_b.name = 'default'\ndict_b.x_val = 0\ndict_b.y_val = 0\n\ncomb_dict = eu.combine_dicts(dict_a, dict_b)\n\nprint(comb_dict)\n</code></pre> <p>Output: <pre><code>AttrDict({'name': 'a', 'x_val': 1, 'y_val': 0})\n</code></pre></p> </li> </ul>"},{"location":"tutorials/#using-the-config","title":"Using the Config","text":"<p>We are then using the dictionary to seed the random number generators (random, numpy.random, torch.random) through the <code>seed</code> function that takes as input the config dictionary and uses its <code>seed</code> property to set them. If <code>seed=None</code> then a random initialization is done.  <pre><code>eu.misc.seed(config)\n</code></pre></p> <p>Then we use the config to load the training dataset using the create_object_from_config function: <pre><code>training_data = eu.create_object_from_config(\n    config.dataset,\n    train=True,\n    transform=ToTensor(),\n)\n</code></pre> The function takes as input a dictionary that defines an object that should be created.  In our case, this is a <code>torch.utils.data.Dataset</code> object.  The given dictionary defines the class (<code>cls</code> property) used to create the object and extra parameters that are given to the <code>__init__</code> method. The default config defines this object of class <code>FashionMNIST</code> and having as <code>root</code> parameter (location of the dataset on disk) the <code>./mnist</code> folder. <pre><code>config.dataset=eu.AttrDict(\n    cls=datasets.FashionMNIST,\n    root='./mnist',\n),\n</code></pre> Our call of the <code>create_object_from_config</code> function will also set the <code>train=True</code> and <code>transform=ToTensor()</code> properties which are not defined in the config. </p> <p>We use the same method to create the test_dataset, model, loss_fn and the optimizer objects for our training procedure.</p>"},{"location":"tutorials/#configuration-of-classes","title":"Configuration of Classes","text":"<p>We can configure objects from our custom classes in a similar way. See the <code>models/neural_network.py</code> for an example: <pre><code>import exputils as eu\nfrom torch import nn\n\nclass NeuralNetwork(nn.Module):\n\n    @staticmethod\n    def default_config():\n        return eu.AttrDict(\n            n_hidden_neurons=512\n        )\n\n    def __init__(self, config=None, **kwargs):\n        super().__init__()\n        self.config = eu.combine_dicts(kwargs, config, self.default_config())\n</code></pre> We define for each class a static method <code>default_config</code> that returns the default configuration of the class. In the <code>__init__(self, config=None, **kwargs)</code> we take as input a config dictionary and combine it with the default configuration to have our <code>self.config</code>.</p> <ul> <li> <p>Note:      The use of the <code>**kwargs</code> parameter is to allow the setting of the  configuration without the need for a dictionary.     The following two expressions are equal:</p> <pre><code>NeuralNetwork(config=dict(n_hidden_neurons=8))\n</code></pre> <p>and </p> <pre><code>NeuralNetwork(n_hidden_neurons=8)\n</code></pre> </li> </ul>"},{"location":"tutorials/#logging","title":"Logging","text":"<p>The exputils provides several logging functions to log for example the loss of the training over its iterations or the accuracy of the model after each epoch. Please see the Logging section in the references for more details of its various functions .</p>"},{"location":"tutorials/#logging-of-loss-and-accuracy","title":"Logging of Loss and Accuracy","text":"<p>To start logging we import the <code>exputils.data.logging</code> module (here as <code>log</code>) in the <code>core.py</code> and then use its <code>add_value</code> function. We can see it used in the <code>train</code> and <code>test</code> functions.</p> <p><pre><code>import exputils.data.logging as log\n\n...\n\ndef test(...):\n    ...\n    log.add_value('test/accuracy', 100 * correct)\n    log.add_value('test/loss', test_loss)\n</code></pre> We will see further below how we can visualize our logged data.</p>"},{"location":"tutorials/#experiment-status","title":"Experiment Status","text":"<p>Sometimes, we want to report the progress or status of our training for the user to see.  As we might run several experiments and repetitions in parallel the <code>print</code> function is not optimal as the parallel processes all write in the same console output making it difficult to now which output is for which experiment. To report the experiment status the exputils provides the <code>update_status</code> function.</p> <pre><code>def run_training(config=None, ...):\n    ...\n    for t in range(config.n_epochs):\n        eu.update_status(f\"train epoch {t+1}\")\n        ...\n</code></pre> <p>The <code>update_status</code> function takes as input a string, here the current epoch number, and will write it in a status file.  We will see further below how to visualize this information.</p>"},{"location":"tutorials/#experiments","title":"Experiments","text":"<p>After having prepared the code we can set up our experiments, run them and analyze afterward their results. Experiments are organized in form of campaigns under the <code>./experiments</code> folder. A campaign usually compares how different algorithms and parameters perform for a specific problem such as our FashionMNIST categorization task.  For this purpose, the demo has the <code>./experiments/my_campaign</code> where we want to compare the performance of our <code>NeuralNetwork</code> with different numbers of <code>n_hidden_neurons</code>.</p> <p>Each campaign has a recommended folder structure: <pre><code>my_campaign \n\u251c\u2500\u2500 analyze  \n\u2502   \u2514\u2500\u2500 overview.ipynb\n\u251c\u2500\u2500 src\n\u2502   \u2514\u2500\u2500 rep\n\u2502       \u251c\u2500\u2500 config.py\n\u2502       \u2514\u2500\u2500 run_repetition.py\n\u251c\u2500\u2500 experiment_configurations.ods\n\u251c\u2500\u2500 generate_experiments.sh\n\u251c\u2500\u2500 run_experiments.sh\n\u251c\u2500\u2500 get_status.sh   \n\u2514\u2500\u2500 experiments # THIS FOLDER WILL BE AUTOGENERATED!\n    \u251c\u2500\u2500 experiment_000001\n    \u2502   \u251c\u2500\u2500 repeition_000001\n    \u2502   \u2502   \u251c\u2500\u2500 data\n    \u2502   \u2502   \u251c\u2500\u2500 config.py\n    \u2502   \u2502   \u251c\u2500\u2500 run_repetition.py\n    \u2502   \u2502   \u2514\u2500\u2500 run_repetition.py.status\n    \u2502   \u251c\u2500\u2500 repeition_000002\n    \u2502   \u2514\u2500 ...\n    \u251c\u2500\u2500 experiment_000002    \n    \u2514\u2500 ...\n</code></pre> The individual elements will be explained in the following sections.</p>"},{"location":"tutorials/#definition","title":"Definition","text":"<p>To define what code to run and which algorithms and parameters to compare in a campaign, we have to set up two elements:</p> <ul> <li><code>src</code> folder: This folder contains the code that should be executed during an experiment and its repetitions.</li> <li><code>experiment_configurations.ods</code> file: This spreadsheet file for Libreoffice (open-source alternative to MS Excel) defines the algorithms and parameters of each experiments under our campaign.</li> </ul> <p>The <code>src</code> folder contains a <code>src/rep</code> folder that contains the code that will be generated for each repetition of each experiment that we define in a moment in the <code>experiment_configurations.ods</code> file.</p> <p>Code of Repetitions: run_repetition.py</p> <p>The python script that we execute when we run a repetition of an experiment is the <code>src/rep/run_repetition.py</code>: <pre><code>#!/usr/bin/env python\n\n# this allows to run processes in parallel on different cores without slowing down the processing\n# because each of them wants to use all cores\nimport torch\ntorch.set_num_threads(1)\n\n# read the config for this repetition from the config.py file\nfrom config import config\n\n# run the traning with the associated configuration for this repetition\nimport my_dl_lib\nmy_dl_lib.run_training(config=config)\n</code></pre> To be able to run it directly as a script it needs the shebang: <code>#!/usr/bin/env python</code>!</p> <p>It first imports pytorch to set its number of parallel threads to 1.  This is necessary to because we will run several repetitions and experiments in parallel on the different CPU or GPU cores that we have. But by default, some pytorch components make use of multithreading and allocate several cores automatically. Unfortunately, if we run processes in parallel and pytorch tries to use for each of them all cores, it comes to conflicts between the cores resulting in a much longer runtime. To avoid this, we define that each repetition can only use 1 thread and core. By handling the parallelization of processes this way we are still faster than letting pytorch handling it.</p> <p>Afterward, it imports the configuration for our experiment and repetition which we will discuss shortly.</p> <p>Finally, it imports our <code>my_dl_lib</code> that we prepared and executes the <code>run_training</code> function giving it the configuration of the repetition.</p> <p>Configuration Template: config.py</p> <p>The template for the configuration is defined in the <code>src/rep/config.py</code>: <pre><code>import exputils as eu\nimport my_dl_lib\nimport torch\nfrom torchvision import datasets\nfrom torch import nn\n\n# config for the my_dl_lib.run_training function\nconfig = eu.AttrDict(\n    # the seed if each repetition is different to have different network parameter initializations\n    seed = &lt;repetition_id&gt;,\n\n    # number of epochs with default of 5\n    n_epochs = &lt;n_epochs,10&gt;,\n\n    # batch size with default of 10\n    batch_size = &lt;batch_size,10&gt;,\n\n    # the loss and dataset is the same for all experiments in this campaign\n    dataset = eu.AttrDict(\n        cls = datasets.FashionMNIST,\n        root = '../../../../../datasets/mnist'\n    ),\n    loss = eu.AttrDict(\n        cls = nn.CrossEntropyLoss\n    ),\n\n    # as models can have different parameters, we allow to set them generally through the\n    # &lt;model_parameters&gt; placeholder, which can have a list of them, for example: \"n_layers=3, n_neurons=128\"\n    model = eu.AttrDict(\n        cls = my_dl_lib.models.&lt;model&gt;,\n        &lt;model_parameters&gt;\n    ),\n\n    optimizer = eu.AttrDict(\n        cls = torch.optim.&lt;optimizer&gt;,\n        lr = &lt;lr&gt;,\n    ),\n)\n</code></pre></p> <p>The configuration template file defines the config dictionary that we will give our <code>run_traning</code> function as input.  The configuration file contains incorrect python code because it contains placeholders: <code>&lt;name, std_value&gt;</code>.  These place holders will be later replaced by the actual parameter values for our experiment that we define in the <code>experiment_configurations.ods</code> file. For example, <code>n_epochs = &lt;n_epochs,10&gt;</code> will be later replaced by <code>n_epochs = 5</code> if the <code>experiment_configurations.ods</code> defines for <code>n_epochs</code> a value of 5. The optional <code>std_value</code> in the place holders will be used if no value would be defined in the <code>experiment_configurations.ods</code>. </p> <p>The random <code>seed</code> will be set by the <code>repetition_id</code> which is an <code>int</code> that defines the ID of a repetition from 0 onwards.   </p> <p>Configuration: experiment_configurations.ods</p> <p>The <code>experiment_configurations.ods</code> contains the values for all the placeholders of each experiment that we want to execute. To view and edit it, please install LibreOffice.</p> <p>Each line that has an <code>Experiment-ID</code> is an experiment. ID's can be integer from 0 onwards.  They can be freely defined, but have to be unique per campaign.</p> <p>The <code>repetitions</code> column define how many repetitions should be executed for this experiment, here 5 for each.</p> <p>The other columns define the values for the placeholders in our <code>config.py</code> template file. Values can be in any format and even python code. The exputils simply takes them as string values and replaces the corresponding placeholder with it.</p> <p>You can also use colors or font modifiers to help readability.  We can see that we want to have three experiments that differ in the <code>n_hidden_neurons</code> parameter (2, 8, 32).</p> <p>With this we have defined our experiments and can execute them.</p>"},{"location":"tutorials/#execution","title":"Execution","text":"<p>Functions for the execution of experiments are under the <code>exputils.manage</code> module as detailed in the  Manage section of the Reference. To manage experiments directly from the command line, three bash commands are provided that call the exputils functions:</p> <ul> <li><code>generate_experiments.sh</code>: Generate code of experiments and repetitions.</li> <li><code>run_experiments.sh</code>: Find which experiments and repetitions need to run and execute them in parallel.</li> <li><code>get_status.sh</code>: Print the execution status of experiments.  </li> </ul> <p>We will detail the use of these commands in the following sections.  For more information you can call them with the <code>-h</code> param, for example <code>./get_status.sh -h</code>.</p> <ul> <li>Tip: The commands have to be copied to each campaign folder that you create.  To avoid this, you can create them as system-wide commands.  See this tutorial for help: How to create custom commands.</li> </ul>"},{"location":"tutorials/#generation-of-experiments","title":"Generation of Experiments","text":"<p>Before execution, we have to generate the code for each experiment and repetition. This creates for each experiment and repetition a folder that contains the code we defined in the <code>./src/rep</code> folder.  Moreover, it replaces the placeholders in the <code>config.py</code> with the values for the experiment and repetition.</p> <p>To generate the code, call:</p> <pre><code>./generate_experiments.sh\n</code></pre> <p>Output:</p> <pre><code>Generate experiments ...\nFinished.\n</code></pre> <p>The command creates a new folder in der campaign: <code>./experiments</code>, that contains all defined experiments and repetitions. When opening the configuration for experiment-ID 1 and its repetition-ID 0 we can see that the placeholders were correctly adjusted according to our <code>experiment_configurations.ods</code>.</p> <p>Content of file <code>./experiments/experiment_000001/repetition_000000/config.py</code>: <pre><code>import ...\n\nconfig = eu.AttrDict(\n    seed = 0,\n    n_epochs = 5,\n    batch_size = 10,\n    dataset = eu.AttrDict(\n        cls = datasets.FashionMNIST,\n        root = '../../../../../datasets/mnist'\n    ),\n    loss = eu.AttrDict(\n        cls = nn.CrossEntropyLoss\n    ),\n    model = eu.AttrDict(\n        cls = my_dl_lib.models.NeuralNetwork,\n        n_hidden_neurons=2\n    ),\n    optimizer = eu.AttrDict(\n        cls = torch.optim.SGD,\n        lr = 0.01,\n    ),\n)\n</code></pre> The <code>seed</code> is set to the repetition-ID 0 and the <code>n_hidden_neurons</code> is correctly set to 2.</p>"},{"location":"tutorials/#running-a-single-repetition","title":"Running a single Repetition","text":"<p>To test if our experiment runs correctly we can execute a particular repetition:</p> <pre><code>cd ./experiments/experiment_000001/repetition_000000\n./run_repetition.py\ncd ../../..\n</code></pre> <p>Output:</p> <pre><code>Using cpu device\nTest Error: \n Accuracy: 10.0%, Avg loss: 2.359976\n\nEpoch 1\n-------------------------------\nloss: 2.377968  [   10/60000]\nloss: 2.175646  [ 1010/60000]\n\n...\n\nloss: 1.392127  [58010/60000]\nloss: 1.375843  [59010/60000]\nTest Error: \n Accuracy: 45.9%, Avg loss: 1.343065\n\nDone!\n</code></pre> <p>The repetition works as intended.  You can also see that it created a <code>data</code> folder in the repetition folder that contains a numpy array file (<code>.npy</code>) for each of the variables that we logged.</p> <pre><code>ls ./experiments/experiment_000001/repetition_000000/data\n</code></pre> <p>Output: </p> <pre><code>test_accuracy.npy  test_loss.npy  train_loss.npy\n</code></pre> <p>We will later visualize this data.</p>"},{"location":"tutorials/#running-of-experiments","title":"Running of Experiments","text":"<p>Of course, we do not want to start each repetition manually.  Moreover, we want to run several of them in parallel on different CPU or GPU cores to save time. To achieve this we use the <code>run_experiments.sh</code> command and instruct it to run 10 experiments / repetitions in parallel:</p> <pre><code>./run_experiments.sh -n 10\n</code></pre> <p>Output:</p> <pre><code>Start experiments ...\n2024/11/13 09:39:08 start './experiments/experiment_000001/repetition_000001/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000001/repetition_000002/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000001/repetition_000003/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000001/repetition_000004/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000002/repetition_000000/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000002/repetition_000001/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000002/repetition_000002/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000002/repetition_000003/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000002/repetition_000004/run_repetition.py' (previous status: todo) ...\n2024/11/13 09:39:08 start './experiments/experiment_000003/repetition_000000/run_repetition.py' (previous status: todo) ...\n\nUsing cpu device\nUsing cpu device\n\n...\n\nDone!\n2024/11/13 09:41:06 finished './experiments/experiment_000003/repetition_000003/run_repetition.py' (status: finished)\n2024/11/13 09:41:06 finished './experiments/experiment_000003/repetition_000004/run_repetition.py' (status: finished)\nFinished.\n</code></pre> <p>Note: If the experiments have not been generated so far then the <code>run_experiments.sh</code> command will generate them.</p> <p>The command collects the first 10 repetitions that have not been started so far and executes them in parallel.  If the first of the 10 repetitions is finished then the exputils selects the next repetition that has to be executed and starts it until all repetitions have been successfully executed.</p>"},{"location":"tutorials/#visualizing-the-progress","title":"Visualizing the Progress","text":"<p>We can see that the repetitions print outputs are also displayed in parallel making it hard to read them and see the progress. For this purpose exists the <code>get_status.sh</code> command. While the experiments are running, open another terminal and navigate to the campaign folder. Then call:</p> <pre><code>./get_status.sh\n</code></pre> <p>Output:</p> <pre><code>2024/11/13 09:53:37 ./experiments/experiment_000001/repetition_000000/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:44 ./experiments/experiment_000001/repetition_000001/run_repetition.py.status - finished \n2024/11/13 09:53:36 ./experiments/experiment_000001/repetition_000002/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:34 ./experiments/experiment_000001/repetition_000003/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:35 ./experiments/experiment_000001/repetition_000004/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:32 ./experiments/experiment_000002/repetition_000000/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:34 ./experiments/experiment_000002/repetition_000001/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:46 ./experiments/experiment_000002/repetition_000002/run_repetition.py.status - finished \n2024/11/13 09:53:35 ./experiments/experiment_000002/repetition_000003/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:38 ./experiments/experiment_000002/repetition_000004/run_repetition.py.status - running  train epoch 5\n2024/11/13 09:53:44 ./experiments/experiment_000003/repetition_000000/run_repetition.py.status - running \n2024/11/13 09:53:47 ./experiments/experiment_000003/repetition_000001/run_repetition.py.status - running \n2024/11/13 09:52:35 ./experiments/experiment_000003/repetition_000002/run_repetition.py.status - todo \n2024/11/13 09:52:35 ./experiments/experiment_000003/repetition_000003/run_repetition.py.status - todo \n2024/11/13 09:52:35 ./experiments/experiment_000003/repetition_000004/run_repetition.py.status - todo \ntotal: 15 | todo: 3 | running: 10 | error: 0 | finished: 2\n</code></pre> <p>We can see that 2 repetitions are finished, 10 are running and 3 are still to be started.  The command also shows us the current training epoch of each repetition that we are reporting using the <code>update_status</code> function in our code.</p> <ul> <li>Tip: To get a contiuous update of the status use the <code>-t</code> flag of the <code>get_status.sh</code> command. You can exit it with <code>Ctrl+C</code>.  To avoid that it displayes information about already finished experiments use the <code>-u</code> flag.<pre><code>./get_status.sh -t -u\n</code></pre> </li> </ul>"},{"location":"tutorials/#running-additional-experiments","title":"Running Additional Experiments","text":"<p>Usually our initial experiments are not enough and we have to run further parameters. This can be easily done by adding new lines in the <code>experiment_configurations.ods</code> file and then by running again the experiments.</p> <p>Let's add a new experiments (ID: 4) that evaluates our network model with 128 <code>n_hidden_neurons</code> to the <code>experiment_configurations.ods</code>:</p> <p>After saving the file, we use again our command to run experiments. Besides running experiments, it will also generate them first:</p> <pre><code>./run_experiments.sh -n 10\n</code></pre> <p>Output:</p> <pre><code>Start experiments ...\n2024/11/13 13:12:53 start './experiments/experiment_000004/repetition_000000/run_repetition.py' (previous status: todo) ...\n2024/11/13 13:12:53 start './experiments/experiment_000004/repetition_000001/run_repetition.py' (previous status: todo) ...\n2024/11/13 13:12:53 start './experiments/experiment_000004/repetition_000002/run_repetition.py' (previous status: todo) ...\n2024/11/13 13:12:53 start './experiments/experiment_000004/repetition_000003/run_repetition.py' (previous status: todo) ...\n2024/11/13 13:12:53 start './experiments/experiment_000004/repetition_000004/run_repetition.py' (previous status: todo) ...\n\n...\n\nFinished.\n</code></pre> <p>We can observe that the command only starts the repetitions of the new experiment (ID: 4). It will not rerun experiments that have been already executed.</p> <p>Note: If you want to rerun experiments, you have to delete their folders under <code>./experiments</code>. Exputils will then regenerate and rerun them. </p>"},{"location":"tutorials/#analysis","title":"Analysis","text":"<p>After our experiments have been finished we want to look at their results.  The exputils provide some useful Jupyter widgets to load our logged data and visualize them with interactive plots. For this you have to install some extras for Jupyter notebook as outlined in the Installation section.</p> <p>Inside our campaign start Jupyter notebook:</p> <pre><code>jupyter notebook\n</code></pre> <p>Inside the notebook, open the prepared notebook <code>./analyze/overview.ipynb</code>.</p>"},{"location":"tutorials/#loading-data","title":"Loading Data","text":"<p>The first cell imports the exputils and opens the ExperimentDataLoaderWidget.</p> <pre><code>import exputils as eu\nexperiment_data_loader = eu.gui.jupyter.ExperimentDataLoaderWidget()\ndisplay(experiment_data_loader)\n</code></pre> <p>We can see all the experiments that we executed and that we can load. Click the 'Load Data' button to load the data from the checkmarked () items.</p> <p>Output:</p> <pre><code>Load data ...\nData successfully loaded.\n</code></pre> <p>The widget loaded all the logged data that was in the <code>data</code> folder of each repetition. If you run new experiments at a later point, click on Update Descriptions to see them in the table and load them.</p> <p>The data is stored in the nested dictionary <code>experiment_data_loader.experiment_data</code> that has the following general structure:</p> <pre><code>experiment_data_loader.experiment_data: dict\n\u2514\u2500\u2500 key: &lt;Experiment-ID&gt; (str): dict  \n    \u2514\u2500\u2500 key: 'repetition_data': dict\n        \u2514\u2500\u2500 key: &lt;Repetition-ID&gt; (int): dict    \n            \u2514\u2500\u2500 key: &lt;datasource_name&gt; (int): data usually as numpy array\n</code></pre> <p>The next cell prints the data in a 'pretty' way:</p> <pre><code>def pretty(d, indent=0):\n   for key, value in d.items():\n      print('\\t' * indent + str(key))\n      if isinstance(value, dict):\n         pretty(value, indent+1)\n      else:\n         print('\\t' * (indent+1) + str(value))\n\npretty(experiment_data_loader.experiment_data)\n</code></pre> <p>Output (shortened):</p> <pre><code>000001\n    repetition_data\n        0\n            test_loss\n                [2.35997581 1.73878336 1.5804979  1.46617584 1.37025173 1.34306539]\n            train_loss\n                [2.37796783 2.38081217 2.57028079 ... 1.57344127 1.52922952 1.03360915]\n            test_accuracy\n                [10.         33.215      32.38333333 44.97166667 46.80833333 45.94833333]\n        1\n        ...\n000002\n...\n</code></pre>"},{"location":"tutorials/#visualizing-data","title":"Visualizing Data","text":"<p>With the data loaded, we can now visualize it. The ExperimentDataPlotSelectionWidget allows to select which datasources (variables that we logged) to plot and by which plotting tool. The next cell calls it:</p> <pre><code>experiment_data_plotter = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(experiment_data_loader)\ndisplay(experiment_data_plotter)\n</code></pre> <p>In the Data Sources field we input the name of the datasource we want to plot. Under Plot Function we can select the plotting tool which can be configured in the Plot Configuration section.</p>"},{"location":"tutorials/#line-plots","title":"Line Plots","text":"<p>First, we would like to plot the <code>test_accuracy</code> data in a line plot. For this we enter <code>test_accuracy</code> in the the Data Sources field, select plotly_meanstd_scatter  as Plot Function and press the Plot Data button.</p> <p>The interactive plot shows us the accuracy over training epochs. Each line represents the mean accuracy per experiment and the shaded area the standard deviation. All plots are based on plotly, so they are interactive. You can zoom in the plot or select which data curve should be only visible by clicking on the labels. The buttons on the bottom also allow to view for example the individual elements (repetitions) or each experiment. </p>"},{"location":"tutorials/#changing-the-plot-configuration","title":"Changing the Plot Configuration","text":"<p>We can modify the configuration of the plot to make things more clear.  Replace the Plot Configuration with the following config to modify the labels of the x-axis and y-axis:</p> <pre><code>layout = dict(\n    xaxis = dict(title = 'epoch'), \n    yaxis = dict(title = 'accuracy'),\n)\n</code></pre> <p>Moreover, we want to change the labels of the experiments. For, this go back to the ExperimentDataLoaderWidget (the table that shows which data to load) and change the name of each experiment. (Note: You do not need to reload the data.)</p> <pre><code>exp 000001 --&gt; n_hidden: 2\nexp 000002 --&gt; n_hidden: 8\nexp 000003 --&gt; n_hidden: 32\nexp 000004 --&gt; n_hidden: 128\n</code></pre> <p>With these changes plot the data again using the Plot Data button.</p>"},{"location":"tutorials/#creating-dedicated-plots","title":"Creating Dedicated Plots","text":"<p>Instead of using in the future always the ExperimentDataPlotSelectionWidget to plot the accuracy data we can also create a dedicated cell to plot the figure that we configured. Open the Code Production selection of the Plot Selection Widget and select Multi Line. This creates a new cell below the current one with:</p> <p><pre><code># Plotting of ['test_accuracy'] \nimport exputils as eu\nfrom exputils.gui.jupyter.plotly_meanstd_scatter import plotly_meanstd_scatter\n\nplot_config = eu.AttrDict(\nlayout = dict(\n    xaxis = dict(title = 'epoch'), \n    yaxis = dict(title = 'accuracy'),\n)\n)\n\nselection_widget = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(\n    experiment_data_loader,\n    datasources=['test_accuracy'],\n    experiment_ids='all',\n    repetition_ids='all',\n    output_format=('S', 'E', 'D'),\n    data_filter='',\n    plot_function=plotly_meanstd_scatter,\n    plot_function_config=plot_config,\n    state_backup_name='state_backup_153826407',\n    state_backup_variable_filter=['experiment_ids', 'repetition_ids'],  # only save these variables as backup\n    is_datasources_selection=False,\n    is_output_format_selection=False,\n    is_data_filter_selection=False,\n    is_plot_function_selection=False,\n    is_plot_function_config_editor=False,\n    is_code_producer=False) \ndisplay(selection_widget)\nselection_widget.plot_data()\n</code></pre> If you execute the cell, you can see that it replicates the plot. The configuration for the plot can now be directly changed through this code. We can use this method to create all the general plots that we need to analyze our campaign.</p> <p>In the rest of our notebook there are already several of these plots created.  We discuss them in the following sections.</p>"},{"location":"tutorials/#box-plots","title":"Box Plots","text":"<p>We want to better illustrate the final accuracy of each experiment. For this we can use a box plot that compares scalar values between experiments.</p> <p>Use again the ExperimentDataPlotSelectionWidget with the following configuration:</p> <ul> <li>Data Sources: <code>test_accuracy[-1]</code> (This selects the final array element in our datasource.)</li> <li>Plot Function: plotly_box</li> <li>Plot Configuration: <code>layout = dict(yaxis = dict(title = 'accuracy'))</code></li> </ul> <p>The interactive plot shows you several statistics such as the mean, median, min and max of each final accuracy over the 5 repetitions per experiment. If you select the <code>_all_</code> button at the bottom of the plot you can also see the individual outcomes of each repetition as dots next to each box.</p> <p>The plot shows use clearly that the accuracy increases with a higher number of hidden neurons in the NeuralNetwork model, but that there is also a diminishing return.</p>"},{"location":"tutorials/#bar-plots","title":"Bar Plots","text":"<p>The next plot is similar, but presents each experiment as a bar. </p> <p>Use: </p> <ul> <li>Data Sources: <code>test_accuracy[-1]</code></li> <li>Plot Function: plotly_meanstd_bar</li> <li>Plot Configuration: <code>layout = dict(yaxis = dict(title='accuracy', range=[0,100]))</code></li> </ul>"},{"location":"tutorials/#tables","title":"Tables","text":"<p>We can show the information also in a table which allows us also to visualize several datasources together.</p> <p>Use:</p> <ul> <li>Data Sources: <code>test_accuracy[-1], test_loss[-1], train_loss[-1]</code></li> <li>Plot Function: tabulate_meanstd</li> <li>Plot Configuration: <code>flip_rows_and_cols = True, top_left_cell_content = 'Experiment'</code></li> </ul> <p>The table shows for the final accuracy and each final loss the average and in brackets the standard deviation over all repetition. </p>"},{"location":"tutorials/#pairwise-comparison-tables","title":"Pairwise-Comparison Tables","text":"<p>We can also compare the one scalar value of each experiment pairwise with each other experiment. With this we can compute for example a Mann\u2013Whitney U test to see if the results are statistically significant different.</p> <p>Use:</p> <ul> <li>Data Sources: <code>test_accuracy[-1]</code></li> <li>Plot Function: tabulate_pairwise</li> <li>Plot Configuration: Keep the default.</li> </ul> <p>The table shows the p-value for each test. As they are all way below 0.01 we can establish that the resulting accuracy differences between our models are statistically significant.  You can choose which function to use to compare experiments. See more details at the reference for tabulate_pairwise.</p>"},{"location":"reference/io/","title":"IO","text":"<p>Different IO operations used to load and save data through the exputils package.  They are usually not needed to log or load data which is done with the functions under the <code>exputils.data</code> module. See the Logging and Loading sections for more information.</p>"},{"location":"reference/io/#exputils.io.general.makedirs","title":"<code>makedirs</code>","text":"<p>Creates a directory and all intermediate directories if they do not exist in a file path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The directory path to create.</p> required Source code in <code>exputils/io/general.py</code> <pre><code>def makedirs(path: str):\n    \"\"\"\n    Creates a directory and all intermediate directories if they do not exist in a file path.\n\n    Parameters:\n        path (str): The directory path to create.\n    \"\"\"\n\n    if not os.path.isdir(path):\n        os.makedirs(path)\n</code></pre>"},{"location":"reference/io/#exputils.io.general.makedirs_for_file","title":"<code>makedirs_for_file</code>","text":"<p>Creates the necessary directories for a given file path if they do not already exist.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>The complete file path for which the directories are to be created.</p> required Source code in <code>exputils/io/general.py</code> <pre><code>def makedirs_for_file(filepath: str):\n    \"\"\"\n    Creates the necessary directories for a given file path if they do not already exist.\n\n    Parameters:\n        filepath (str): The complete file path for which the directories are to be created.\n    \"\"\"\n\n    directory_path, _ = os.path.split(filepath)\n    makedirs(directory_path)\n</code></pre>"},{"location":"reference/io/#exputils.io.numpy.load_numpy_files","title":"<code>load_numpy_files</code>","text":"<p>Loads numpy files from a specified directory into an AttrDict.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The path to the directory containing the numpy files.</p> required <code>allowed_data_filter</code> <code>list</code> <p>A list of allowed file names to be loaded. If specified, only files with names in this list will be loaded.</p> <code>None</code> <code>denied_data_filter</code> <code>list</code> <p>A list of denied file names to be excluded from loading. If specified, files with names in this list will not be loaded.</p> <code>None</code> <code>allow_pickle</code> <code>bool</code> <p>Whether to allow loading pickled (serialized) objects. Default is True.   This could allow arbitrary code execution. Only load files you trust!</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both allowed_data_filter and denied_data_filter are specified.</p> <code>FileNotFoundError</code> <p>If the specified directory does not exist.</p> <code>Exception</code> <p>If an error occurs during loading of a file.</p> <p>Returns:</p> Name Type Description <code>data</code> <code>AttrDict</code> <p>Dictionary with loaded data where the keys are file names without extensions and the values are the respective numpy arrays.</p> Source code in <code>exputils/io/numpy.py</code> <pre><code>def load_numpy_files(directory: str,\n                    allowed_data_filter: Optional[list] = None,\n                    denied_data_filter: Optional[list] = None,\n                    allow_pickle: bool = True) -&gt; AttrDict:\n    \"\"\"Loads numpy files from a specified directory into an AttrDict.\n\n    Parameters:\n        directory (str):\n            The path to the directory containing the numpy files.\n        allowed_data_filter (list, optional):\n            A list of allowed file names to be loaded.\n            If specified, only files with names in this list will be loaded.\n        denied_data_filter (list, optional):\n            A list of denied file names to be excluded from loading.\n            If specified, files with names in this list will not be loaded.\n        allow_pickle (bool):\n            Whether to allow loading pickled (serialized) objects.\n            Default is True. &lt;br&gt;\n            :warning: This could allow arbitrary code execution. Only load files you trust!\n\n    Raises:\n        ValueError:\n            If both allowed_data_filter and denied_data_filter are specified.\n        FileNotFoundError:\n            If the specified directory does not exist.\n        Exception:\n            If an error occurs during loading of a file.\n\n    Returns:\n        data (AttrDict):\n            Dictionary with loaded data where the keys are file names without extensions\n            and the values are the respective numpy arrays.\n    \"\"\"\n\n    if allowed_data_filter is not None and denied_data_filter is not None:\n        raise ValueError('in_data_filter and out_data_filter can not both be set, only one or none!')\n\n    if not os.path.isdir(directory):\n        raise FileNotFoundError('Directory {!r} does not exist!'.format(directory))\n\n    data = AttrDict()\n\n    for file in glob(os.path.join(directory, '*.npy')):\n        stat_name = os.path.splitext(os.path.basename(file))[0]\n\n        if eu.misc.is_allowed(stat_name, allowed_list=allowed_data_filter, denied_list=denied_data_filter):\n            try:\n                stat_val = np.load(file, allow_pickle=allow_pickle)\n            except FileNotFoundError:\n                raise\n            except Exception as e:\n                raise Exception('Exception during loading of file {!r}!'.format(file)) from e\n\n            if len(stat_val.shape) == 0:\n                stat_val = stat_val.dtype.type(stat_val)\n\n            data[stat_name] = stat_val\n\n    for file in glob(os.path.join(directory, '*.npz')):\n        stat_name = os.path.splitext(os.path.basename(file))[0]\n        if eu.misc.is_allowed(stat_name, allowed_list=allowed_data_filter, denied_list=denied_data_filter):\n            try:\n                stat_vals = AttrDict(np.load(file, allow_pickle=allow_pickle))\n            except FileNotFoundError:\n                raise\n            except Exception as e:\n                raise Exception('Exception during loading of file {!r}!'.format(file)) from e\n\n            # remove data that should not be loaded\n            keys = [k for k, v in stat_vals.items() if not eu.misc.is_allowed(k, allowed_list=allowed_data_filter, denied_list=denied_data_filter)]\n            for x in keys:\n                del stat_vals[x]\n\n            # numpy encapsulates scalars as darrays with an empty shape\n            # recover the original type\n            for substat_name, substat_val in stat_vals.items():\n                if len(substat_val.shape) == 0:\n                    stat_vals[substat_name] = substat_val.dtype.type(substat_val)\n\n            data[stat_name] = stat_vals\n\n    return data\n</code></pre>"},{"location":"reference/io/#exputils.io.numpy.save_dict_to_numpy_files","title":"<code>save_dict_to_numpy_files</code>","text":"<p>Saves a dictionary with numpy arrays to numpy files (either .npy, .npz, or .npz compressed formats).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing the data to be saved, with keys as filenames and values as data to be saved.</p> required <code>path</code> <code>str</code> <p>Directory or file path where the numpy files will be saved. Default is the current directory.</p> <code>'.'</code> <code>mode</code> <code>str</code> <p>Mode in which to save the data. Can be 'npy', 'npz', or 'cnpz'. Default is 'npy'.</p> <code>'npy'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid mode is provided.</p> Source code in <code>exputils/io/numpy.py</code> <pre><code>def save_dict_to_numpy_files(data: dict,\n                             path: Optional[str] = '.',\n                             mode: Optional[str] = 'npy'):\n    \"\"\"Saves a dictionary with numpy arrays to numpy files (either .npy, .npz, or .npz compressed formats).\n\n    Parameters:\n        data (dict):\n            Dictionary containing the data to be saved, with keys as filenames and values as data to be saved.\n        path (str):\n            Directory or file path where the numpy files will be saved.\n            Default is the current directory.\n        mode (str):\n            Mode in which to save the data.\n            Can be 'npy', 'npz', or 'cnpz'.\n            Default is 'npy'.\n\n    Raises:\n        ValueError: If an invalid mode is provided.\n    \"\"\"\n\n    # save logs in numpy format if they exist\n    if mode.lower() == 'npy':\n        eu.io.makedirs(path)\n        for name, values in data.items():\n            np.save(os.path.join(path, name), values)\n\n    elif mode.lower() == 'npz':\n        eu.io.makedirs_for_file(path)\n        np.savez(path, **data)\n\n    elif mode.lower() == 'cnpz':\n        eu.io.makedirs_for_file(path)\n        np.savez_compressed(path, **data)\n\n    else:\n        raise ValueError('Unknown numpy logging mode {!r}! Only \\'npy\\', \\'npz\\' and \\'cnpz\\' are allowed.'.format(mode))\n</code></pre>"},{"location":"reference/io/#exputils.io.dill.load_dill","title":"<code>load_dill</code>","text":"<p>Loads a serialized object from a file using the dill library.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the file from which to load the object. The file extension is optionally added if not already present.</p> required <p>Returns:</p> Name Type Description <code>obj</code> <code>Any</code> <p>The object that was deserialized from the file.</p> Notes: <ul> <li>If the specified file does not exist, the function attempts to append   the expected file extension (.dill) before throwing an error.</li> <li> This could allow arbitrary code execution. Only load files you trust!</li> </ul> Source code in <code>exputils/io/dill.py</code> <pre><code>def load_dill(file_path: str) -&gt; object:\n    \"\"\"\n    Loads a serialized object from a file using the [dill](https://pypi.org/project/dill/) library.\n\n    Parameters:\n        file_path (str):\n            The path to the file from which to load the object.\n            The file extension is optionally added if not already present.\n\n    Returns:\n        obj (Any): The object that was deserialized from the file.\n\n    &lt;h4&gt;Notes:&lt;/h4&gt;\n\n    - If the specified file does not exist, the function attempts to append\n      the expected file extension (.dill) before throwing an error.\n    - :warning: This could allow arbitrary code execution. Only load files you trust!\n    \"\"\"\n    if not os.path.exists(file_path):\n        if not file_path.endswith('.' + DILL_FILE_EXTENSION):\n            file_path += '.' + DILL_FILE_EXTENSION\n\n    with open(file_path, 'rb') as fh:\n        obj = dill.load(fh)\n    return obj\n</code></pre>"},{"location":"reference/io/#exputils.io.dill.load_dill_files","title":"<code>load_dill_files</code>","text":"<p>Loads all serialized objects from a directory using the dill library and returns them in a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>The path to the directory containing dill-serialized files.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified directory does not exist.</p> <p>Returns:</p> Name Type Description <code>data</code> <code>AttrDict</code> <p>An attribute dictionary where keys are the file names (without extensions) and values are the deserialized objects.</p> Notes: <ul> <li>If the specified file does not exist, the function attempts to append   the expected file extension (.dill) before throwing an error.</li> <li> This could allow arbitrary code execution. Only load files you trust!</li> </ul> Source code in <code>exputils/io/dill.py</code> <pre><code>def load_dill_files(directory: str):\n    \"\"\"\n    Loads all serialized objects from a directory using the [dill](https://pypi.org/project/dill/)\n    library and returns them in a dictionary.\n\n    Parameters:\n        directory (str):\n            The path to the directory containing dill-serialized files.\n\n    Raises:\n        FileNotFoundError: If the specified directory does not exist.\n\n    Returns:\n        data (AttrDict):\n            An attribute dictionary where keys are the file names (without extensions) and\n            values are the deserialized objects.\n\n    &lt;h4&gt;Notes:&lt;/h4&gt;\n\n    - If the specified file does not exist, the function attempts to append\n      the expected file extension (.dill) before throwing an error.\n    - :warning: This could allow arbitrary code execution. Only load files you trust!\n    \"\"\"\n\n    if not os.path.isdir(directory):\n        raise FileNotFoundError('Directory {!r} does not exist!'.format(directory))\n\n    data_dict = eu.AttrDict()\n\n    for file in glob(os.path.join(directory, '*.' + DILL_FILE_EXTENSION)):\n        data_name = os.path.splitext(os.path.basename(file))[0]\n        data = load_dill(file)\n        data_dict[data_name] = data\n\n    return data_dict\n</code></pre>"},{"location":"reference/io/#exputils.io.dill.save_dill","title":"<code>save_dill</code>","text":"<p>Serializes a Python object and saves it to a file using the dill serialization library.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The Python object to be serialized.</p> required <code>file_path</code> <code>str</code> <p>The file path where the serialized object will be saved.</p> required Notes: <ul> <li>If the provided file path does not have the correct file extension for Dill files,   the extension will be added automatically.</li> <li>The necessary directories for the file path will be created if they do not exist.</li> </ul> Source code in <code>exputils/io/dill.py</code> <pre><code>def save_dill(obj,\n              file_path: str):\n    \"\"\"\n    Serializes a Python object and saves it to a file using the [dill](https://pypi.org/project/dill/)\n    serialization library.\n\n    Parameters:\n        obj (Any):\n            The Python object to be serialized.\n        file_path (str):\n            The file path where the serialized object will be saved.\n\n    &lt;h4&gt;Notes:&lt;/h4&gt;\n\n    - If the provided file path does not have the correct file extension for Dill files,\n      the extension will be added automatically.\n    - The necessary directories for the file path will be created if they do not exist.\n    \"\"\"\n    if not file_path.endswith('.' + DILL_FILE_EXTENSION):\n        file_path += '.' + DILL_FILE_EXTENSION\n\n    eu.io.makedirs_for_file(file_path)\n    with open(file_path, 'wb') as fh:\n        dill.dump(obj, fh)\n</code></pre>"},{"location":"reference/loading/","title":"Loading","text":"<p>Functions to load the logged data from experiments and their repetitions and the structure of the generated experiments.</p> <p>The functions can be accessed under the module: <code>exputils.data</code></p> <p>Usually the data is loaded in Jupyter notebook using the <code>ExperimentDataLoaderWidget</code>. The following loading functions can be used if data should be loaded for a custom analysis or plots.</p>"},{"location":"reference/loading/#exputils.data.loading.load_experiment_descriptions","title":"<code>load_experiment_descriptions</code>","text":"<p>Loads and returns descriptions of experiments from a specified experiments directory.</p> <p>Parameters:</p> Name Type Description Default <code>experiments_directory</code> <code>str</code> <p>Path to the experiments directory. Defaults to \"..\\DEFAULT_EXPERIMENTS_DIRECTORY\".</p> <code>None</code> <code>allowed_experiments_id_list</code> <code>list</code> <p>List of experiment IDs to be loaded. Cannot be used with denied_experiments_id_list. Default: All experiments are considered.</p> <code>None</code> <code>denied_experiments_id_list</code> <code>list</code> <p>List of experiment IDs to be excluded. Cannot be used with allowed_experiments_id_list. Default: All experiments are considered.</p> <code>None</code> <code>experiment_directory_template</code> <code>str</code> <p>Template string for the name of experiment directories. The template should include a placeholder for the experiment id. Example: 'experiment_{:06d}' for experiment folders with ids with at least six digits. Defaults to EXPERIMENT_DIRECTORY_TEMPLATE.</p> <code>None</code> <code>repetition_directory_template</code> <code>str</code> <p>Template string for the name of experiment directories. The template should include a placeholder for the repetition id. Example: 'repetition_{:06d}' for repetition folders with ids with at least six digits. Defaults to REPETITION_DIRECTORY_TEMPLATE.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AttrDict</code> <code>AttrDict</code> <p>A dictionary containing descriptions of the experiments.</p> <code>AttrDict</code> <p>The keys are the experiment ids and the values are dictionaries with the follwing properties:</p> <ul> <li>id: experiment id.</li> <li>name: Name of the experiment. Default: 'exp &lt;experiment id&gt;'.</li> <li>short_name: A short name for display purposes. Default: 'e&lt;experiment id&gt;'.</li> <li>order: Sort order of experiments if they should be displayed in a GUI.</li> <li>directory: Full path to experiment directory.</li> <li>description: Description of the experiment. Default: ''.</li> <li>repetition_ids: List of repetition ids.</li> <li>repetition_directories : List of full paths to repetition directories.</li> </ul> Source code in <code>exputils/data/loading.py</code> <pre><code>def load_experiment_descriptions(experiments_directory: Optional[str] = None,\n                                 allowed_experiments_id_list: Optional[list] = None,\n                                 denied_experiments_id_list: Optional[list] = None,\n                                 experiment_directory_template: Optional[str] = None,\n                                 repetition_directory_template: Optional[str] = None) -&gt; AttrDict:\n    \"\"\"\n    Loads and returns descriptions of experiments from a specified experiments directory.\n\n    Arguments:\n        experiments_directory (str): Path to the experiments directory.\n            Defaults to \"..\\DEFAULT_EXPERIMENTS_DIRECTORY\".\n        allowed_experiments_id_list (list): List of experiment IDs to be loaded.\n            Cannot be used with denied_experiments_id_list.\n            Default: All experiments are considered.\n        denied_experiments_id_list (list): List of experiment IDs to be excluded.\n            Cannot be used with allowed_experiments_id_list.\n            Default: All experiments are considered.\n        experiment_directory_template (str): Template string for the name of experiment directories.\n            The template should include a placeholder for the experiment id.\n            Example: 'experiment_{:06d}' for experiment folders with ids with at least six digits.\n            Defaults to EXPERIMENT_DIRECTORY_TEMPLATE.\n        repetition_directory_template (str): Template string for the name of experiment directories.\n            The template should include a placeholder for the repetition id.\n            Example: 'repetition_{:06d}' for repetition folders with ids with at least six digits.\n            Defaults to REPETITION_DIRECTORY_TEMPLATE.\n\n    Returns:\n        AttrDict: A dictionary containing descriptions of the experiments.\n        The keys are the experiment ids and the values are dictionaries with the follwing properties:\n\n            - id: experiment id.\n            - name: Name of the experiment. Default: 'exp &lt;experiment id\\&gt;'.\n            - short_name: A short name for display purposes. Default: 'e&lt;experiment id\\&gt;'.\n            - order: Sort order of experiments if they should be displayed in a GUI.\n            - directory: Full path to experiment directory.\n            - description: Description of the experiment. Default: ''.\n            - repetition_ids: List of repetition ids.\n            - repetition_directories : List of full paths to repetition directories.\n    \"\"\"\n\n    if experiments_directory is None:\n        experiments_directory = os.path.join('..', eu.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n    if allowed_experiments_id_list is not None and denied_experiments_id_list is not None:\n        raise ValueError('allowed_experiments_id_list and denied_experiments_id_list can not be set at the same time!')\n\n    if experiment_directory_template is None: experiment_directory_template = eu.EXPERIMENT_DIRECTORY_TEMPLATE\n    experiment_directory_template = re.sub('\\{.*\\}', '*', experiment_directory_template)\n\n    if repetition_directory_template is None: repetition_directory_template = eu.REPETITION_DIRECTORY_TEMPLATE\n    repetition_directory_template = re.sub('\\{.*\\}', '*', repetition_directory_template)\n\n    experiment_descriptions = AttrDict()\n\n    exp_directories = glob(os.path.join(experiments_directory, experiment_directory_template))\n    for order, exp_directory in enumerate(np.sort(exp_directories)):\n\n        try:\n            exp_id = re.findall(r'\\d+', os.path.basename(exp_directory))[0]\n        except IndexError as err:\n            raise ValueError('The experiments_directory (\\'{}\\') seems not to have experiment folders!'.format(experiments_directory)) from err\n\n        is_add_experiment_descr = True\n        if allowed_experiments_id_list is not None and exp_id not in allowed_experiments_id_list:\n            is_add_experiment_descr = False\n        elif denied_experiments_id_list is not None and exp_id in denied_experiments_id_list:\n            is_add_experiment_descr = False\n\n        if is_add_experiment_descr:\n            experiment_descr = AttrDict()\n            experiment_descr.id = exp_id\n            experiment_descr.name = 'exp {}'.format(exp_id)\n            experiment_descr.order = order\n            experiment_descr.is_load_data = True\n            experiment_descr.directory = exp_directory\n            experiment_descr.short_name = 'e{}'.format(exp_id)\n            experiment_descr.description = ''\n\n            # find repetition directories and ids\n            repetition_directories = glob(os.path.join(exp_directory, repetition_directory_template))\n            experiment_descr.repetition_directories = repetition_directories\n            if experiment_descr.repetition_directories:\n                experiment_descr.repetition_directories.sort()\n\n            experiment_descr.repetition_ids = []\n            for rep_directory in np.sort(repetition_directories):\n                rep_id = re.findall(r'\\d+', os.path.basename(rep_directory))[0]\n                experiment_descr.repetition_ids.append(int(rep_id))\n            experiment_descr.repetition_ids.sort()\n\n            experiment_descriptions[exp_id] = experiment_descr\n\n    return experiment_descriptions\n</code></pre>"},{"location":"reference/loading/#exputils.data.loading.load_experiment_data","title":"<code>load_experiment_data</code>","text":"<p>Loads logged data from experiments and their repetitions in form of nested dictionaries and numpy arrays.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_descriptions</code> <code>AttrDict</code> <p>Predefined descriptions of the experiments. The descriptions contain the paths to all experiments and their repetitions that should be loaded. See <code>load_experiment_descriptions</code> for details. Can not be set together with experiments_directory.</p> <code>None</code> <code>experiments_directory</code> <code>str</code> <p>Path to the experiments directory. Defaults to <code>'..\\experiments'</code>. Can not be set together with experiment_descriptions.</p> <code>None</code> <code>allowed_experiments_id_list</code> <code>list</code> <p>List of allowed experiment IDs. Only these will be loaded. Can not be set together with denied_experiments_id_list.</p> <code>None</code> <code>denied_experiments_id_list</code> <code>list</code> <p>List of denied experiment IDs. All experiments besides these will be loaded. Can not be set together with allowed_experiments_id_list.</p> <code>None</code> <code>data_directory</code> <code>str</code> <p>Relative path of the data directories under the experiments and repetitions. Defaults to <code>'./data'</code>.</p> <code>None</code> <code>is_load_repetition_data</code> <code>bool</code> <p>Flag to indicate if repetition data should be loaded. Defaults to <code>True</code>.</p> <code>True</code> <code>pre_allowed_data_filter</code> <code>list</code> <p>List of datasources that will be loaded before the loading callback functions (see <code>on_experiment_data_loaded</code> and <code>on_repetition_data_loaded</code>) are called. Thus this data will be given to the callback functions. If defined then only these datasources will be loaded. The list contains strings with names of datasources.</p> <code>None</code> <code>pre_denied_data_filter</code> <code>list</code> <p>List of datasources that will NOT be loaded before the loading callback functions (see <code>on_experiment_data_loaded</code> and <code>on_repetition_data_loaded</code>) are called. Thus this data will NOT be given to the callback functions. If defined then all existing datasources besides the ones specified will be loaded. The list contains strings with names of datasources.</p> <code>None</code> <code>post_allowed_data_filter</code> <code>list</code> <p>List of datasources that will be added to the data dictionary that is returned after loading and the loading callback functions (see <code>on_experiment_data_loaded</code> and <code>on_repetition_data_loaded</code>) are called. If defined then only these datasources will be returned. The list contains strings with names of datasources.</p> <code>None</code> <code>post_denied_data_filter</code> <code>list</code> <p>List of datasources that will NOT be added to the data dictionary that is returned after loading and the loading callback functions (see <code>on_experiment_data_loaded</code> and <code>on_repetition_data_loaded</code>) are called. If defined then all existing datasources besides the ones specified will be returned. The list contains strings with names of datasources.</p> <code>None</code> <code>on_experiment_data_loaded</code> <code>list</code> <p>List of callback functions executed when experiment data is loaded. Can be used to modify the data by changing or adding elements. Form of the functions: func(exp_id: int, exp_data: AttrDict) -&gt; AttrDict.</p> <code>None</code> <code>on_repetition_data_loaded</code> <code>list</code> <p>List of callback functions executed when repetition data is loaded. Can be used to modify the data by changing or adding elements. Form of the functions: func(exp_id: int, exp_data: AttrDict) -&gt; AttrDict.</p> <code>None</code> <code>allow_pickle</code> <code>bool</code> <p>Indicates if loading of pickled objects is allowed. Defaults to True.   This could allow arbitrary code execution. Only load files you trust!</p> <code>True</code> <p>Returns:</p> Name Type Description <code>data</code> <code>AttrDict</code> <p>Loaded data.</p> <code>experiment_descriptions</code> <code>AttrDict</code> <p>Experiment descriptions of the loaded data. See <code>load_experiment_descriptions</code> for details.</p> Source code in <code>exputils/data/loading.py</code> <pre><code>def load_experiment_data(experiment_descriptions: Optional[AttrDict]=None,\n                         experiments_directory: Optional[str]=None,\n                         allowed_experiments_id_list: Optional[list]=None,\n                         denied_experiments_id_list: Optional[list]=None,\n                         data_directory: Optional[str]=None,\n                         is_load_repetition_data: bool=True,\n                         pre_allowed_data_filter: Optional[list]=None,\n                         pre_denied_data_filter: Optional[list]=None,\n                         post_allowed_data_filter: Optional[list]=None,\n                         post_denied_data_filter: Optional[list]=None,\n                         on_experiment_data_loaded: Optional[list]=None,\n                         on_repetition_data_loaded: Optional[list]=None,\n                         allow_pickle: bool = True) -&gt; tuple[AttrDict, AttrDict]:\n    \"\"\"\n    Loads logged data from experiments and their repetitions in form of nested dictionaries and numpy arrays.\n\n    [//]: # (TODO: give an example of a file structure and how it is loaded)\n\n    Parameters:\n        experiment_descriptions (AttrDict):\n            Predefined descriptions of the experiments.\n            The descriptions contain the paths to all experiments and their repetitions that should be loaded.\n            See [`load_experiment_descriptions`][exputils.data.loading.load_experiment_descriptions] for details.\n            Can not be set together with experiments_directory.\n        experiments_directory (str):\n            Path to the experiments directory.\n            Defaults to `'..\\experiments'`.\n            Can not be set together with experiment_descriptions.\n        allowed_experiments_id_list (list):\n            List of allowed experiment IDs.\n            Only these will be loaded.\n            Can not be set together with denied_experiments_id_list.\n        denied_experiments_id_list (list):\n            List of denied experiment IDs.\n            All experiments besides these will be loaded.\n            Can not be set together with allowed_experiments_id_list.\n        data_directory (str):\n            Relative path of the data directories under the experiments and repetitions.\n            Defaults to `'./data'`.\n        is_load_repetition_data (bool):\n            Flag to indicate if repetition data should be loaded.\n            Defaults to `True`.\n        pre_allowed_data_filter (list):\n            List of datasources that will be loaded before the loading callback functions\n            (see `on_experiment_data_loaded` and `on_repetition_data_loaded`) are called.\n            Thus this data will be given to the callback functions.\n            If defined then only these datasources will be loaded.\n            The list contains strings with names of datasources.\n        pre_denied_data_filter (list):\n            List of datasources that will NOT be loaded before the loading callback functions\n            (see `on_experiment_data_loaded` and `on_repetition_data_loaded`) are called.\n            Thus this data will NOT be given to the callback functions.\n            If defined then all existing datasources besides the ones specified will be loaded.\n            The list contains strings with names of datasources.\n        post_allowed_data_filter (list):\n            List of datasources that will be added to the data dictionary that is returned after\n            loading and the loading callback functions (see `on_experiment_data_loaded` and `on_repetition_data_loaded`)\n            are called.\n            If defined then only these datasources will be returned.\n            The list contains strings with names of datasources.\n        post_denied_data_filter (list):\n            List of datasources that will NOT be added to the data dictionary that is returned after\n            loading and the loading callback functions (see `on_experiment_data_loaded` and `on_repetition_data_loaded`)\n            are called.\n            If defined then all existing datasources besides the ones specified will be returned.\n            The list contains strings with names of datasources.\n        on_experiment_data_loaded (list):\n            List of callback functions executed when experiment data is loaded.\n            Can be used to modify the data by changing or adding elements.\n            Form of the functions: func(exp_id: int, exp_data: AttrDict) -&gt; AttrDict.\n        on_repetition_data_loaded (list):\n            List of callback functions executed when repetition data is loaded.\n            Can be used to modify the data by changing or adding elements.\n            Form of the functions: func(exp_id: int, exp_data: AttrDict) -&gt; AttrDict.\n        allow_pickle (bool):\n            Indicates if loading of pickled objects is allowed.\n            Defaults to True. &lt;br&gt;\n            :warning: This could allow arbitrary code execution. Only load files you trust!\n\n    Returns:\n        data (AttrDict):\n            Loaded data.\n        experiment_descriptions (AttrDict):\n            Experiment descriptions of the loaded data.\n            See [`load_experiment_descriptions`][exputils.data.loading.load_experiment_descriptions] for details.\n    \"\"\"\n\n    if experiments_directory is not None and experiment_descriptions is not None:\n        raise ValueError('Can not set experiment_directory and experiment_descriptions at the same time!')\n\n    if experiment_descriptions is not None and (allowed_experiments_id_list is not None or denied_experiments_id_list is not None):\n        raise ValueError('experiment_descriptions and (allowed_experiments_id_list or denied_experiments_id_list) can not be set at the same time!')\n\n    if allowed_experiments_id_list is not None and denied_experiments_id_list is not None:\n        raise ValueError('allowed_experiments_id_list and denied_experiments_id_list can not be set at the same time!')\n\n    if experiment_descriptions is None:\n        experiment_descriptions = load_experiment_descriptions(\n            experiments_directory=experiments_directory,\n            allowed_experiments_id_list=allowed_experiments_id_list,\n            denied_experiments_id_list=denied_experiments_id_list\n        )\n    else:\n        experiment_descriptions = experiment_descriptions\n\n    if on_experiment_data_loaded is None:\n        on_experiment_data_loaded = []\n\n    if on_repetition_data_loaded is None:\n        on_repetition_data_loaded = []\n\n    # load experiments according to the order in the experiment_descriptions\n    sorted_experiment_ids = eu.data.get_ordered_experiment_ids_from_descriptions(experiment_descriptions)\n\n    data = collections.OrderedDict()\n    for exp_id in sorted_experiment_ids:\n        exp_descr = experiment_descriptions[exp_id]\n\n        if 'is_load_data' not in exp_descr or exp_descr['is_load_data']:\n            try:\n                data[exp_id] = load_single_experiment_data(\n                    exp_descr['directory'],\n                    data_directory=data_directory,\n                    allowed_data_filter=pre_allowed_data_filter,\n                    denied_data_filter=pre_denied_data_filter,\n                    allow_pickle=allow_pickle)\n\n                for callback_function in on_experiment_data_loaded:\n                    callback_function(exp_id, data[exp_id])\n\n                _filter_data(data[exp_id], post_allowed_data_filter, post_denied_data_filter)\n\n            except FileNotFoundError:\n                if not exp_descr.repetition_ids or not is_load_repetition_data:\n                    warnings.warn('Could find data for experiment {!r} ({!r}). Skipped ...'.format(exp_id, exp_descr['directory']))\n\n            except Exception as e:\n                raise Exception('Exception during loading of data for experiment {!r} ({!r})!'.format(exp_id, exp_descr['directory'])) from e\n\n            # load data of each repetition\n            if is_load_repetition_data:\n                if eu.REPETITION_DATA_KEY in data:\n                    warnings.warn('A statistic called {!r} was loaded for experiment data. Can not store repetition data under the same data source name. Skip to load repetition data. Please rename this statistic.'.format(eu.REPETITION_DATA_KEY))\n                else:\n                    cur_rep_statistics_dict = dict()\n                    for rep_id in exp_descr.repetition_ids:\n                        cur_rep_directory = os.path.join(exp_descr['directory'], eu.REPETITION_DIRECTORY_TEMPLATE.format(rep_id))\n                        try:\n                            cur_rep_statistics_dict[rep_id] = load_single_experiment_data(\n                                cur_rep_directory,\n                                data_directory=data_directory,\n                                allowed_data_filter=pre_allowed_data_filter,\n                                denied_data_filter=pre_denied_data_filter,\n                                allow_pickle=allow_pickle)\n\n                            for callback_function in on_repetition_data_loaded:\n                                callback_function(exp_id, rep_id, cur_rep_statistics_dict[rep_id])\n\n                            _filter_data(cur_rep_statistics_dict[rep_id], post_allowed_data_filter, post_denied_data_filter)\n\n                        except FileNotFoundError:\n                            warnings.warn('Could not find data for repetition {} of experiment {!r} ({!r}). Skipped ...'.format(rep_id, exp_id, exp_descr['directory']))\n\n                        except Exception as e:\n                            raise Exception('Exception during loading of data for repetition {} of experiment {!r} ({!r})!'.format(rep_id, exp_id, exp_descr['directory'])) from e\n\n                    if cur_rep_statistics_dict:\n                        # in case no experimental level data exists\n                        if exp_id not in data:\n                            data[exp_id] = AttrDict()\n\n                        data[exp_id][eu.REPETITION_DATA_KEY] = cur_rep_statistics_dict\n\n    return data, experiment_descriptions\n</code></pre>"},{"location":"reference/loading/#exputils.data.loading.load_single_experiment_data","title":"<code>load_single_experiment_data</code>","text":"<p>Loads data for a single experiment which includes all its repetition data.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_directory</code> <code>str</code> <p>Path to the experiment directory.</p> required <code>data_directory</code> <code>str</code> <p>Relative path of the data directories under the experiments and repetitions. Defaults to <code>'./data'</code>.</p> <code>None</code> <code>allowed_data_filter</code> <code>list</code> <p>List of datasource names (strings) that will be loaded. If defined then only these datasources will be loaded.</p> <code>None</code> <code>denied_data_filter</code> <code>list</code> <p>List of datasource names (strings) that will NOT be loaded. If defined then all datasources besides the specified ones will be loaded.</p> <code>None</code> <code>allow_pickle</code> <code>bool</code> <p>Indicates if loading of pickled objects is allowed. Defaults to True.   This could allow arbitrary code execution. Only load files you trust!</p> <code>True</code> <p>Returns:</p> Name Type Description <code>data</code> <code>AttrDict</code> <p>A dictionary containing the loaded data.</p> Source code in <code>exputils/data/loading.py</code> <pre><code>def load_single_experiment_data(experiment_directory: str,\n                                data_directory: Optional[str] = None,\n                                allowed_data_filter: Optional[list] = None,\n                                denied_data_filter: Optional[list] = None,\n                                allow_pickle: bool = True) -&gt; AttrDict:\n    \"\"\"\n    Loads data for a single experiment which includes all its repetition data.\n\n    Parameters:\n        experiment_directory (str):\n            Path to the experiment directory.\n        data_directory (str):\n            Relative path of the data directories under the experiments and repetitions.\n            Defaults to `'./data'`.\n        allowed_data_filter (list):\n            List of datasource names (strings) that will be loaded.\n            If defined then only these datasources will be loaded.\n        denied_data_filter (list):\n            List of datasource names (strings) that will NOT be loaded.\n            If defined then all datasources besides the specified ones will be loaded.\n        allow_pickle (bool):\n            Indicates if loading of pickled objects is allowed.\n            Defaults to True. &lt;br&gt;\n            :warning: This could allow arbitrary code execution. Only load files you trust!\n\n    Returns:\n        data (AttrDict):\n            A dictionary containing the loaded data.\n    \"\"\"\n\n    if data_directory is None:\n        data_directory = eu.DEFAULT_DATA_DIRECTORY\n\n    # need to allow also logging to be able to load data that is in logging.npz files\n    if allowed_data_filter is not None:\n        allowed_data_filter.append('logging')\n\n    data = eu.io.load_numpy_files(\n        os.path.join(experiment_directory, data_directory),\n        allowed_data_filter=allowed_data_filter,\n        denied_data_filter=denied_data_filter,\n        allow_pickle=allow_pickle)\n\n    # TODO: Refactor - make loading of npz files without the 'logging' sub-directory as a general cases\n    if 'logging' in data:\n        data.update(data['logging'])\n        del data['logging']\n\n    return data\n</code></pre>"},{"location":"reference/loading/#exputils.data.loading.load_experiment_data_single_object","title":"<code>load_experiment_data_single_object</code>","text":"<p>Loads single object that was logged via the add_single_object. function and saved as a dill file. The file that is either located under the experiments, or a single experiment or repetition directory.</p> <p> This could allow arbitrary code execution. Only load files you trust!</p> Example <pre><code>loaded_obj = load_experiment_data_single_object(\n    'my_object',  # name of the object\n    experiment_id=100,\n    repetition_id=1\n)\nprint(loaded_obj)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the object which is the name of the dill file with or without extension.</p> required <code>experiment_id</code> <code>int</code> <p>An optional identifier for a specific experiment. If not provided, then the object is loaded from the experiments directory.</p> <code>None</code> <code>repetition_id</code> <code>int</code> <p>An optional identifier for a specific repetition of the experiment. If not provided, then the object is loaded from the experiments or experiment directory.</p> <code>None</code> <code>experiments_directory</code> <code>str</code> <p>The root directory where all experiments are stored. Defaults to <code>..\\experiments</code>.</p> <code>None</code> <code>data_directory</code> <code>str</code> <p>Relative path of the data directories under the experiments and repetitions. Defaults to <code>'./data'</code>.</p> <code>None</code> <code>experiment_directory_template</code> <code>str</code> <p>Name template of experiment directories. Defaults to <code>'experiment_{:06d}'</code>.</p> <code>None</code> <code>repetition_directory_template</code> <code>str</code> <p>Template for constructing the repetition directory. Defaults to None. Name template of repetition directories. Defaults to <code>'repetition_{:06d}'</code>.</p> <code>None</code> <code>add_execution_directory_to_sys_path</code> <code>bool</code> <p>Whether to add the execution directory to the system path temporailly while loading the object. This can be necessary if the object has relational import statements. By adding the directory where the object is located temporailly to the python path, these import statments can be processed correctly. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>object</code> <code>object</code> <p>The loaded experiment data object.</p> Source code in <code>exputils/data/loading.py</code> <pre><code>def load_experiment_data_single_object(name: str,\n                                       experiment_id: Optional[int] = None,\n                                       repetition_id: Optional[int] = None,\n                                       experiments_directory: Optional[str] = None,\n                                       data_directory: Optional[str] = None,\n                                       experiment_directory_template: Optional[str] = None,\n                                       repetition_directory_template: Optional[str] = None,\n                                       add_execution_directory_to_sys_path: bool = True) -&gt; object:\n    \"\"\"\n    Loads single object that was logged via the [add_single_object][exputils.data.logging.add_single_object].\n    function and saved as a dill file. The file that is either located under the experiments, or a\n    single experiment or repetition directory.\n\n    :warning: This could allow arbitrary code execution. Only load files you trust!\n\n    Example:\n        ```python\n        loaded_obj = load_experiment_data_single_object(\n            'my_object',  # name of the object\n            experiment_id=100,\n            repetition_id=1\n        )\n        print(loaded_obj)\n        ```\n\n    Parameters:\n        name (str):\n            The name of the object which is the name of the dill file with or without extension.\n        experiment_id (int):\n            An optional identifier for a specific experiment.\n            If not provided, then the object is loaded from the experiments directory.\n        repetition_id (int):\n            An optional identifier for a specific repetition of the experiment.\n            If not provided, then the object is loaded from the experiments or experiment directory.\n        experiments_directory (str):\n            The root directory where all experiments are stored.\n            Defaults to `..\\experiments`.\n        data_directory (str):\n            Relative path of the data directories under the experiments and repetitions.\n            Defaults to `'./data'`.\n        experiment_directory_template (str):\n            Name template of experiment directories.\n            Defaults to `'experiment_{:06d}'`.\n        repetition_directory_template (str): Template for constructing the repetition directory. Defaults to None.\n            Name template of repetition directories.\n            Defaults to `'repetition_{:06d}'`.\n        add_execution_directory_to_sys_path (bool):\n            Whether to add the execution directory to the system path temporailly while loading the object.\n            This can be necessary if the object has relational import statements.\n            By adding the directory where the object is located temporailly to the python path,\n            these import statments can be processed correctly.\n            Defaults to True.\n\n    Returns:\n        object: The loaded experiment data object.\n    \"\"\"\n\n\n    if experiments_directory is None:\n        experiments_directory = os.path.join('..', eu.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n    full_execution_dir_path = experiments_directory\n\n    # only add experiment subfolder if needed\n    if experiment_id is not None:\n\n        if experiment_directory_template is None:\n            experiment_directory_template = eu.EXPERIMENT_DIRECTORY_TEMPLATE\n\n        experiment_directory = experiment_directory_template.format(experiment_id)\n\n        full_execution_dir_path = os.path.join(full_execution_dir_path, experiment_directory)\n\n        # only add repetition subfolder if needed\n        if repetition_id is not None:\n\n            if repetition_directory_template is None:\n                repetition_directory_template = eu.REPETITION_DIRECTORY_TEMPLATE\n\n            repetition_directory = repetition_directory_template.format(repetition_id)\n\n            full_execution_dir_path = os.path.join(full_execution_dir_path, repetition_directory)\n\n    if data_directory is None:\n        data_directory = eu.DEFAULT_DATA_DIRECTORY\n\n    # construct the full path to the module\n    full_dill_path = os.path.join(full_execution_dir_path, data_directory, name)\n\n    # add the directory in which the code was executed to system path\n    if add_execution_directory_to_sys_path:\n        sys.path.append(full_execution_dir_path)\n\n    obj = eu.io.dill.load_dill(full_dill_path)\n\n    if add_execution_directory_to_sys_path:\n        sys.path.pop()\n\n    return obj\n</code></pre>"},{"location":"reference/loading/#exputils.data.loading.load_experiment_python_module","title":"<code>load_experiment_python_module</code>","text":"<p>Loads a Python module dynamically that is either located under the experiments, or a single experiment or repetition directory. This can be used to load for example the configuration file of a repetition.</p> Example <pre><code># load the configuration file of a repetition and print its config dictionary\nconfig_module = load_experiment_python_module(\n    'repetition_config.py',  # name of the configuration file\n    experiment_id=100,\n    repetition_id=3\n)\nprint(config_module.config)\n</code></pre> <p> This could allow arbitrary code execution. Only load files you trust!</p> <p>Parameters:</p> Name Type Description Default <code>module_path</code> <code>str</code> <p>The realtive path to the python module file either under the experiments, experiment, or repetition directory. Which level depends on if an experiment_id and a repetition_id are provided or not.</p> required <code>experiment_id</code> <code>int</code> <p>An optional identifier for a specific experiment. If not provided, then the module is loaded from the experiments directory.</p> <code>None</code> <code>repetition_id</code> <code>int</code> <p>An optional identifier for a specific repetition of the experiment. If not provided, then the module is loaded from the experiments or experiment directory.</p> <code>None</code> <code>experiments_directory</code> <code>str</code> <p>The root directory where all experiments are stored. Defaults to <code>..\\experiments</code>.</p> <code>None</code> <code>exec_module</code> <code>bool</code> <p>If True, the module will be executed after being loaded which means it will be imported. Defaults to True.</p> <code>True</code> <code>experiment_directory_template</code> <code>str</code> <p>Name template of experiment directories. Defaults to <code>'experiment_{:06d}'</code>.</p> <code>None</code> <code>repetition_directory_template</code> <code>str</code> <p>Template for constructing the repetition directory. Defaults to None. Name template of repetition directories. Defaults to <code>'repetition_{:06d}'</code>.</p> <code>None</code> <code>add_execution_directory_to_sys_path</code> <code>bool</code> <p>If True, the script's execution directory will be added to sys.path. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>module</code> <code>ModuleType</code> <p>The loaded Python module object.</p> Source code in <code>exputils/data/loading.py</code> <pre><code>def load_experiment_python_module(module_path: str,\n                                  experiment_id: Optional[int] = None,\n                                  repetition_id: Optional[int] = None,\n                                  experiments_directory: Optional[str] = None,\n                                  exec_module: bool = True,\n                                  experiment_directory_template: Optional[str] = None,\n                                  repetition_directory_template: Optional[str] = None,\n                                  add_execution_directory_to_sys_path: bool = True) -&gt; ModuleType:\n    \"\"\"\n    Loads a Python module dynamically that is either located under the experiments, or a single\n    experiment or repetition directory.\n    This can be used to load for example the configuration file of a repetition.\n\n    Example:\n        ```python\n        # load the configuration file of a repetition and print its config dictionary\n        config_module = load_experiment_python_module(\n            'repetition_config.py',  # name of the configuration file\n            experiment_id=100,\n            repetition_id=3\n        )\n        print(config_module.config)\n        ```\n\n    :warning: This could allow arbitrary code execution. Only load files you trust!\n\n    Parameters:\n        module_path (str):\n            The realtive path to the python module file either under the experiments, experiment, or\n            repetition directory.\n            Which level depends on if an experiment_id and a repetition_id are provided or not.\n        experiment_id (int):\n            An optional identifier for a specific experiment.\n            If not provided, then the module is loaded from the experiments directory.\n        repetition_id (int):\n            An optional identifier for a specific repetition of the experiment.\n            If not provided, then the module is loaded from the experiments or experiment directory.\n        experiments_directory (str):\n            The root directory where all experiments are stored.\n            Defaults to `..\\experiments`.\n        exec_module (bool):\n            If True, the module will be executed after being loaded which means it will be imported.\n            Defaults to True.\n        experiment_directory_template (str):\n            Name template of experiment directories.\n            Defaults to `'experiment_{:06d}'`.\n        repetition_directory_template (str): Template for constructing the repetition directory. Defaults to None.\n            Name template of repetition directories.\n            Defaults to `'repetition_{:06d}'`.\n        add_execution_directory_to_sys_path (bool):\n            If True, the script's execution directory will be added to sys.path.\n            Defaults to True.\n\n    Returns:\n        module (ModuleType): The loaded Python module object.\n\n    \"\"\"\n\n    if experiments_directory is None:\n        experiments_directory = os.path.join('..', eu.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n    full_module_path = experiments_directory\n\n    # only add experiment subfolder if needed\n    if experiment_id is not None:\n\n        if experiment_directory_template is None:\n            experiment_directory_template = eu.EXPERIMENT_DIRECTORY_TEMPLATE\n\n        experiment_directory = experiment_directory_template.format(experiment_id)\n\n        full_module_path = os.path.join(full_module_path, experiment_directory)\n\n        # only add repetition subfolder if needed\n        if repetition_id is not None:\n\n            if repetition_directory_template is None:\n                repetition_directory_template = eu.REPETITION_DIRECTORY_TEMPLATE\n\n            repetition_directory = repetition_directory_template.format(repetition_id)\n\n            full_module_path = os.path.join(full_module_path, repetition_directory)\n\n    # construct the full path to the module\n    full_module_path = os.path.join(full_module_path, module_path)\n\n    filename = os.path.basename(module_path)\n    module_name = filename.replace('.py', '')\n\n    spec = importlib.util.spec_from_file_location(module_name, full_module_path)\n\n    # creates a new module based on spec\n    module = importlib.util.module_from_spec(spec)\n\n    if exec_module:\n        # add the directory in which the code was executed to system path\n        if add_execution_directory_to_sys_path:\n            sys.path.append(os.path.dirname(full_module_path))\n\n        spec.loader.exec_module(module)\n\n        if add_execution_directory_to_sys_path:\n            sys.path.pop()\n\n    return module\n</code></pre>"},{"location":"reference/logging/","title":"Logging","text":"<p>Functions to log data for experiments.</p> <p>All functions can be accessed under the module: <code>exputils.data.logging</code></p>"},{"location":"reference/logging/#usage","title":"Usage","text":"<p>Import the logging module and directly use its functions to log values or objects.  It is not necessary to create a logging object.</p> <p>Scalars and arrays will be logged as numpy arrays in the memory.</p> <p> To write the logged values to disk it is necessary to call the save function.</p> <p>Example:     <pre><code># import the logging module as log\nimport exputils.data.logging as log\n\n# use the log to log some scalars under the name 'val'\nfor i in range(10):\n    log.add_value('val', i)\n\n# save the log, only then will the log be written from memory to a file!\nlog.save()\n</code></pre></p>"},{"location":"reference/logging/#writting","title":"Writting","text":""},{"location":"reference/logging/#exputils.data.logging.add_value","title":"<code>add_value</code>","text":"<p>Adds a value to a log entry with optional parallel TensorBoard logging.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the entry where the value is added.</p> required <code>value</code> <code>Any</code> <p>The value to be added. Can be a scalar or an array.</p> required <code>log_to_tb</code> <code>bool</code> <p>Defines of the value should be logged to TensorBoard in parallel to the standard log. If True, log the value to TensorBoard. If False, do not log the value to TensorBoard. If not specified, then it gets logged if TensorBoard is globally activated. See activate_tensorboard for more details.</p> <code>None</code> <code>tb_global_step</code> <code>int</code> <p>If logging to TensorBoard is active, then this is the global step value to record with the value in TensorBoard.</p> <code>None</code> <code>tb_walltime</code> <code>float</code> <p>If logging to TensorBoard is active, then this is an optional override for the walltime in TensorBoard.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def add_value(name: str,\n              value,\n              log_to_tb: Optional[bool] = None,\n              tb_global_step: Optional[int] = None,\n              tb_walltime: Optional[float] = None):\n    \"\"\"\n    Adds a value to a log entry with optional parallel TensorBoard logging.\n\n    Parameters:\n        name (str):\n            The name of the entry where the value is added.\n        value (Any):\n            The value to be added. Can be a scalar or an array.\n        log_to_tb (bool):\n            Defines of the value should be logged to TensorBoard in parallel to the standard log.\n            If True, log the value to TensorBoard.\n            If False, do not log the value to TensorBoard.\n            If not specified, then it gets logged if TensorBoard is globally activated.\n            See [activate_tensorboard][exputils.data.logging.activate_tensorboard] for more details.\n        tb_global_step (int):\n            If logging to TensorBoard is active, then this is the global step value to record with\n            the value in TensorBoard.\n        tb_walltime (float):\n            If logging to TensorBoard is active, then this is an optional override for the walltime\n            in TensorBoard.\n    \"\"\"\n    log.add_value(name, value, log_to_tb, tb_global_step, tb_walltime)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.add_scalar","title":"<code>add_scalar</code>","text":"<p>Adds a scalar value to a log entry with optional parallel TensorBoard logging.</p> <p>Note: Has the same functionality as add_value and exists to have a similar named log function as TensorBoard.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the entry where the value is added.</p> required <code>scalar</code> <code>Any</code> <p>The scalar value to be added.</p> required <code>log_to_tb</code> <code>bool</code> <p>Defines of the value should be logged to TensorBoard in parallel to the standard log. If True, log the value to TensorBoard. If False, do not log the value to TensorBoard. If not specified, then it gets logged if TensorBoard is globally activated. See activate_tensorboard for more details.</p> <code>None</code> <code>tb_global_step</code> <code>int</code> <p>If logging to TensorBoard is active, then this is the global step value to record with the value in TensorBoard.</p> <code>None</code> <code>tb_walltime</code> <code>float</code> <p>If logging to TensorBoard is active, then this is an optional override for the walltime in TensorBoard.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def add_scalar(name: str,\n              scalar,\n              log_to_tb: Optional[bool] = None,\n              tb_global_step: Optional[int] = None,\n              tb_walltime: Optional[float] = None):\n    \"\"\"\n    Adds a scalar value to a log entry with optional parallel TensorBoard logging.\n\n    Note: Has the same functionality as [add_value][exputils.data.logging.add_value] and exists to\n    have a similar named log function as TensorBoard.\n\n    Parameters:\n        name (str):\n            The name of the entry where the value is added.\n        scalar (Any):\n            The scalar value to be added.\n        log_to_tb (bool):\n            Defines of the value should be logged to TensorBoard in parallel to the standard log.\n            If True, log the value to TensorBoard.\n            If False, do not log the value to TensorBoard.\n            If not specified, then it gets logged if TensorBoard is globally activated.\n            See [activate_tensorboard][exputils.data.logging.activate_tensorboard] for more details.\n        tb_global_step (int):\n            If logging to TensorBoard is active, then this is the global step value to record with\n            the value in TensorBoard.\n        tb_walltime (float):\n            If logging to TensorBoard is active, then this is an optional override for the walltime\n            in TensorBoard.\n    \"\"\"\n    log.add_scalar(name, scalar, log_to_tb, tb_global_step, tb_walltime)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.add_histogram","title":"<code>add_histogram</code>","text":"<p>Adds a histogram which is a one-dimensional array a log entry with optional parallel TensorBoard logging.</p> <p>This allows to add the values as a histogram plot to TensorBoard.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the entry where the value is added.</p> required <code>values</code> <code>Any</code> <p>The array of values to be added.</p> required <code>log_to_tb</code> <code>bool</code> <p>Defines of the value should be logged to TensorBoard in parallel to the standard log. If True, log the value to TensorBoard. If False, do not log the value to TensorBoard. If not specified, then it gets logged if TensorBoard is globally activated. See activate_tensorboard for more details.</p> <code>None</code> <code>tb_global_step</code> <code>int</code> <p>If logging to TensorBoard is active, then this is the global step value to record with the value in TensorBoard.</p> <code>None</code> <code>tb_walltime</code> <code>float</code> <p>If logging to TensorBoard is active, then this is an optional override for the walltime in TensorBoard.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def add_histogram(name: str,\n                  values,\n                  log_to_tb: Optional[bool] = None,\n                  tb_global_step: Optional[int] = None,\n                  tb_walltime: Optional[float] = None):\n    \"\"\"\n    Adds a histogram which is a one-dimensional array a log entry with optional parallel TensorBoard\n    logging.\n\n    This allows to add the values as a histogram plot to TensorBoard.\n\n    Parameters:\n        name (str):\n            The name of the entry where the value is added.\n        values (Any):\n            The array of values to be added.\n        log_to_tb (bool):\n            Defines of the value should be logged to TensorBoard in parallel to the standard log.\n            If True, log the value to TensorBoard.\n            If False, do not log the value to TensorBoard.\n            If not specified, then it gets logged if TensorBoard is globally activated.\n            See [activate_tensorboard][exputils.data.logging.activate_tensorboard] for more details.\n        tb_global_step (int):\n            If logging to TensorBoard is active, then this is the global step value to record with\n            the value in TensorBoard.\n        tb_walltime (float):\n            If logging to TensorBoard is active, then this is an optional override for the walltime\n            in TensorBoard.\n    \"\"\"\n    log.add_histogram(name, values, log_to_tb, tb_global_step, tb_walltime)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.add_object","title":"<code>add_object</code>","text":"<p>Adds an object to a log entry. Objects are stored in a list and saved as dill files.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the log entry where the object is added.</p> required <code>obj</code> <code>object</code> <p>The object to be added to the log.</p> required Source code in <code>exputils/data/logging.py</code> <pre><code>def add_object(name: str,\n               obj: object):\n    \"\"\"\n    Adds an object to a log entry. Objects are stored in a list and saved as dill files.\n\n    Parameters:\n        name (str):\n            The name of the log entry where the object is added.\n        obj (object):\n            The object to be added to the log.\n    \"\"\"\n    log.add_object(name, obj)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.add_single_object","title":"<code>add_single_object</code>","text":"<p>Logs a single object which is directly written to a dill file and not stored in memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the object which is used for the filename.</p> required <code>obj</code> <code>object</code> <p>The object to be logged.</p> required <code>directory</code> <code>str</code> <p>Optional directory path where the dill file for the object is saved. Default is the log directory.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def add_single_object(name: str,\n                      obj: object,\n                      directory: Optional[str] = None):\n    \"\"\"\n    Logs a single object which is directly written to a dill file and not stored in memory.\n\n    Parameters:\n        name (str):\n            The name of the object which is used for the filename.\n        obj (object):\n            The object to be logged.\n        directory (str):\n            Optional directory path where the dill file for the object is saved.\n            Default is the log directory.\n    \"\"\"\n    log.add_single_object(name, obj, directory=directory)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.save","title":"<code>save</code>","text":"<p>Saves the log. All logged values are stored in memory and only written to disk when this function is called.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Optional directory path where the dill file for the object is saved. Default is the log directory.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def save(directory: Optional[str] = None):\n    \"\"\"\n    Saves the log.\n    All logged values are stored in memory and only written to disk when this function is called.\n\n    Parameters:\n        directory (str):\n            Optional directory path where the dill file for the object is saved.\n            Default is the log directory.\n    \"\"\"\n    log.save(directory=directory)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.clear","title":"<code>clear</code>","text":"<p>Clears the data of all or a specific log entry.</p> <p> Data that has been logged after the save function was called will be lost.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the log entry. If no name is given, then all log entries will be cleared.</p> <code>None</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def clear(name: Optional[str] = None):\n    \"\"\"\n    Clears the data of all or a specific log entry.\n\n    :warning: Data that has been logged after the [save][exputils.data.logging.save] function\n    was called will be lost.\n\n    Parameters:\n        name (str):\n            Name of the log entry.\n            If no name is given, then all log entries will be cleared.\n    \"\"\"\n    log.clear(name=name)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.reset","title":"<code>reset</code>","text":"<p>Resets the log which deletes all data in the memory and resets all changed configuration such as the directory path of the log.</p> <p> Data that has been logged after the save function was called will be lost.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def reset():\n    \"\"\"\n    Resets the log which deletes all data in the memory and resets all changed configuration such\n    as the directory path of the log.\n\n    :warning: Data that has been logged after the [save][exputils.data.logging.save] function\n    was called will be lost.\n    \"\"\"\n    global log\n    log = Logger()\n</code></pre>"},{"location":"reference/logging/#reading","title":"Reading","text":"<p>Values that were logged can also be accessed. It is also possible to load a complete log from disk. This can be used to continue experiment and add new values to an existing log.</p>"},{"location":"reference/logging/#exputils.data.logging.contains","title":"<code>contains</code>","text":"<p>Check if a log entry for the given name exists.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to be checked in the log.</p> required <p>Returns:</p> Name Type Description <code>is_contained</code> <code>bool</code> <p>True if a log for the name exists, otherwise False.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def contains(name: str) -&gt; bool:\n    \"\"\"\n    Check if a log entry for the given name exists.\n\n    Parameters:\n        name (str): The name to be checked in the log.\n\n    Returns:\n        is_contained (bool): True if a log for the name exists, otherwise False.\n    \"\"\"\n    return (name in log)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.items","title":"<code>items</code>","text":"<p>Returns all log entries as a list of tuples with the name and values of the entries.</p> <p>Returns:</p> Name Type Description <code>entries</code> <code>list</code> <p>All logged entries.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def items() -&gt; list:\n    \"\"\"\n    Returns all log entries as a list of tuples with the name and values of the entries.\n\n    Returns:\n        entries (list): All logged entries.\n    \"\"\"\n    return log.items()\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.get_item","title":"<code>get_item</code>","text":"<p>Returns the logged data for a certain entry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the log entry.</p> required <p>Returns:</p> Type Description <code>object</code> <p>Logged data. Usually in form of a numpy array.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def get_item(name: str) -&gt; object:\n    \"\"\"\n    Returns the logged data for a certain entry.\n\n    Parameters:\n        name (str):\n            Name of the log entry.\n\n    Returns:\n        Logged data. Usually in form of a numpy array.\n    \"\"\"\n    return log[name]\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.get_values","title":"<code>get_values</code>","text":"<p>Returns the logged data for a certain entry.</p> <p>Note: Has the same functionality as get_item and exists to have a similar named log function as TensorBoard.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the log entry.</p> required <p>Returns:</p> Type Description <p>Logged data. Usually in form of a numpy array.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def get_values(name: str):\n    \"\"\"\n    Returns the logged data for a certain entry.\n\n    Note: Has the same functionality as [get_item][exputils.data.logging.get_item] and exists to\n    have a similar named log function as TensorBoard.\n\n    Parameters:\n        name (str):\n            Name of the log entry.\n\n    Returns:\n        Logged data. Usually in form of a numpy array.\n    \"\"\"\n    return log[name]\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.get_objects","title":"<code>get_objects</code>","text":"<p>Returns the logged objects for a certain entry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the log entry.</p> required <p>Returns:</p> Name Type Description <code>objects</code> <code>list</code> <p>Logged objects.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def get_objects(name: str) -&gt; list:\n    \"\"\"\n    Returns the logged objects for a certain entry.\n\n    Args:\n        name (str): Name of the log entry.\n\n    Returns:\n        objects (list): Logged objects.\n    \"\"\"\n    return log[name]\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.load","title":"<code>load</code>","text":"<p>Loads entries from a log directory into the log. Afterwards the loaded entries can be accessed via the items and get_item functions.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Optional directory path where the dill file for the object is saved. Default is the log directory.</p> <code>None</code> <code>load_objects</code> <code>bool</code> <p>True if objects (dill files) that are in the directory should also be loaded. Default is False to avoid unintended large loads of objects.</p> <code>False</code> Source code in <code>exputils/data/logging.py</code> <pre><code>def load(directory: Optional[str] = None,\n         load_objects: bool = False):\n    \"\"\"\n    Loads entries from a log directory into the log.\n    Afterwards the loaded entries can be accessed via the [items][exputils.data.logging.items] and\n    [get_item][exputils.data.logging.get_item] functions.\n\n    Parameters:\n        directory (str):\n            Optional directory path where the dill file for the object is saved.\n            Default is the log directory.\n        load_objects (bool):\n            True if objects (dill files) that are in the directory should also be loaded.\n            Default is False to avoid unintended large loads of objects.\n    \"\"\"\n    log.load(directory=directory, load_objects=load_objects)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.load_single_object","title":"<code>load_single_object</code>","text":"<p>Loads a single object from the log folder and returns it. The object is not stored in the log memory.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the object which is used for the filename. Either with or without the <code>'.dill'</code> extension.</p> required <p>Returns:</p> Name Type Description <code>obj</code> <code>object</code> <p>Loaded object.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def load_single_object(name: str) -&gt; object:\n    \"\"\"\n    Loads a single object from the log folder and returns it.\n    The object is not stored in the log memory.\n\n    Parameters:\n        name (str):\n            Name of the object which is used for the filename.\n            Either with or without the `'.dill'` extension.\n\n    Returns:\n        obj (object): Loaded object.\n    \"\"\"\n    return log.load_single_object(name)\n</code></pre>"},{"location":"reference/logging/#tensorboard","title":"Tensorboard","text":"<p>The log has the ability to log values in parallel to Tensorboard which can be used to visualize them while an experiment is running.</p>"},{"location":"reference/logging/#exputils.data.logging.tensorboard","title":"<code>tensorboard</code>","text":"<p>Returns the tensorboard SummaryWriter object used to log values to TensorBoard.</p> <p>Returns:</p> Name Type Description <code>writer</code> <code>SummaryWriter</code> <p>TensorBoard SummaryWriter object.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def tensorboard():\n    \"\"\"\n    Returns the tensorboard SummaryWriter object used to log values to TensorBoard.\n\n    Returns:\n        writer (SummaryWriter): TensorBoard SummaryWriter object.\n    \"\"\"\n    return log.tensorboard\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.create_tensorboard","title":"<code>create_tensorboard</code>","text":"<p>Creates the SummaryWriter object used to log values to TensorBoard. This allows to set its configuration parameters.</p> <p>For more details see: https://pytorch.org/docs/stable/tensorboard.html</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Optional dictionary with the configuration of the SummaryWriter. Has the same entries as the set of \"Other Parameters\" below.</p> <code>None</code> <p>Other Parameters:</p> Name Type Description <code>log_dir</code> <code>str</code> <p>Directly location of the TensorBoard log files. Default is <code>experiments/tensorboard_logs/exp_\\&lt;experiment_id&gt;/rep_\\&lt;repetition_id&gt;/\\&lt;date&gt;_\\&lt;time&gt;.</code></p> <code>purge_step</code> <code>int</code> <p>When logging crashes at step T+XT+XT+X and restarts at step TTT, any events whose global_step larger or equal to TTT will be purged and hidden from TensorBoard. Note that crashed and resumed experiments should have the same log_dir.</p> <code>max_queue</code> <code>int</code> <p>Size of the queue for pending events and summaries before one of the \u2018add\u2019 calls forces a flush to disk. (default = 10)</p> <code>flush_secs</code> <code>int</code> <p>How often, in seconds, to flush the pending events and summaries to disk. (default = 120)</p> <code>filename_suffix</code> <code>string</code> <p>Suffix added to all event filenames in the log_dir directory. (default = '.tblog')</p> <p>Returns:</p> Name Type Description <code>writer</code> <code>SummaryWriter</code> <p>TensorBoard SummaryWriter object.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def create_tensorboard(config: Optional[dict] = None,\n                       **kwargs):\n    \"\"\"\n    Creates the SummaryWriter object used to log values to TensorBoard.\n    This allows to set its configuration parameters.\n\n    For more details see: https://pytorch.org/docs/stable/tensorboard.html\n\n    Parameters:\n        config (dict):\n            Optional dictionary with the configuration of the SummaryWriter.\n            Has the same entries as the set of \"Other Parameters\" below.\n\n    Other Parameters:\n        log_dir (str):\n            Directly location of the TensorBoard log files.\n            Default is `experiments/tensorboard_logs/exp_\\&lt;experiment_id&gt;/rep_\\&lt;repetition_id&gt;/\\&lt;date&gt;_\\&lt;time&gt;.`\n        purge_step (int):\n            When logging crashes at step T+XT+XT+X and restarts at step TTT, any events whose\n            global_step larger or equal to TTT will be purged and hidden from TensorBoard.\n            Note that crashed and resumed experiments should have the same log_dir.\n        max_queue (int):\n            Size of the queue for pending events and summaries before one of the \u2018add\u2019 calls forces\n            a flush to disk. (default = 10)\n        flush_secs (int):\n            How often, in seconds, to flush the pending events and summaries to disk. (default = 120)\n        filename_suffix (string):\n            Suffix added to all event filenames in the log_dir directory. (default = '.tblog')\n\n    Returns:\n        writer (SummaryWriter): TensorBoard SummaryWriter object.\n    \"\"\"\n\n    return log.create_tensorboard(config=config, **kwargs)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.activate_tensorboard","title":"<code>activate_tensorboard</code>","text":"<p>Activates parallel TensorBoard logging. When it is activated, then the logging functions ( add_value, add_scalar, add_histogram) will automatically log each value also in TensorBoard if not otherwise specified for them.</p> <p>Creates a TensorBoard SummaryWriter if non is created yet with the create_tensorboard function. If non is created then the configureation of the writer can be defined by the parameters of this function. For more details see: https://pytorch.org/docs/stable/tensorboard.html</p> <p>Other Parameters:</p> Name Type Description <code>log_dir</code> <code>str</code> <p>Directly location of the TensorBoard log files. Default is <code>experiments/tensorboard_logs/exp_\\&lt;experiment_id&gt;/rep_\\&lt;repetition_id&gt;/\\&lt;date&gt;_\\&lt;time&gt;.</code></p> <code>purge_step</code> <code>int</code> <p>When logging crashes at step T+XT+XT+X and restarts at step TTT, any events whose global_step larger or equal to TTT will be purged and hidden from TensorBoard. Note that crashed and resumed experiments should have the same log_dir.</p> <code>max_queue</code> <code>int</code> <p>Size of the queue for pending events and summaries before one of the \u2018add\u2019 calls forces a flush to disk. (default = 10)</p> <code>flush_secs</code> <code>int</code> <p>How often, in seconds, to flush the pending events and summaries to disk. (default = 120)</p> <code>filename_suffix</code> <code>string</code> <p>Suffix added to all event filenames in the log_dir directory. (default = '.tblog')</p> <p>Returns:</p> Name Type Description <code>writer</code> <code>SummaryWriter</code> <p>TensorBoard SummaryWriter object.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def activate_tensorboard(config: Optional[dict] = None,\n                         **kwargs):\n    \"\"\"\n    Activates parallel TensorBoard logging.\n    When it is activated, then the logging functions (\n    [add_value][exputils.data.logging.add_value],\n    [add_scalar][exputils.data.logging.add_scalar],\n    [add_histogram][exputils.data.logging.add_histogram])\n    will automatically log each value also in TensorBoard if not otherwise specified for them.\n\n    Creates a TensorBoard SummaryWriter if non is created yet with the [create_tensorboard][exputils.data.logging.create_tensorboard] function.\n    If non is created then the configureation of the writer can be defined by the parameters of this function.\n    For more details see: https://pytorch.org/docs/stable/tensorboard.html\n\n    Other Parameters:\n        log_dir (str):\n            Directly location of the TensorBoard log files.\n            Default is `experiments/tensorboard_logs/exp_\\&lt;experiment_id&gt;/rep_\\&lt;repetition_id&gt;/\\&lt;date&gt;_\\&lt;time&gt;.`\n        purge_step (int):\n            When logging crashes at step T+XT+XT+X and restarts at step TTT, any events whose\n            global_step larger or equal to TTT will be purged and hidden from TensorBoard.\n            Note that crashed and resumed experiments should have the same log_dir.\n        max_queue (int):\n            Size of the queue for pending events and summaries before one of the \u2018add\u2019 calls forces\n            a flush to disk. (default = 10)\n        flush_secs (int):\n            How often, in seconds, to flush the pending events and summaries to disk. (default = 120)\n        filename_suffix (string):\n            Suffix added to all event filenames in the log_dir directory. (default = '.tblog')\n\n    Returns:\n        writer (SummaryWriter): TensorBoard SummaryWriter object.\n    \"\"\"\n\n    return log.activate_tensorboard(config=config, **kwargs)\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.deactivate_tensorboard","title":"<code>deactivate_tensorboard</code>","text":"<p>Deactivates tensorboard logging. Afterwards, values will not be automatically logged via the add_value / add_scalar function to the tensorboard.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def deactivate_tensorboard():\n    \"\"\"\n    Deactivates tensorboard logging.\n    Afterwards, values will not be automatically logged via the add_value / add_scalar function\n    to the tensorboard.\n    \"\"\"\n    return log.deactivate_tensorboard()\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.is_tensorboard_active","title":"<code>is_tensorboard_active</code>","text":"<p>Returns true, if the tensorboard is active.</p> <p>Returns:</p> Name Type Description <code>is_active</code> <code>bool</code> <p>True if the tensorboard is active, otherwise False.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def is_tensorboard_active() -&gt; bool:\n    \"\"\"Returns true, if the tensorboard is active.\n\n    Returns:\n        is_active (bool): True if the tensorboard is active, otherwise False.\n    \"\"\"\n    return log.is_tensorboard_active\n</code></pre>"},{"location":"reference/logging/#configuration","title":"Configuration","text":"<p>To configure the default directory the logging is using.</p>"},{"location":"reference/logging/#exputils.data.logging.set_directory","title":"<code>set_directory</code>","text":"<p>Sets the directory path under which the logs will be saved. The default is <code>./data</code>.</p> <p>If the directory does not exist it will be created.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Path to the directory.</p> required Source code in <code>exputils/data/logging.py</code> <pre><code>def set_directory(directory: str):\n    \"\"\"\n    Sets the directory path under which the logs will be saved.\n    The default is `./data`.\n\n    If the directory does not exist it will be created.\n\n    Parameters:\n        directory (str):\n            Path to the directory.\n\n    \"\"\"\n    log.directory = directory\n</code></pre>"},{"location":"reference/logging/#exputils.data.logging.get_directory","title":"<code>get_directory</code>","text":"<p>Returns the path to the directory the log.</p> <p>Returns:</p> Name Type Description <code>directory</code> <code>str</code> <p>Path to the directory.</p> Source code in <code>exputils/data/logging.py</code> <pre><code>def get_directory() -&gt; str:\n    \"\"\"\n    Returns the path to the directory the log.\n\n    Returns:\n        directory (str):\n            Path to the directory.\n    \"\"\"\n    return log.directory\n</code></pre>"},{"location":"reference/manage/","title":"Manage","text":"<p>Functions to manage the generation and execution of experiments.</p> <p>All functions can be accessed under the module: <code>exputils.manage</code></p> <p>Experiments are recommended to be stored in a specific folder structure which allows to save and load experimental data in a structured manner. Please note that it represents a default structure which can be adapted if required. Elements in brackets (&lt;custom name&gt;) can have custom names. </p> <p>Folder structure:</p> <ul> <li>&lt;experiments&gt; folder: Holds all your campaigns.<ul> <li>&lt;experimental campaign&gt; folders:<ul> <li>&lt;analyze&gt; folder: Scripts such as Jupyter notebooks to analyze the different experiments in this experimental campaign. </li> <li>experiment_configurations.ods file: ODS file that contains the configuration parameters of the different experiments in this campaign.</li> <li>src folder: Holds code templates of the experiments.<ul> <li>rep folder: Code templates that are used under the repetition folders of th experiments. These contain the acutal experimental code that should be run.</li> <li>exp folder: Code templates that are used under the experiment folder of the experiment. These contain usually code to compute statistics over all repetitions of an experiment.</li> </ul> </li> <li>experiments folder: Contains generated code for experiments and the collected experimental data.<ul> <li>experiment_{id} folders:<ul> <li>repetition_{id} folders:<ul> <li>data folder: Experimental data for the single repetitions, such as logs.</li> <li>code files: Generated code and resource files.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/manage/#generation-execution","title":"Generation &amp; Execution","text":""},{"location":"reference/manage/#exputils.manage.experimentgenerator.generate_experiment_files","title":"<code>generate_experiment_files</code>","text":"<p>Generates experiments based on a configuration ODS file (LibreOffice Spreadsheet) and template source code.</p> <p>The configuration ODS has to be in a specific form. See <code>resources/experiment_configurations.ods</code> for an example file.</p> <p>The template source code is usually located in <code>.\\src\\exp</code> for code on the experiment level and <code>.\\src\\rep</code> for code on the repetition level.</p> <p>Parameters:</p> Name Type Description Default <code>ods_filepath</code> <code>str</code> <p>Path to the ODS configuration file that defines the experiments. Default is <code>'./experiment_configurations.ods'</code></p> <code>None</code> <code>directory</code> <code>str</code> <p>Path to directory where the experiments will be generated. Default is <code>'./experiments'</code>.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Should verbose output with more information given. Default is <code>False</code>.</p> <code>False</code> <code>copy_operator</code> <code>str</code> <p>Define the copy operator for source code files. Either 'shutil' (default) for the python copy function or 'cp' for the linux terminal cp operator. The choice of the 'cp' copy operator was introduced as for some OS systems the 'shutil' did not work under python 3.8.</p> <code>'shutil'</code> <p>Notes:</p> <ul> <li>Sheets in the configuration ODS file define groups of experiments for which an extra    subfolder in the output directory will be generated.</li> </ul> Source code in <code>exputils/manage/experimentgenerator.py</code> <pre><code>def generate_experiment_files(ods_filepath: Optional[str] = None,\n                              directory: Optional[str] = None,\n                              extra_files: Optional[list] = None,\n                              extra_experiment_files: Optional[list] = None,\n                              verbose: bool = False,\n                              copy_operator: str = 'shutil'):\n    \"\"\"\n    Generates experiments based on a configuration ODS file (LibreOffice Spreadsheet) and template\n    source code.\n\n    The configuration ODS has to be in a specific form.\n    See `resources/experiment_configurations.ods` for an example file.\n\n    The template source code is usually located in `.\\src\\exp` for code on the experiment level\n    and `.\\src\\\\rep` for code on the repetition level.\n\n    [//]: # (TODO: either remove or document the options for extra-files)\n\n    Parameters:\n        ods_filepath (str):\n            Path to the ODS configuration file that defines the experiments.\n            Default is `'./experiment_configurations.ods'`\n        directory (str):\n            Path to directory where the experiments will be generated.\n            Default is `'./experiments'`.\n        verbose (bool):\n            Should verbose output with more information given. Default is `False`.\n        copy_operator (str):\n            Define the copy operator for source code files. Either 'shutil' (default) for the python\n            copy function or 'cp' for the linux terminal cp operator. The choice of the 'cp' copy\n            operator was introduced as for some OS systems the 'shutil' did not work under python 3.8.\n\n    Notes:\n\n    - Sheets in the configuration ODS file define groups of experiments for which an extra\n       subfolder in the output directory will be generated.\n    \"\"\"\n\n    if ods_filepath is None:\n        ods_filepath = os.path.join('.', exputils.DEFAULT_ODS_CONFIGURATION_FILE)\n\n    if directory is None:\n        directory = os.path.join('.',exputils. DEFAULT_EXPERIMENTS_DIRECTORY)\n    elif directory == '':\n        directory = '.'\n\n    if verbose:\n        print('Load config from {!r} ...'.format(ods_filepath))\n\n    config_data = _load_configuration_data_from_ods(ods_filepath)\n\n    # generate experiment files based on the loaded configurations\n    if verbose:\n        print('Generate experiments ...'.format(ods_filepath))\n\n    _generate_files_from_config(\n        config_data, directory,\n        extra_files=extra_files, extra_experiment_files=extra_experiment_files, verbose=verbose, copy_operator=copy_operator\n    )\n</code></pre>"},{"location":"reference/manage/#exputils.manage.experimentstarter.start_experiments","title":"<code>start_experiments</code>","text":"<p>Searches all the start scripts of experiments and/or repetitions in the experiments folder and executes them either in parallel or sequentially.</p> <p>It also documents their execution status (todo, running, finished, error) in a status file that allows it to identify if a script should be executed or not when used again on the same target directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Directory in which the start scripts are searched. Default is <code>'./experiments'</code>.</p> <code>None</code> <code>start_scripts</code> <code>str</code> <p>Filename of the start script file that are searched under the given target directory. Can include '' to search for scripts, for example 'run_.py'. The default <code>'run_*'</code> will look for all files that start with 'run' and try to start them.</p> <code>'run_*.py'</code> <code>parallel</code> <code>(bool, int)</code> <p>Defines if scripts should be started in parallel and how many are allowed to run in parallel. If <code>False</code> then the scripts are started sequentially one after another. If <code>True</code> then the scripts are started and executed in parallel all at once. If an integer, then the number defines how many scripts can run in parallel.</p> <code>True</code> <code>is_chdir</code> <code>bool</code> <p>Before starting a script, should the main process change to its working directory.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>Should verbose output with more information given. Default is <code>False</code>.</p> <code>False</code> <code>post_start_wait_time</code> <code>float</code> <p>Time waited before one process is started after another.</p> <code>0.0</code> <code>write_status_files_automatically</code> <code>bool</code> <p>Should status files that document if scripts were started and executed be written by the manager. These are important to identify if an experiment or repetition did run already.</p> <code>True</code> Source code in <code>exputils/manage/experimentstarter.py</code> <pre><code>def start_experiments(directory: Optional[str] = None,\n                      start_scripts: Optional[str] = 'run_*.py',\n                      start_command: Optional[str] = '{}',\n                      parallel: Union[bool, int] = True,\n                      is_chdir: bool = True,\n                      verbose: bool = False,\n                      post_start_wait_time: float = 0.,\n                      write_status_files_automatically: bool = True):\n    \"\"\"\n    Searches all the start scripts of experiments and/or repetitions in the experiments folder\n    and executes them either in parallel or sequentially.\n\n    It also documents their execution status (todo, running, finished, error) in a status file\n    that allows it to identify if a script should be executed or not when used again on the\n    same target directory.\n\n    Parameters:\n        directory (str):\n            Directory in which the start scripts are searched.\n            Default is `'./experiments'`.\n        start_scripts (str):\n            Filename of the start script file that are searched under the given target directory.\n            Can include '*' to search for scripts, for example 'run_*.py'.\n            The default `'run_*'` will look for all files that start with 'run' and try to start them.\n        parallel (bool, int):\n            Defines if scripts should be started in parallel and how many are allowed to run in parallel.\n            If `False` then the scripts are started sequentially one after another.\n            If `True` then the scripts are started and executed in parallel all at once.\n            If an integer, then the number defines how many scripts can run in parallel.\n        is_chdir (bool):\n            Before starting a script, should the main process change to its working directory.\n        verbose (bool):\n            Should verbose output with more information given. Default is `False`.\n        post_start_wait_time (float):\n            Time waited before one process is started after another.\n        write_status_files_automatically (bool):\n            Should status files that document if scripts were started and executed be\n            written by the manager. These are important to identify if an experiment or repetition\n            did run already.\n    \"\"\"\n\n    if directory is None:\n        directory = os.path.join('.', exputils.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n    # handle number of parallel processes\n    if isinstance(parallel, bool):\n        if parallel:\n            n_parallel = np.inf\n        else:\n            n_parallel = 1\n    elif isinstance(parallel, int):\n        if parallel &lt;= 0:\n            raise ValueError('Number of parallel processes must be larger 0!')\n        else:\n            n_parallel = parallel\n    else:\n        raise ValueError('Argument \\'parallel\\' must be either a bool or an integer number!')\n\n    if is_chdir:\n        cwd = os.getcwd()\n\n    # get all scripts\n    all_scripts = get_scripts(directory=directory, start_scripts=start_scripts)\n\n    ignored_scripts = []\n    todo_scripts = []\n    # check their initial status and write one for the scripts that will be started\n    for script in all_scripts:\n\n        # lock processing of the script, so that no other running experimentstarter is updating its status in parallel\n        with _get_script_lock(script):\n\n            status = get_script_status(script)\n\n            if status is None:\n                if write_status_files_automatically:\n                    _update_script_status(script, 'todo')\n                todo_scripts.append(script)\n\n            elif status.lower() != 'finished':\n                todo_scripts.append(script)\n\n            else:\n                ignored_scripts.append((script, status))\n\n    # start all in parallel if wanted\n    if n_parallel == np.inf:\n        n_parallel = len(todo_scripts)\n\n    # started process and their corresponding scripts\n    started_processes = []\n    started_scripts = []\n    finished_processes_idxs = []\n\n    next_todo_script_idx = 0\n    n_active_processes = 0\n\n    # run as long as there is an active process or we did not finish all processes yet\n    while n_active_processes &gt; 0 or next_todo_script_idx &lt; len(todo_scripts):\n\n        # start as many processes as parallel processes are allowed\n        for i in range(n_parallel - n_active_processes):\n\n            # stop starting processes when all scripts are started\n            if next_todo_script_idx &lt; len(todo_scripts):\n\n                script = todo_scripts[next_todo_script_idx]\n                next_todo_script_idx += 1\n\n                # lock processing of the script, so that no other running experimentstarter is starting it in parallel\n                with _get_script_lock(script):\n\n                    # check the script status, only start if needed\n                    status = get_script_status(script)\n                    if _is_to_start_status(status):\n\n                        if write_status_files_automatically:\n                            _update_script_status(script, 'running')\n\n                        # start\n                        script_directory = os.path.dirname(script)\n                        script_path_in_its_working_directory = os.path.join('.', os.path.basename(script))\n\n                        print('{} start {!r} (previous status: {}) ...'.format(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"), script, status))\n\n                        process_environ = {\n                            **os.environ,\n                            \"EU_STATUS_FILE\": script_path_in_its_working_directory + STATUS_FILE_EXTENSION,\n                        }\n\n                        if is_chdir:\n                            os.chdir(script_directory)\n                            process = subprocess.Popen(start_command.format(script_path_in_its_working_directory).split(), env=process_environ)\n                            os.chdir(cwd)\n                        else:\n                            process = subprocess.Popen(start_command.format(script).split(), cwd=script_directory, env=process_environ)\n\n                        started_processes.append(process)\n                        started_scripts.append(script)\n\n                        if post_start_wait_time &gt; 0:\n                            time.sleep(post_start_wait_time)\n\n                    else:\n                        # do not start\n                        ignored_scripts.append((script, status))\n\n        # check the activity of the started processes\n        n_active_processes = 0\n        for p_idx, process in enumerate(started_processes):\n\n            if p_idx not in finished_processes_idxs:\n\n                if process.poll() is None:\n                    n_active_processes += 1\n                else:\n                    finished_processes_idxs.append(p_idx)\n                    if process.returncode == 0:\n                        status = 'finished'\n                    else:\n                        status = 'error'\n\n                    if write_status_files_automatically:\n                        _update_script_status(started_scripts[p_idx], status)\n\n                    print('{} finished {!r} (status: {})'.format(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"), started_scripts[p_idx], status))\n\n        if n_active_processes &gt; 0:\n            time.sleep(0.5) # sleep half a second before checking again\n\n    if verbose:\n        if ignored_scripts:\n            print('Ignored scripts:')\n            for (script_path, status) in ignored_scripts:\n                print('\\t- {!r} (status: {})'.format(script_path, status))\n</code></pre>"},{"location":"reference/manage/#helper","title":"Helper","text":"<p>A couple of extra functions exist that can be used to determine how to best start experiments. For example by identifying how many scripts need to be executed and asking a cluster manager to  provide to required resources such as the number of cores.</p>"},{"location":"reference/manage/#exputils.manage.experimentstarter.get_scripts","title":"<code>get_scripts</code>","text":"<p>Searches all start scripts in the experiments directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Directory in which the start scripts are searched. Default is <code>'./experiments'</code>.</p> <code>None</code> <code>start_scripts</code> <code>str</code> <p>Filename of the start script file that are searched under the given target directory. Can include '' to search for scripts, for example 'run_.py'. The default <code>'run_*'</code> will look for all files that start with 'run' and try to start them.</p> <code>'run_*.py'</code> <p>Returns:</p> Name Type Description <code>scripts</code> <code>list</code> <p>List of filepaths to the start scripts.</p> Source code in <code>exputils/manage/experimentstarter.py</code> <pre><code>def get_scripts(directory: Optional[str] = None,\n                start_scripts: Optional[str] = 'run_*.py') -&gt; list:\n    \"\"\"\n    Searches all start scripts in the experiments directory.\n\n    Parameters:\n        directory (str):\n            Directory in which the start scripts are searched.\n            Default is `'./experiments'`.\n        start_scripts (str):\n            Filename of the start script file that are searched under the given target directory.\n            Can include '*' to search for scripts, for example 'run_*.py'.\n            The default `'run_*'` will look for all files that start with 'run' and try to start them.\n\n    Returns:\n        scripts (list): List of filepaths to the start scripts.\n    \"\"\"\n\n    if directory is None:\n        directory = os.path.join('.', exputils.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n    # find all start scripts\n    scripts = glob.iglob(os.path.join(directory, '**', start_scripts), recursive=True)\n    scripts = list(scripts)\n    scripts.sort()\n\n    return scripts\n</code></pre>"},{"location":"reference/manage/#exputils.manage.experimentstarter.get_script_status","title":"<code>get_script_status</code>","text":"<p>Returns the execution status of a certain start script.</p> <p>Parameters:</p> Name Type Description Default <code>script_file</code> <code>str</code> <p>Path to the script file.</p> required <p>Returns:</p> Name Type Description <code>status</code> <code>(str, None)</code> <p>Status as a string. Usually <code>'todo'</code>, <code>'error'</code>, <code>'running'</code>, or <code>'finished'</code>. <code>None</code> if no status exists.</p> Source code in <code>exputils/manage/experimentstarter.py</code> <pre><code>def get_script_status(script_file: str) -&gt; Optional[str]:\n    \"\"\"\n    Returns the execution status of a certain start script.\n\n    Parameters:\n        script_file (str): Path to the script file.\n\n    Returns:\n        status (str, None):\n            Status as a string. Usually `'todo'`, `'error'`, `'running'`, or `'finished'`.\n            `None` if no status exists.\n    \"\"\"\n    status = None\n\n    status_file_path = script_file + STATUS_FILE_EXTENSION\n\n    if os.path.isfile(status_file_path):\n        # read status\n        with open(status_file_path, 'r') as f:\n            lines = f.read().splitlines()\n            if len(lines) &gt; 0:\n                status = lines[-1]\n\n    return status\n</code></pre>"},{"location":"reference/manage/#exputils.manage.experimentstarter.get_number_of_scripts","title":"<code>get_number_of_scripts</code>","text":"<p>Identifies the number of all scripts in the experiments directory regardless of their execution status.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Directory in which the start scripts are searched. Default is <code>'./experiments'</code>.</p> <code>None</code> <code>start_scripts</code> <code>str</code> <p>Filename of the start script file that are searched under the given target directory. Can include '' to search for scripts, for example 'run_.py'. The default <code>'run_*'</code> will look for all files that start with 'run' and try to start them.</p> <code>'run_*.py'</code> <p>Returns:</p> Name Type Description <code>n_scripts</code> <code>int</code> <p>Number of scripts.</p> Source code in <code>exputils/manage/experimentstarter.py</code> <pre><code>def get_number_of_scripts(directory: Optional[str] = None,\n                          start_scripts: str = 'run_*.py'):\n    \"\"\"\n    Identifies the number of all scripts in the experiments directory regardless of their execution\n    status.\n\n    Parameters:\n        directory (str):\n            Directory in which the start scripts are searched.\n            Default is `'./experiments'`.\n        start_scripts (str):\n            Filename of the start script file that are searched under the given target directory.\n            Can include '*' to search for scripts, for example 'run_*.py'.\n            The default `'run_*'` will look for all files that start with 'run' and try to start them.\n\n    Returns:\n        n_scripts (int): Number of scripts.\n    \"\"\"\n\n    scripts = get_scripts(directory=directory, start_scripts=start_scripts)\n    return len(scripts)\n</code></pre>"},{"location":"reference/manage/#exputils.manage.experimentstarter.get_number_of_scripts_to_execute","title":"<code>get_number_of_scripts_to_execute</code>","text":"<p>Identifies the number of scripts that have to be executed in the experiments directory. Scripts that have to be executed have either the status 'none', 'todo', 'error', or 'unfinished'.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str</code> <p>Directory in which the start scripts are searched. Default is <code>'./experiments'</code>.</p> <code>None</code> <code>start_scripts</code> <code>str</code> <p>Filename of the start script file that are searched under the given target directory. Can include '' to search for scripts, for example 'run_.py'. The default <code>'run_*'</code> will look for all files that start with 'run' and try to start them.</p> <code>'run_*.py'</code> <p>Returns:</p> Name Type Description <code>n_scripts</code> <code>int</code> <p>Number of scripts that have to be executed.</p> Source code in <code>exputils/manage/experimentstarter.py</code> <pre><code>def get_number_of_scripts_to_execute(directory: Optional[str] = None,\n                                     start_scripts: str = 'run_*.py') -&gt; int:\n    \"\"\"\n    Identifies the number of scripts that have to be executed in the experiments directory.\n    Scripts that have to be executed have either the status 'none', 'todo', 'error', or 'unfinished'.\n\n    Parameters:\n        directory (str):\n            Directory in which the start scripts are searched.\n            Default is `'./experiments'`.\n        start_scripts (str):\n            Filename of the start script file that are searched under the given target directory.\n            Can include '*' to search for scripts, for example 'run_*.py'.\n            The default `'run_*'` will look for all files that start with 'run' and try to start them.\n\n    Returns:\n        n_scripts (int): Number of scripts that have to be executed.\n    \"\"\"\n\n    scripts = get_scripts(directory=directory, start_scripts=start_scripts)\n\n    n = 0\n    for script in scripts:\n        status = get_script_status(script)\n        if _is_to_start_status(status):\n            n += 1\n\n    return n\n</code></pre>"},{"location":"reference/overview/","title":"Overview","text":"<p>The exputils package has several submodules that are organized according to functionality. The submodules must not be imported individually. After importing the <code>exputils</code> module all can be accessed through it.</p> <p>List of submodules:</p> <ul> <li><code>exputils</code>: Basic functionality that contain the <code>AttrDict</code>      to define experiment configurations and functions that help to use the configuration.</li> <li><code>exputils.manage</code>: Functions to generate experiments from a configuration template and to execute them with support      for parallel execution. See the Manage section for details.</li> <li><code>exputils.data</code>: Functions that are data related, such as Logging and Loading of experiment data.</li> <li><code>exputils.gui.jupyter</code>: Widgets and plotting functions to load and plot logged data in Jupyter notebook.     See the Visualization section for details.</li> <li><code>exputils.io</code>: Basic IO helper functions which are used by the exputils package.     They are usually not needed to log or load data which is done with the functions under the <code>exputils.data</code> module. </li> <li><code>exputils.misc</code>: Various helper functions used by the exputils package. Not yet documented.</li> </ul> <p>Note: As this is a one-person development project, not all functionality is documented yet. In question, please refer directly to the source code or contact me.</p>"},{"location":"reference/overview/#basic-functions","title":"Basic Functions","text":""},{"location":"reference/overview/#exputils.misc.attrdict.AttrDict","title":"<code>AttrDict</code>","text":"<p>               Bases: <code>dict</code></p> <p>A dictionary that provides attribute-style access. Can be used to configure experiments.</p> <p>Example: <pre><code>&gt;&gt;&gt; b = AttrDict()\n&gt;&gt;&gt; b.hello = 'world'\n&gt;&gt;&gt; b.hello\n'world'\n&gt;&gt;&gt; b['hello'] += \"!\"\n&gt;&gt;&gt; b.hello\n'world!'\n&gt;&gt;&gt; b.foo = AttrDict(lol=True)\n&gt;&gt;&gt; b.foo.lol\nTrue\n&gt;&gt;&gt; b.foo is b['foo']\nTrue\nA AttrDict is a subclass of dict; it supports all the methods a dict does...\n&gt;&gt;&gt; sorted(b.keys())\n['foo', 'hello']\nIncluding update()...\n&gt;&gt;&gt; b.update({ 'ponies': 'are pretty!' }, hello=42)\n&gt;&gt;&gt; print (repr(b))\nAttrDict({'ponies': 'are pretty!', 'foo': Munch({'lol': True}), 'hello': 42})\nAs well as iteration...\n&gt;&gt;&gt; sorted([ (k,b[k]) for k in b ])\n[('foo', AttrDict({'lol': True})), ('hello', 42), ('ponies', 'are pretty!')]\nAnd \"splats\".\n&gt;&gt;&gt; \"The {knights} who say {ni}!\".format(**AttrDict(knights='lolcats', ni='can haz'))\n'The lolcats who say can haz!'\n</code></pre></p> Source code in <code>exputils/misc/attrdict.py</code> <pre><code>class AttrDict(dict):\n    \"\"\" A dictionary that provides attribute-style access. Can be used to configure experiments.\n\n    Example:\n    ```python\n    &gt;&gt;&gt; b = AttrDict()\n    &gt;&gt;&gt; b.hello = 'world'\n    &gt;&gt;&gt; b.hello\n    'world'\n    &gt;&gt;&gt; b['hello'] += \"!\"\n    &gt;&gt;&gt; b.hello\n    'world!'\n    &gt;&gt;&gt; b.foo = AttrDict(lol=True)\n    &gt;&gt;&gt; b.foo.lol\n    True\n    &gt;&gt;&gt; b.foo is b['foo']\n    True\n    A AttrDict is a subclass of dict; it supports all the methods a dict does...\n    &gt;&gt;&gt; sorted(b.keys())\n    ['foo', 'hello']\n    Including update()...\n    &gt;&gt;&gt; b.update({ 'ponies': 'are pretty!' }, hello=42)\n    &gt;&gt;&gt; print (repr(b))\n    AttrDict({'ponies': 'are pretty!', 'foo': Munch({'lol': True}), 'hello': 42})\n    As well as iteration...\n    &gt;&gt;&gt; sorted([ (k,b[k]) for k in b ])\n    [('foo', AttrDict({'lol': True})), ('hello', 42), ('ponies', 'are pretty!')]\n    And \"splats\".\n    &gt;&gt;&gt; \"The {knights} who say {ni}!\".format(**AttrDict(knights='lolcats', ni='can haz'))\n    'The lolcats who say can haz!'\n    ```\n    \"\"\"\n\n    # only called if k not found in normal places\n    def __getattr__(self, k):\n        \"\"\" Gets key if it exists, otherwise throws AttributeError.\n\n        nb. __getattr__ is only called if key is not found in normal places.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; b = AttrDict(bar='baz', lol={})\n            &gt;&gt;&gt; b.foo\n            Traceback (most recent call last):\n                ...\n            AttributeError: foo\n            &gt;&gt;&gt; b.bar\n            'baz'\n            &gt;&gt;&gt; getattr(b, 'bar')\n            'baz'\n            &gt;&gt;&gt; b['bar']\n            'baz'\n            &gt;&gt;&gt; b.lol is b['lol']\n            True\n            &gt;&gt;&gt; b.lol is getattr(b, 'lol')\n            True\n        ```\n        \"\"\"\n        try:\n            # Throws exception if not in prototype chain\n            return object.__getattribute__(self, k)\n        except AttributeError:\n            try:\n                return self[k]\n            except KeyError:\n                raise AttributeError(k)\n\n\n    def __setattr__(self, k, v):\n        \"\"\" Sets attribute k if it exists, otherwise sets key k. A KeyError\n            raised by set-item (only likely if you subclass Munch) will\n            propagate as an AttributeError instead.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; b = AttrDict(foo='bar', this_is='useful when subclassing')\n            &gt;&gt;&gt; hasattr(b.values, '__call__')\n            True\n            &gt;&gt;&gt; b.values = 'uh oh'\n            &gt;&gt;&gt; b.values\n            'uh oh'\n            &gt;&gt;&gt; b['values']\n            Traceback (most recent call last):\n                ...\n            KeyError: 'values'\n        ```\n        \"\"\"\n        try:\n            # Throws exception if not in prototype chain\n            object.__getattribute__(self, k)\n        except AttributeError:\n            try:\n                self[k] = v\n            except:\n                raise AttributeError(k)\n        else:\n            object.__setattr__(self, k, v)\n\n\n    def __delattr__(self, k):\n        \"\"\" Deletes attribute k if it exists, otherwise deletes key k. A KeyError\n            raised by deleting the key--such as when the key is missing--will\n            propagate as an AttributeError instead.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; b = AttrDict(lol=42)\n            &gt;&gt;&gt; del b.lol\n            &gt;&gt;&gt; b.lol\n            Traceback (most recent call last):\n                ...\n            AttributeError: lol\n        ```\n        \"\"\"\n        try:\n            # Throws exception if not in prototype chain\n            object.__getattribute__(self, k)\n        except AttributeError:\n            try:\n                del self[k]\n            except KeyError:\n                raise AttributeError(k)\n        else:\n            object.__delattr__(self, k)\n\n\n    def toDict(self):\n        \"\"\" Recursively converts a munch back into a dictionary.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; b = AttrDict(foo=AttrDict(lol=True), hello=42, ponies='are pretty!')\n            &gt;&gt;&gt; sorted(b.toDict().items())\n            [('foo', {'lol': True}), ('hello', 42), ('ponies', 'are pretty!')]\n            See unmunchify for more info.\n        ```\n        \"\"\"\n        return attrdict_to_dict(self)\n\n\n    @property\n    def __dict__(self):\n        return self.toDict()\n\n\n    def __repr__(self):\n        \"\"\" Invertible string-form of a Munch.\n\n        (Invertible so long as collection contents are each repr-invertible.)\n\n        Example:\n        ```python\n            &gt;&gt;&gt; b = AttrDict(foo=AttrDict(lol=True), hello=42, ponies='are pretty!')\n            &gt;&gt;&gt; print (repr(b))\n            Munch({'ponies': 'are pretty!', 'foo': Munch({'lol': True}), 'hello': 42})\n            &gt;&gt;&gt; eval(repr(b))\n            Munch({'ponies': 'are pretty!', 'foo': Munch({'lol': True}), 'hello': 42})\n            &gt;&gt;&gt; with_spaces = AttrDict({1: 2, 'a b': 9, 'c': AttrDict({'simple': 5})})\n            &gt;&gt;&gt; print (repr(with_spaces))\n            Munch({'a b': 9, 1: 2, 'c': Munch({'simple': 5})})\n            &gt;&gt;&gt; eval(repr(with_spaces))\n            Munch({'a b': 9, 1: 2, 'c': Munch({'simple': 5})})\n        ```\n        \"\"\"\n        return '{0}({1})'.format(self.__class__.__name__, dict.__repr__(self))\n\n\n    def __dir__(self):\n        return list(iterkeys(self))\n\n\n    def __getstate__(self):\n        \"\"\" Implement a serializable interface used for pickling.\n        See https://docs.python.org/3.6/library/pickle.html.\n        \"\"\"\n        return {k: v for k, v in self.items()}\n\n\n    def __setstate__(self, state):\n        \"\"\" Implement a serializable interface used for pickling.\n        See https://docs.python.org/3.6/library/pickle.html.\n        \"\"\"\n        self.clear()\n        self.update(state)\n\n\n    __members__ = __dir__  # for python2.x compatibility\n\n\n    def __eq__(self, other):\n        '''Is the dict equal to another dict. Allows to compare numpy arrays.'''\n        return exputils.misc.dict_equal(self, other)\n\n\n    @classmethod\n    def from_dict(cls, d):\n        \"\"\" Recursively transforms a dictionary into a AttrDict via copy.\n            &gt;&gt;&gt; b = AttrDict.from_dict({'urmom': {'sez': {'what': 'what'}}})\n            &gt;&gt;&gt; b.urmom.sez.what\n            'what'\n            See dict_to_attrdict for more info.\n        \"\"\"\n        return dict_to_attrdict(d, cls)\n\n\n    def copy(self):\n        return type(self).from_dict(self)\n\n\n    def to_json(self, **options):\n        \"\"\" Serializes this AttrDict to JSON. Accepts the same keyword options as `json.dumps()`.\n            &gt;&gt;&gt; b = AttrDict(foo=AttrDict(lol=True), hello=42, ponies='are pretty!')\n            &gt;&gt;&gt; json.dumps(b) == b.to_json()\n            True\n\n            Allows to dump numpy arrays into JSON.\n        \"\"\"\n\n        # allow to dump numpy into json\n        if 'cls' not in options:\n            options['cls'] = exputils.io.json.ExputilsJSONEncoder\n\n        return json.dumps(self, **options)\n\n\n    @classmethod\n    def from_json(cls, json_data, is_transform_ints=True, **options):\n        \"\"\" Loads an AttrDict from JSON. Accepts the same keyword options as `json.loads()`.\"\"\"\n\n        # allow to load numpy from json\n        if 'cls' not in options:\n            options['object_hook'] = exputils.io.json.exputils_json_object_hook\n\n        loaded_json = json.loads(json_data, **options)\n\n        # chenge possible int keys to ints as json changes ints to strings\n        if is_transform_ints:\n            loaded_json = exputils.io.convert_json_dict_keys_to_ints(loaded_json)\n\n        return dict_to_attrdict(loaded_json, cls)\n\n\n    def to_json_file(self, filepath, **options):\n        exputils.io.save_dict_as_json_file(self, filepath, **options)\n\n\n    @classmethod\n    def from_json_file(cls, filepath, **options):\n        loaded_dict = exputils.io.load_dict_from_json_file(filepath, **options)\n        return dict_to_attrdict(loaded_dict, cls)\n\n\n    def to_yaml(self, path) -&gt; None:\n\n        with open(path, 'w') as output_file:\n            yaml.dump(self.toDict(), output_file)\n\n    @classmethod\n    def from_yaml(cls, filepath, **options):\n        with open(filepath, 'r') as config_file:\n            loaded_dict = yaml.load(config_file.read(),\n                                    yaml.FullLoader)\n        return dict_to_attrdict(loaded_dict, cls)\n</code></pre>"},{"location":"reference/overview/#exputils.misc.attrdict.combine_dicts","title":"<code>combine_dicts</code>","text":"<p>Combines several AttrDicts recursively. This can be used to combine a given configuration with a default configuration.</p> Example <p><pre><code>import exputils as eu\n\ndict_a = eu.AttrDict(name='a', x_val=1)\ndict_b = eu.AttrDict(name='default', x_val=0, y_val=0)\n\ncomb_dict = eu.combine_dicts(dict_a, dict_b)\n\nprint(comb_dict)\n</code></pre> Output: <pre><code>AttrDict({'name': 'a', 'x_val': 1, 'y_val': 0})\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Dictionaries that should be combined. The order is important as a dictionary that is given first overwrites the values of properties of all following dictionaries.</p> <code>()</code> <code>is_recursive</code> <code>bool</code> <p>Should the dictionaries be recursively combined?</p> <code>True</code> <code>copy_mode</code> <code>str</code> <p>Defines how the properties of the dictionaries should be copied ('deepcopy', 'copy', 'none') to the combined dictionary.</p> <code>'deepcopy'</code> <p>Returns:</p> Name Type Description <code>comb_dict</code> <code>AttrDict</code> <p>Combined AttrDict.</p> Source code in <code>exputils/misc/attrdict.py</code> <pre><code>def combine_dicts(*args,\n                  is_recursive: bool = True,\n                  copy_mode: str = 'deepcopy') -&gt; AttrDict:\n    \"\"\"\n    Combines several AttrDicts recursively.\n    This can be used to combine a given configuration with a default configuration.\n\n    Example:\n        ```python\n        import exputils as eu\n\n        dict_a = eu.AttrDict(name='a', x_val=1)\n        dict_b = eu.AttrDict(name='default', x_val=0, y_val=0)\n\n        comb_dict = eu.combine_dicts(dict_a, dict_b)\n\n        print(comb_dict)\n        ```\n        Output:\n        ```\n        AttrDict({'name': 'a', 'x_val': 1, 'y_val': 0})\n        ```\n\n    Parameters:\n        *args:\n            Dictionaries that should be combined.\n            The order is important as a dictionary that is given first overwrites the values of\n            properties of all following dictionaries.\n        is_recursive (bool):\n            Should the dictionaries be recursively combined?\n        copy_mode:\n            Defines how the properties of the dictionaries should be copied ('deepcopy', 'copy', 'none')\n            to the combined dictionary.\n\n    Returns:\n        comb_dict (AttrDict): Combined AttrDict.\n    \"\"\"\n\n    args = list(args)\n\n    # convert arguments to AttrDicts if they are not\n    for idx in range(len(args)):\n        if args[idx] is None:\n            args[idx] = AttrDict()\n        elif not isinstance(args[idx], AttrDict):\n            args[idx] = AttrDict.from_dict(args[idx])\n\n    # copy the dictionaries according to copy mode\n    dicts = []\n    for dict in args:\n        if copy_mode.lower() == 'deepcopy':\n            dicts.append(deepcopy(dict))\n        elif copy_mode.lower() == 'copy':\n            dicts.append(dict.copy())\n        elif copy_mode is None or copy_mode.lower() == 'none':\n            dicts.append(dict)\n        else:\n            raise ValueError('Unknown copy mode {!r}!'.format(copy_mode))\n\n    # combine the dicts going from last to first\n    for dict_idx in range(len(args)-1, 0, -1):\n\n        for def_key, def_item in dicts[dict_idx].items():\n\n            if not def_key in dicts[dict_idx-1]:\n                # add default item if not found target\n                dicts[dict_idx - 1][def_key] = def_item\n            elif (is_recursive\n                  and isinstance(def_item, Mapping)\n                  and isinstance(dicts[dict_idx - 1][def_key], Mapping)):\n                # If the value is a dictionary in the default and the target, then also set default\n                # values for it.\n                dicts[dict_idx - 1][def_key] = combine_dicts(dicts[dict_idx - 1][def_key],\n                                                             def_item,\n                                                             is_recursive=is_recursive,\n                                                             copy_mode=copy_mode)\n\n    return dicts[0]\n</code></pre>"},{"location":"reference/overview/#exputils.misc.misc.create_object_from_config","title":"<code>create_object_from_config</code>","text":"<p>Creates a class object that is defined as a config dictionary or AttrDict.</p> <p>The configuration dictionary must contain a 'cls' property that holds the class type. All other properties are used as parameters for the constructor of the object.</p> Example <p><pre><code>import exputils as eu\nfrom collections import Counter\n\nconfig = eu.AttrDict()\nconfig.cls = Counter  # class type that should be created\nconfig.green=2\nconfig.blue=1\n\n# creates the Counter object using: obj = Counter(red=3, green=2, blue=1)\nobj = eu.create_object_from_config(config, red=3)\n\nprint(obj)\n</code></pre> Output: <pre><code>Counter({'red': 3, 'green': 2, 'blue': 1})\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary with <code>cls</code> property that holds the class type.</p> required <code>*args</code> <p>Additional arguments to pass to the constructor of the object.</p> <code>()</code> <code>*argv</code> <p>Additional arguments to pass to the constructor of the object.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>obj</code> <code>object</code> <p>The resulting object.</p> Source code in <code>exputils/misc/misc.py</code> <pre><code>def create_object_from_config(config: dict, *args, **argv):\n    \"\"\"\n    Creates a class object that is defined as a config dictionary or AttrDict.\n\n    The configuration dictionary must contain a 'cls' property that holds the class type.\n    All other properties are used as parameters for the constructor of the object.\n\n    Example:\n        ```python\n        import exputils as eu\n        from collections import Counter\n\n        config = eu.AttrDict()\n        config.cls = Counter  # class type that should be created\n        config.green=2\n        config.blue=1\n\n        # creates the Counter object using: obj = Counter(red=3, green=2, blue=1)\n        obj = eu.create_object_from_config(config, red=3)\n\n        print(obj)\n        ```\n        Output:\n        ```\n        Counter({'red': 3, 'green': 2, 'blue': 1})\n        ```\n\n    Parameters:\n        config (dict): Configuration dictionary with `cls` property that holds the class type.\n        *args: Additional arguments to pass to the constructor of the object.\n        *argv: Additional arguments to pass to the constructor of the object.\n\n    Returns:\n        obj (object): The resulting object.\n    \"\"\"\n    return call_function_from_config(config, *args, func_attribute_name='cls', **argv)\n</code></pre>"},{"location":"reference/overview/#exputils.misc.misc.call_function_from_config","title":"<code>call_function_from_config</code>","text":"<p>Calls a function that is defined as a config dictionary or AttrDict.</p> <p>The configuration dictionary must contain a property that holds the function handle. This is by default called <code>func</code>, but can be differently defined using the <code>func_attribute_name</code> parameter. All other properties of the configuration dictionary are used as parameters for the function call.</p> <p>If the given <code>config</code> argument is a function handle, then this function is called and the given args and *argvs given as arguments. If the given <code>config</code> argument is not a dictionary or a function handle, then it is directly returned.</p> Example <p><pre><code>import exputils as eu\n\ndef calc_area(length, width, unit='sm'):\n    area = length * width\n    return f\"{area} {unit}\"\n\nconfig = eu.AttrDict()\nconfig.func = calc_area  # function that should be called\nconfig.unit = 'square meters'\n\n# calls the function with: calc_area(length=3, width=4, unit='square meters')\nout = eu.call_function_from_config(config, length=3, width=4)\n\nprint(out)\n</code></pre> Output: <pre><code>'12 square meters'\n</code></pre></p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary func property that holds the function handle.</p> required <code>func_attribute_name</code> <code>str</code> <p>Name of the func attribute.</p> <code>'func'</code> <code>*args</code> <p>Additional arguments to pass to the function.</p> <code>()</code> <code>*argv</code> <p>Additional arguments to pass to the function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>res</code> <code>Any</code> <p>The return value of the function.</p> Source code in <code>exputils/misc/misc.py</code> <pre><code>def call_function_from_config(config, *args, func_attribute_name='func', **argv):\n    \"\"\"Calls a function that is defined as a config dictionary or AttrDict.\n\n    The configuration dictionary must contain a property that holds the function handle. This is\n    by default called `func`, but can be differently defined using the `func_attribute_name` parameter.\n    All other properties of the configuration dictionary are used as parameters for the function call.\n\n    If the given `config` argument is a function handle, then this function is called and the given\n    *args and **argvs given as arguments.\n    If the given `config` argument is not a dictionary or a function handle, then it is directly\n    returned.\n\n    Example:\n        ```python\n        import exputils as eu\n\n        def calc_area(length, width, unit='sm'):\n            area = length * width\n            return f\"{area} {unit}\"\n\n        config = eu.AttrDict()\n        config.func = calc_area  # function that should be called\n        config.unit = 'square meters'\n\n        # calls the function with: calc_area(length=3, width=4, unit='square meters')\n        out = eu.call_function_from_config(config, length=3, width=4)\n\n        print(out)\n        ```\n        Output:\n        ```\n        '12 square meters'\n        ```\n\n    Parameters:\n        config (dict): Configuration dictionary func property that holds the function handle.\n        func_attribute_name (str): Name of the func attribute.\n        *args: Additional arguments to pass to the function.\n        *argv: Additional arguments to pass to the function.\n\n    Returns:\n        res (Any): The return value of the function.\n    \"\"\"\n\n    if isinstance(config, dict) and func_attribute_name in config:\n\n        func_handle = config[func_attribute_name]\n\n        function_arguments = copy.deepcopy(config)\n        del function_arguments[func_attribute_name]\n        function_arguments = combine_dicts(argv, function_arguments)\n\n        return func_handle(*args, **function_arguments)\n\n    elif callable(config):\n        return config(*args, **argv)\n\n    else:\n        return config\n</code></pre>"},{"location":"reference/overview/#exputils.misc.misc.seed","title":"<code>seed</code>","text":"<p>Sets the random seed for random, numpy and pytorch (if it is installed).</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>(int, dict)</code> <p>Seed (integer) or a configuration dictionary which contains a 'seed' property. If <code>None</code> is given, a random seed is chosen.</p> <code>None</code> <code>is_set_random</code> <code>bool</code> <p>Should the random seed of the python <code>random</code> package be set.</p> <code>True</code> <code>is_set_numpy</code> <code>bool</code> <p>Should random seed of <code>numpy.random</code> be set.</p> <code>True</code> <code>is_set_torch</code> <code>bool</code> <p>Should random seed of torch be set.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>seed</code> <code>int</code> <p>Integer that was used as seed.</p> Source code in <code>exputils/misc/misc.py</code> <pre><code>def seed(seed: Optional[Union[int, dict]] = None,\n         is_set_random: bool = True,\n         is_set_numpy: bool = True,\n         is_set_torch: bool = True) -&gt; int:\n    \"\"\"\n    Sets the random seed for random, numpy and pytorch (if it is installed).\n\n    Parameters:\n        seed (int, dict):\n            Seed (integer) or a configuration dictionary which contains a 'seed' property.\n            If `None` is given, a random seed is chosen.\n        is_set_random (bool):\n            Should the random seed of the python `random` package be set.\n        is_set_numpy (bool):\n            Should random seed of `numpy.random` be set.\n        is_set_torch:\n            Should random seed of torch be set.\n\n    Returns:\n        seed (int): Integer that was used as seed.\n    \"\"\"\n\n    if seed is None:\n        if torch:\n            seed = torch.seed()\n        else:\n            seed = np.randint(2**32)\n\n    elif isinstance(seed, dict):\n        seed = seed.get('seed', None)\n\n    if is_set_numpy:\n        np.random.seed(seed)\n\n    if is_set_random:\n        random.seed(seed)\n\n    if torch:\n        if is_set_torch:\n            torch.manual_seed(seed)\n\n    return seed\n</code></pre>"},{"location":"reference/overview/#exputils.misc.misc.update_status","title":"<code>update_status</code>","text":"<p>Updates the status of the running experiment/repetition in its status file.</p> <p>Parameters:</p> Name Type Description Default <code>status</code> <code>str</code> <p>Status in form of a string.</p> required <code>status_file</code> <code>str</code> <p>Optional path to the status file. By default, it is the status file of the running process.</p> <code>None</code> Source code in <code>exputils/misc/misc.py</code> <pre><code>def update_status(status: str,\n                  status_file: Optional[str] = None):\n    \"\"\"\n    Updates the status of the running experiment/repetition in its status file.\n\n    Parameters:\n        status (str): Status in form of a string.\n        status_file (str):\n            Optional path to the status file.\n            By default, it is the status file of the running process.\n    \"\"\"\n\n    if status_file is None:\n        status_file = os.environ.get('EU_STATUS_FILE', default=None)\n\n    if status_file is None or status_file == '':\n        warnings.warn('Can not find status file location to update its status.')\n    else:\n        time_str = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n        with open(status_file, 'a+') as file:\n            file.write(time_str + \"\\n\" + \"running \" + status + \"\\n\")\n</code></pre>"},{"location":"reference/overview/#default-variables","title":"Default Variables","text":"<p>The package has a list of default variables located on the module level that mainly control the names of the generated  directories. They can be adjusted if needed.</p> Name Type Description Default <code>DEFAULT_ODS_CONFIGURATION_FILE</code> <code>str</code> Filename of the ODS configuration file for campaigns. <code>'experiment_configurations.ods'</code> <code>DEFAULT_EXPERIMENTS_DIRECTORY</code> <code>str</code> Name of the directory in the campaign directory under which experiment directories are created. <code>'experiments'</code> <code>EXPERIMENT_DIRECTORY_TEMPLATE</code> <code>str</code> Name template of experiment directories. Has to contain a placeholder for the ID. <code>'experiment_{:06d}'</code> <code>REPETITION_DIRECTORY_TEMPLATE</code> <code>str</code> Name template of repetition directories. Has to contain a placeholder for the ID. <code>'repetition_{:06d}'</code> <code>DEFAULT_DATA_DIRECTORY</code> <code>str</code> Name of the directory that is used to store the logs under each repetition. <code>'data'</code> <code>REPETITION_DATA_KEY</code> <code>str</code> Keyname of the element in the <code>AttrDict</code> returned by the <code>load_experiment_data</code> function that holds all the repetition data. <code>'repetition_data'</code> <p>To customize them they can be changed after the exputils package as been imported: <pre><code>import exputils as eu\n# use a shorter form for experiment and repetition directories\neu.EXPERIMENT_DIRECTORY_TEMPLATE = 'exp_{:06d}' \neu.REPETITION_DIRECTORY_TEMPLATE = 'rep_{:06d}'\n</code></pre></p>"},{"location":"reference/visualization/","title":"Jupyter Visualization","text":"<p>Jupyter notebook can be used to visualize the logged data.  For this purpose, several Jupyter widgets and plotting functions based on plotly and tabulate are provided.</p> <p>All widgets and functions can be accessed under the module: <code>exputils.gui.jupyter</code></p> <p>Please note that the current widgets only work with Jupyter Notebook &lt;= 6.5 and are also not compatible with Jupyter Lab.</p>"},{"location":"reference/visualization/#general-widgets","title":"General Widgets","text":""},{"location":"reference/visualization/#exputils.gui.jupyter.experiment_data_loader_widget.ExperimentDataLoaderWidget","title":"<code>ExperimentDataLoaderWidget</code>","text":"<p>               Bases: <code>BaseWidget</code>, <code>VBox</code></p> <p>Jupyter widget for loading experiment data which can then be used for analysis and visualization.</p> <p>The widget allows to select which experiments and datasources are loaded. The widget provides basically a GUI for the load_experiment_data function. It is also possible to define callback functions that allow to compute statistics of the loaded data or alter the data. After the user loaded the data through the widget it is available via its <code>experiment_data</code> property.</p> <p>GUI of the widget:</p> <p>Functionality:</p> <ul> <li>Update Descriptions: Load the descriptions of new experiments. This can be used to update the table after more experiments have been performed.</li> <li>Reset Descriptions: Resets the descriptions of experiments in the table to their default if they had been changed by the user.</li> <li>Up Button: Moves the selected experiments up in the order.</li> <li>Down Button: Moves the selected experiments down in the order.</li> <li>Sort by Experiment ID: Resorts the experiments according to their ID.</li> <li>Load Data: Loads the data of all selected experiments. It is then available via the <code>experiment_data</code> property.</li> <li>Empty Data: Empties the loaded data to free memory.</li> </ul> Example <p>Execute the following code in a Jupyter notebook located in the experiment campaign directory under a subdirectory, such as <code>./analysis</code>. <pre><code>import exputils as eu\n\nexperiment_data_loader = eu.gui.jupyter.ExperimentDataLoaderWidget()\ndisplay(experiment_data_loader)\n</code></pre> To access the experiment data after the user has loaded it through the widget: <pre><code>experiment_data_loader.experiment_data\n</code></pre></p> Source code in <code>exputils/gui/jupyter/experiment_data_loader_widget.py</code> <pre><code>class ExperimentDataLoaderWidget(BaseWidget, ipywidgets.VBox):\n    \"\"\"\n        Jupyter widget for loading experiment data which can then be used for analysis and visualization.\n\n        The widget allows to select which experiments and datasources are loaded.\n        The widget provides basically a GUI for the [load_experiment_data][exputils.data.load_experiment_data] function.\n        It is also possible to define callback functions that allow to compute statistics of the\n        loaded data or alter the data.\n        After the user loaded the data through the widget it is available via its `experiment_data` property.\n\n        GUI of the widget:\n        &lt;figure markdown=\"span\"&gt;\n          ![ExperimentDataLoaderWidget](../assets/images/experiment_data_loader_widget.png)\n        &lt;/figure&gt;\n\n        Functionality:\n\n        - _Update Descriptions_: Load the descriptions of new experiments.\n        This can be used to update the table after more experiments have been performed.\n        - _Reset Descriptions_: Resets the descriptions of experiments in the table to their default if they had been changed by the user.\n        - _Up Button_: Moves the selected experiments up in the order.\n        - _Down Button_: Moves the selected experiments down in the order.\n        - _Sort by Experiment ID_: Resorts the experiments according to their ID.\n        - _Load Data_: Loads the data of all selected experiments. It is then available via the `experiment_data` property.\n        - _Empty Data_: Empties the loaded data to free memory.\n\n        Example:\n            Execute the following code in a Jupyter notebook located in the experiment campaign directory under a subdirectory, such as `./analysis`.\n            ```python\n            import exputils as eu\n\n            experiment_data_loader = eu.gui.jupyter.ExperimentDataLoaderWidget()\n            display(experiment_data_loader)\n            ```\n            To access the experiment data after the user has loaded it through the widget:\n            ```python\n            experiment_data_loader.experiment_data\n            ```\n    \"\"\"\n\n    @staticmethod\n    def default_config():\n        \"\"\"Generates the default configuration for the widget.\n\n            Returns:\n                dict: A dictionary containing default configurations for various components of the widget.\n        \"\"\"\n\n        dc = BaseWidget.default_config()\n\n        dc.load_experiment_descriptions_function = eu.AttrDict(\n            func=eu.data.load_experiment_descriptions\n        )\n        dc.load_experiment_data_function = eu.AttrDict(\n            func=eu.data.load_experiment_data\n        )\n        dc.experiments_directory = os.path.join('..', eu.DEFAULT_EXPERIMENTS_DIRECTORY)\n\n        dc.main_box = eu.AttrDict(\n            layout=eu.AttrDict(\n                width='99%',\n                display='flex',\n                flex_flow='column',\n                align_items='stretch'))\n\n        dc.top_button_box = eu.AttrDict(\n            layout=eu.AttrDict(\n                width='100%',\n                display='flex',\n                flex_flow='row',\n                align_items='stretch'))\n\n        dc.load_descr_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '75%',\n                height = 'auto'),\n            description = 'Update Descriptions',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Update for the selected experiment and repetition.')\n\n        dc.reset_descr_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '25%',\n                height = 'auto'),\n            description = 'Reset Descriptions',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Reset all experiment descriptions.')\n\n        dc.move_buttons_box = eu.AttrDict(\n            layout=eu.AttrDict(\n                width='100%',\n                display='flex',\n                flex_flow='row',\n                align_items='stretch'))\n\n        dc.move_up_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '25%',\n                height = 'auto'),\n            description = u'\\u02C5', # 'down',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Moves the selected experiments up in the order.  (Only works if data is not filtered.)')\n\n        dc.move_down_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '25%',\n                height = 'auto'),\n            description = u'\\u02C4', #'up',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Moves the selected experiments down in the order.  (Only works if data is not filtered.)')\n\n        dc.sort_by_id_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width='50%',\n                height='auto'),\n            description='Sort by Experiment ID',  # 'up',\n            disabled=False,\n            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip='Resorts the experiments according to their ID.')\n\n        dc.data_buttons_box = eu.AttrDict(\n            layout=eu.AttrDict(\n                width='100%',\n                display='flex',\n                flex_flow='row',\n                align_items='stretch'))\n\n        dc.load_data_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '75%',\n                height = 'auto'),\n            description = 'Load Data',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Load experimental data.')\n\n        dc.empty_data_button = eu.AttrDict(\n            layout=eu.AttrDict(\n                width = '25%',\n                height = 'auto'),\n            description = 'Empty Data',\n            disabled = False,\n            button_style = '',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip = 'Empties the loaded experimental data to free memory.')\n\n\n        # naming of columns in the dataframe (key: name in experiment_description dict, value: name in dataframe)\n        dc.dataframe_column_names = {'id': 'experiment id',\n                                     'order': 'order',\n                                     'is_load_data': 'load data',\n                                     'short_name': 'short name',\n                                     'name': 'name',\n                                     'description': 'description',\n                                     'directory': 'directory'}\n\n        dc.qgrid_widget = eu.AttrDict(\n            show_toolbar = True,\n            grid_options = {'autoEdit': True,\n                            'sortable': False},\n            column_options = {'editable': False},\n            column_definitions = {\n                'load data': {'editable': True},\n                'short name': {'editable': True},\n                'name': {'editable': True},\n                'description': {'editable': True}})\n\n        dc.output_widget = eu.AttrDict()\n\n        return dc\n\n\n    def __init__(self, config=None, **kwargs):\n        # constructor of BaseWidget\n        super().__init__(config=config, **kwargs)\n        # constructor of GridspecLayout\n        super(BaseWidget, self).__init__(\n            **self.config.main_box)\n\n        self.experiment_descriptions = None\n        self.experiment_data = None\n\n        # list with registered event handlers for the data collected event\n        self._on_experiment_data_loaded_event_handlers = []\n        self._on_experiment_descriptions_updated_event_handlers = []\n\n        self.load_state_backup()\n\n        self.update_experiment_descriptions()\n\n        # create gui elements\n        self.load_descr_btn = ipywidgets.Button(**self.config.load_descr_button)\n        self.reset_descr_btn = ipywidgets.Button(**self.config.reset_descr_button)\n        self.top_button_box = ipywidgets.Box(\n            children=[self.load_descr_btn, self.reset_descr_btn],\n            **self.config.top_button_box)\n\n        self.qgrid_widget = ipywidgets.Box()  # initialize with dummy, will be overridden by update function\n\n        self.move_up_btn = ipywidgets.Button(**self.config.move_up_button)\n        self.move_down_btn = ipywidgets.Button(**self.config.move_down_button)\n        self.sort_by_id_button = ipywidgets.Button(**self.config.sort_by_id_button)\n        self.move_buttons_box = ipywidgets.Box(\n            children=[self.move_down_btn, self.move_up_btn, self.sort_by_id_button],\n            **self.config.move_buttons_box)\n\n        self.load_data_btn = ipywidgets.Button(**self.config.load_data_button)\n        self.empty_data_btn = ipywidgets.Button(**self.config.empty_data_button)\n        self.data_buttons_box = ipywidgets.Box(\n            children=[self.load_data_btn, self.empty_data_btn],\n            **self.config.data_buttons_box)\n\n        eu.gui.jupyter.add_children_to_widget(\n            self,\n            [self.top_button_box, self.qgrid_widget, self.move_buttons_box, self.data_buttons_box])\n\n        # create an output widget\n        self._output_widget = None\n\n        self._update_qgrid()\n\n        # register events\n        self.load_descr_btn.on_click(self._handle_load_descr_button_on_click)\n        self.reset_descr_btn.on_click(self._handle_reset_descr_button_on_click)\n        self.load_data_btn.on_click(self._handle_load_data_button_on_click)\n        self.empty_data_btn.on_click(self._handle_empty_data_button_on_click)\n        self.move_up_btn.on_click(self._handle_move_up_button_on_click)\n        self.move_down_btn.on_click(self._handle_move_down_button_on_click)\n        self.sort_by_id_button.on_click(self._handle_sort_by_id_button_on_click)\n\n        self._handle_qgrid_cell_edited_is_active = True\n\n    def _prepare_output_widget(self):\n\n        if self._output_widget is None:\n            self._output_widget = ipywidgets.Output(**self.config.output_widget)\n            IPython.display.display(self._output_widget)\n        else:\n            warnings.resetwarnings()\n            self._output_widget.clear_output(wait=False)\n\n        return self._output_widget\n\n\n    def _handle_load_descr_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            self.update_experiment_descriptions(is_reset=False)\n            self._update_qgrid()\n\n\n    def _handle_reset_descr_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            self.update_experiment_descriptions(is_reset=True)\n            self._update_qgrid()\n\n\n    def _handle_load_data_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            # load data and save widget state\n            print('Load data ...')\n            self.load_data()\n            self.backup_state()\n            print('Data successfully loaded.')\n\n\n    def _handle_empty_data_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            # empty data and save widget state\n            self.empty_data()\n            self.backup_state()\n            print('Emptied data.')\n\n\n    def _handle_move_up_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            try:\n                self.move_up_btn.disabled = True\n                self.move_down_btn.disabled = True\n\n                self.move_experiments_up()\n            finally:\n                self.move_up_btn.disabled = False\n                self.move_down_btn.disabled = False\n\n    def _handle_move_down_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            try:\n                self.move_up_btn.disabled = True\n                self.move_down_btn.disabled = True\n\n                self.move_experiments_down()\n            finally:\n                self.move_up_btn.disabled = False\n                self.move_down_btn.disabled = False\n\n    def _handle_sort_by_id_button_on_click(self, btn):\n        # errors are plotted in output widget and it will be cleaned after next button press\n        with self._prepare_output_widget():\n            self.resort_experiments_by_id()\n\n    def _handle_qgrid_cell_edited(self, event, widget):\n        with self._prepare_output_widget():\n\n            if self._handle_qgrid_cell_edited_is_active:\n\n                # update the experiment_description\n                if event['name'] == 'cell_edited':\n\n                    for expdescr_prop_name, df_col_name in self.config.dataframe_column_names.items():\n                        if df_col_name == event['column']:\n                            self.experiment_descriptions[event['index']][expdescr_prop_name] = event['new']\n                            break\n\n                    self.backup_state()\n\n                    self._call_experiment_descriptions_updated_event()\n\n\n    def _handle_qgrid_filter_changed(self, event, widget):\n        with self._prepare_output_widget():\n\n            # identify if a filter is active or not\n            is_filter_active = len(self.qgrid_widget.df) != len(self.qgrid_widget.get_changed_df())\n\n            if is_filter_active:\n                # do not allow to change order\n                self.move_up_btn.disabled = True\n                self.move_down_btn.disabled = True\n\n            else:\n                # allow to change order\n                self.move_up_btn.disabled = False\n                self.move_down_btn.disabled = False\n\n    def _update_qgrid(self):\n\n        # convert experiment description to the dataframe\n        df = pd.DataFrame()\n        for exp_descr_field_name, df_column_name in self.config.dataframe_column_names.items():\n            df[df_column_name] = [descr[exp_descr_field_name] for descr in self.experiment_descriptions.values()]\n\n        df = df.set_index(self.config.dataframe_column_names['id'])\n\n        # create a new qgrid widget with the dataframe\n        for opt_name, opt_value in self.config.qgrid_widget.grid_options.items():\n            qgrid.set_grid_option(opt_name, opt_value)\n\n        self.qgrid_widget = qgrid.show_grid(df,\n                                            column_options=self.config.qgrid_widget.column_options,\n                                            column_definitions=self.config.qgrid_widget.column_definitions,\n                                            show_toolbar=self.config.qgrid_widget.show_toolbar)\n\n        eu.gui.jupyter.remove_children_from_widget(self, 1)\n        eu.gui.jupyter.add_children_to_widget(self, self.qgrid_widget, idx=1)\n\n        self.qgrid_widget.on('cell_edited', self._handle_qgrid_cell_edited)\n\n        self.qgrid_widget.on('filter_changed', self._handle_qgrid_filter_changed)\n\n        self.sort_grid_by_order()\n\n\n    def sort_grid_by_order(self):\n        # hack to resort the experiments in the grid according to the order field\n        content = dict(\n            type='change_sort',\n            sort_field=self.config.dataframe_column_names['order'],\n            sort_ascending=True)\n        self.qgrid_widget._handle_qgrid_msg_helper(content)\n\n\n    def on_experiment_descriptions_updated(self, handler):\n        \"\"\"\n        Register an event handler for the case that the experiment descriptions was changed.\n        Please note, that this does not mean that the data was loaded according to the new experiment descriptions.\n        Use the on_experiment_data_loaded for this purpose.\n        The handler receives a dict with information about the event.\n        \"\"\"\n        self._on_experiment_descriptions_updated_event_handlers.append(handler)\n\n\n    def _call_experiment_descriptions_updated_event(self):\n        for handler in self._on_experiment_descriptions_updated_event_handlers:\n            handler(eu.AttrDict(\n                name='experiment_descriptions_updated',\n                new=self.experiment_descriptions,\n                owner=self,\n                type='change'))\n\n\n    def on_experiment_data_loaded(self, handler):\n        \"\"\"\n        Register an event handler for the case new data was loaded.\n        The handler receives a dict with information about the event.\n        \"\"\"\n        self._on_experiment_data_loaded_event_handlers.append(handler)\n\n\n    def _call_experiment_data_loaded_event(self):\n        for handler in self._on_experiment_data_loaded_event_handlers:\n            handler(eu.AttrDict(\n                name='data_loaded',\n                new=self.experiment_data,\n                owner=self,\n                type='change'))\n\n\n    def move_experiments_up(self, selected_items=None, is_select_changed_items=True):\n\n        try:\n            self._handle_qgrid_cell_edited_is_active = False\n\n            if selected_items is None:\n                selected_items = self.qgrid_widget.get_selected_df()\n\n            if len(selected_items) &gt; 0:\n\n                order_col_name = self.config.dataframe_column_names['order']\n                experiment_id_col_name = self.config.dataframe_column_names['id']\n\n                # select according to the order\n                selected_items = selected_items.sort_values(by=order_col_name)\n                qgrid_df = self.qgrid_widget.get_changed_df()\n\n                # make order the index to allow to seach by it\n                all_items_sorted_by_order = qgrid_df.sort_values(by=order_col_name).reset_index().set_index(order_col_name)\n\n                selected_idx = len(selected_items) - 1\n                while selected_idx &gt;= 0:\n\n                    # identify current block of consequetively selected items\n                    current_block_exp_ids = []\n\n                    is_block = True\n                    last_item_order = None\n                    while is_block and selected_idx &gt;= 0:\n                        cur_item_order = selected_items.iloc[selected_idx][order_col_name]\n\n                        if last_item_order is None or last_item_order - cur_item_order == 1:\n                            current_block_exp_ids.append(selected_items.index[selected_idx])\n                            selected_idx -= 1\n                            last_item_order = cur_item_order\n                        else:\n                            is_block = False\n\n                    order_of_highest_block_item = qgrid_df.loc[current_block_exp_ids[0]][order_col_name]\n\n                    # only change orders if the block is not at the end of the list\n                    if order_of_highest_block_item &lt; len(qgrid_df) - 1:\n\n                        # change the order of item below the block\n                        exp_id_of_current_item_above_block = all_items_sorted_by_order.loc[order_of_highest_block_item + 1][experiment_id_col_name]\n\n                        new_order = order_of_highest_block_item - len(current_block_exp_ids) + 1\n                        self.qgrid_widget.edit_cell(\n                            exp_id_of_current_item_above_block,\n                            order_col_name,\n                            new_order)\n                        self.experiment_descriptions[exp_id_of_current_item_above_block]['order'] = new_order\n\n                        # subtract 1 to all selected items in the block\n                        for block_item_exp_id in current_block_exp_ids:\n                            new_order = qgrid_df.loc[block_item_exp_id]['order'] + 1\n\n                            self.qgrid_widget.edit_cell(\n                                block_item_exp_id,\n                                order_col_name,\n                                new_order)\n                            self.experiment_descriptions[block_item_exp_id]['order'] = new_order\n\n                        #resort the experiments in the grid according to the order field\n                        self.sort_grid_by_order()\n\n                        # reslect the old elements\n                        if is_select_changed_items:\n                            self.qgrid_widget.change_selection(selected_items.index)\n\n                        self.backup_state()\n\n                        self._call_experiment_descriptions_updated_event()\n        finally:\n            self._handle_qgrid_cell_edited_is_active = True\n\n\n    def move_experiments_down(self, selected_items=None, is_select_changed_items=True):\n\n        try:\n            self._handle_qgrid_cell_edited_is_active = False\n\n            if selected_items is None:\n                selected_items = self.qgrid_widget.get_selected_df()\n\n            if len(selected_items) &gt; 0:\n\n                order_col_name = self.config.dataframe_column_names['order']\n                experiment_id_col_name = self.config.dataframe_column_names['id']\n\n                # select according to the order\n                selected_items = selected_items.sort_values(by=order_col_name)\n                qgrid_df = self.qgrid_widget.get_changed_df()\n\n                # make order the index to allow to seach by it\n                all_items_sorted_by_order = qgrid_df.sort_values(by=order_col_name).reset_index().set_index(order_col_name)\n\n                selected_idx = 0\n                while selected_idx &lt; len(selected_items):\n\n                    # identify current block of consequetively selected items\n                    current_block_exp_ids = []\n\n                    is_block = True\n                    last_item_order = None\n                    while is_block and selected_idx &lt; len(selected_items):\n                        cur_item_order = selected_items.iloc[selected_idx][order_col_name]\n\n                        if last_item_order is None or cur_item_order - last_item_order == 1:\n                            current_block_exp_ids.append(selected_items.index[selected_idx])\n                            selected_idx += 1\n                            last_item_order = cur_item_order\n                        else:\n                            is_block = False\n\n                    order_of_lowest_block_item = qgrid_df.loc[current_block_exp_ids[0]][order_col_name]\n\n                    # only change orders if the block is not at the end of the list\n                    if order_of_lowest_block_item &gt; 0:\n\n                        # change the order of item below the block\n                        exp_id_of_current_item_below_block = all_items_sorted_by_order.loc[order_of_lowest_block_item - 1][experiment_id_col_name]\n\n                        new_order = order_of_lowest_block_item + len(current_block_exp_ids) - 1\n                        self.qgrid_widget.edit_cell(\n                            exp_id_of_current_item_below_block,\n                            order_col_name,\n                            new_order)\n                        self.experiment_descriptions[exp_id_of_current_item_below_block]['order'] = new_order\n\n                        # subtract 1 to all selected items in the block\n                        for block_item_exp_id in current_block_exp_ids:\n                            new_order = qgrid_df.loc[block_item_exp_id]['order'] - 1\n\n                            self.qgrid_widget.edit_cell(\n                                block_item_exp_id,\n                                order_col_name,\n                                new_order)\n                            self.experiment_descriptions[block_item_exp_id]['order'] = new_order\n\n                        # resort the experiments in the grid according to the order field\n                        self.sort_grid_by_order()\n\n                        # reselect the old elements\n                        if is_select_changed_items:\n                            self.qgrid_widget.change_selection(selected_items.index)\n\n                        self.backup_state()\n\n                        self._call_experiment_descriptions_updated_event()\n        finally:\n            self._handle_qgrid_cell_edited_is_active = True\n\n\n    def resort_experiments_by_id(self):\n        \"\"\"\n        Resets the order of the experiments according to their IDs.\n        \"\"\"\n        try:\n            # don't allow to change the qgrid during the operation\n            self._handle_qgrid_cell_edited_is_active = False\n\n            # sort experiments according to ids\n            # get list of experiment ids\n            sorted_existing_experiment_ids = sorted(list(self.experiment_descriptions.keys()))\n\n            # update the order of the experiments according to the sorted list\n            for order, exp_id in enumerate(sorted_existing_experiment_ids):\n                self.experiment_descriptions[exp_id].order = order\n\n            # update the gui according to the new order\n            self._update_qgrid()\n\n            # inform others the descriptions are changed\n            self._call_experiment_descriptions_updated_event()\n\n        finally:\n            # qgrid can be changed again\n            self._handle_qgrid_cell_edited_is_active = True\n\n\n    def update_experiment_descriptions(self, is_reset=False):\n        \"\"\"Updates the experiment descriptions by adding new experiments and removing old experiments.\"\"\"\n\n        # load experiment descriptions\n        new_exp_descr = eu.misc.call_function_from_config(\n            self.config.load_experiment_descriptions_function,\n            self.config.experiments_directory)\n\n        if not self.experiment_descriptions or is_reset:\n            self.experiment_descriptions = new_exp_descr\n        else:\n            # combine existing descriptions and new list\n\n            # remove non-existing elements from exisiting descriptions\n            deleted_experiments = set(self.experiment_descriptions.keys()).difference(set(new_exp_descr.keys()))\n            for deleted_exp in deleted_experiments:\n                del self.experiment_descriptions[deleted_exp]\n\n            # kepp current order and add new experiments at the end of the list\n            # get current order of experiment\n            sorted_existing_experiment_ids = eu.data.get_ordered_experiment_ids_from_descriptions(self.experiment_descriptions)\n            sorted_new_experiment_ids = eu.data.get_ordered_experiment_ids_from_descriptions(new_exp_descr)\n\n            # remove existing experiment ids from the sorted list of new experiment ids\n            for existing_exp_id in sorted_existing_experiment_ids:\n                if existing_exp_id in sorted_new_experiment_ids:\n                    sorted_new_experiment_ids.remove(existing_exp_id)\n\n            # add new elements\n            self.experiment_descriptions = eu.combine_dicts(self.experiment_descriptions, new_exp_descr)\n\n            # update the order of the experiments according to the sorted lists\n            for order, exp_id in enumerate(sorted_existing_experiment_ids + sorted_new_experiment_ids):\n                self.experiment_descriptions[exp_id].order = order\n\n            # do not keep the repetition ids from existing ones, but use the ones from the new discriptions\n            # otherwise, if new repetitions are added, they will not be used\n            for new_descr in new_exp_descr.values():\n                self.experiment_descriptions[new_descr.id].repetition_ids = new_descr.repetition_ids\n\n        self._call_experiment_descriptions_updated_event()\n\n\n    def get_widget_state(self):\n        state = super().get_widget_state()\n        state.experiment_descriptions = self.experiment_descriptions\n        return state\n\n\n    def set_widget_state(self, state):\n        if 'experiment_descriptions' in state: self.experiment_descriptions  = state.experiment_descriptions\n        return super().set_widget_state(state)\n\n    def empty_data(self):\n        # Delete experiment_data to free memory\n        if self.experiment_data:\n            keys = list(self.experiment_data.keys())\n            for key in keys:\n                del self.experiment_data[key]\n\n    def load_data(self):\n        \"\"\"Loads the experiment data.\n\n        Can be called directly after initialization of the widget to preload the data without needing a user input.\n        \"\"\"\n\n        # delete old data to free memory\n        self.empty_data()\n\n        experiment_data = eu.misc.call_function_from_config(\n            self.config.load_experiment_data_function,\n            self.experiment_descriptions)\n\n        # some data loader functions give as extra argument the experiment descriptions\n        if isinstance(experiment_data, tuple):\n            experiment_data = experiment_data[0]\n\n        self.experiment_data = experiment_data\n\n        self._call_experiment_data_loaded_event()\n</code></pre>"},{"location":"reference/visualization/#exputils.gui.jupyter.experiment_data_plot_selection_widget.ExperimentDataPlotSelectionWidget","title":"<code>ExperimentDataPlotSelectionWidget</code>","text":"<p>               Bases: <code>ExperimentDataSelectionWidget</code></p> <p>Jupyter widget for plotting experiment data and creating Jupyter cells for dedicated plotting.</p> <p>The widget allows to select the datasource that should be plotted and the plotting function. It also allows to select which experiments should be plotted and to create dedicated Jupyter cells to plot specific datasources.</p> <p>GUI of the widget:</p> <p>Functionality:</p> <ul> <li>Data Sources: Allows to define the datasource or datasources that should be plotted.     The datasource names correspond to the filenames under the data folder of repetitions and     correspond to the names that were used by the logging functions.     A comma-seperated list of datasources can be provided for table plots (tabulate_meanstd).     It is also possible to extract single elements from data arrays using bracket operation after the name.     For example <code>loss[-1]</code> will access the final loss value.</li> <li>Experiments: Selection of experiments from which data was loaded that should be plotted.</li> <li>Repetitions: Selection of repetitions from which data was loaded that should be plotted.</li> <li>Plot Function: Plotting function that should be used.     See the Plotting Functions section for a list of exisiting     plotting functions.</li> <li>Plot Configuration: Configuration of the plotting function.     See the Plotting Functions section for details.</li> <li>Plot Data: Plots the data below the widget.</li> <li>Code Production: Creates a new Jupyter notebook cell below the current one that contains     the code to plot the data again with all the configuration that was set in the GUI.     The code also allows to change the configuration.</li> </ul> Example <p>Execute the following code in a Jupyter notebook located in the experiment campaign directory under a subdirectory, such as <code>./analysis</code>. This code should be executed after data has been loaded, for example via the ExperimentDataLoaderWidget. <pre><code># allow plotting of data loaded by the experiment_data_loader (ExperimentDataLoaderWidget)\nexperiment_data_plotter = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(experiment_data_loader)\ndisplay(experiment_data_plotter)\n</code></pre></p> Source code in <code>exputils/gui/jupyter/experiment_data_plot_selection_widget.py</code> <pre><code>class ExperimentDataPlotSelectionWidget(ExperimentDataSelectionWidget):\n    \"\"\"\n        Jupyter widget for plotting experiment data and creating Jupyter cells for dedicated plotting.\n\n        The widget allows to select the datasource that should be plotted and the plotting function.\n        It also allows to select which experiments should be plotted and to create dedicated Jupyter\n        cells to plot specific datasources.\n\n        GUI of the widget:\n        &lt;figure markdown=\"span\"&gt;\n          ![ExperimentDataPlotSelectionWidget](../assets/images/experiment_data_plot_selection_widget.png)\n        &lt;/figure&gt;\n\n        Functionality:\n\n        - _Data Sources_: Allows to define the datasource or datasources that should be plotted.\n            The datasource names correspond to the filenames under the data folder of repetitions and\n            correspond to the names that were used by the [logging](logging.md#writting) functions.\n            A comma-seperated list of datasources can be provided for table plots ([tabulate_meanstd][exputils.gui.jupyter.tabulate_meanstd.tabulate_meanstd]).\n            It is also possible to extract single elements from data arrays using bracket operation after the name.\n            For example `loss[-1]` will access the final loss value.\n        - _Experiments_: Selection of experiments from which data was loaded that should be plotted.\n        - _Repetitions_: Selection of repetitions from which data was loaded that should be plotted.\n        - _Plot Function_: Plotting function that should be used.\n            See the [Plotting Functions](./#plotting-functions) section for a list of exisiting\n            plotting functions.\n        - _Plot Configuration_: Configuration of the plotting function.\n            See the [Plotting Functions](./#plotting-functions) section for details.\n        - _Plot Data_: Plots the data below the widget.\n        - _Code Production_: Creates a new Jupyter notebook cell below the current one that contains\n            the code to plot the data again with all the configuration that was set in the GUI.\n            The code also allows to change the configuration.\n\n        Example:\n            Execute the following code in a Jupyter notebook located in the experiment campaign directory under a subdirectory, such as `./analysis`.\n            This code should be executed after data has been loaded, for example via the [ExperimentDataLoaderWidget][exputils.gui.jupyter.ExperimentDataLoaderWidget].\n            ```python\n            # allow plotting of data loaded by the experiment_data_loader (ExperimentDataLoaderWidget)\n            experiment_data_plotter = eu.gui.jupyter.ExperimentDataPlotSelectionWidget(experiment_data_loader)\n            display(experiment_data_plotter)\n            ```\n    \"\"\"\n\n    @staticmethod\n    def default_config():\n        dc = ExperimentDataSelectionWidget.default_config()\n\n        # do not show the get data button, this widget will create its own plotting button\n        dc.is_get_experiment_data_button = False\n\n        # dictionary with possible plotting function\n        dc.plot_functions = {'plotly_meanstd_scatter': eu.gui.jupyter.plotly_meanstd_scatter,\n                             'plotly_box': eu.gui.jupyter.plotly_box,\n                             'plotly_meanstd_bar': eu.gui.jupyter.plotly_meanstd_bar,\n                             'tabulate_meanstd': eu.gui.jupyter.tabulate_meanstd,\n                             'tabulate_pairwise': eu.gui.jupyter.tabulate_pairwise,\n\n        }\n\n        # dictionary with plot_function_configs for each\n        dc.plot_function_configs = {'plotly_meanstd_scatter': DEFAULT_PLOTLY_MEANSTD_SCATTER_CONFIG,\n                                    'plotly_box': DEFAULT_PLOTLY_BOX_CONFIG,\n                                    'plotly_meanstd_bar': DEFAULT_PLOTLY_MEANSTD_BAR_CONFIG,\n                                    'tabulate_meanstd': DEFAULT_TABULATE_MEANSTD_CONFIG,\n                                    'tabulate_pairwise': DEFAULT_TABULATE_PAIRWISE_CONFIG,\n        }\n\n        dc.is_plot_function_selection = True\n        dc.plot_function = list(dc.plot_functions.keys())[0]\n        dc.plot_function_selection = eu.AttrDict(\n            hbox=eu.AttrDict(  # ipywidgets.HBox parameters\n                layout=eu.AttrDict(\n                    width='100%')),\n            label=eu.AttrDict(  # ipywidgets.Label parameters\n                value='Plot Function:',\n                layout=eu.AttrDict(min_width='100px')),\n            dropdown=eu.AttrDict(  # ipywidgets.Text parameters\n                description='',\n                layout=eu.AttrDict(width='100%')))\n\n        dc.is_plot_function_config_editor = True\n        dc.plot_function_config = None\n        dc.plot_function_config_editor = eu.AttrDict(\n            title = 'Plot Configuration',\n            accordion=eu.AttrDict(  # ipywidgets.HBox parameters\n                selected_index=None,  # collapse accordion at init\n                layout=eu.AttrDict(\n                    width='100%')),\n            textarea=eu.AttrDict(  # ipywidgets.Label parameters\n                placeholder='Provide the configuration of the plot function in form of a python dictionary ...',\n                layout=eu.AttrDict(\n                    min_width='100%'))) # TODO: start with a larger height at the beginning\n\n        dc.is_plot_button = True\n        dc.plot_button = eu.AttrDict(\n            description='Plot Data',\n            tooltip='Plots the data according to the selection.',\n            layout=eu.AttrDict(width='100%', height='95%'))\n\n        dc.code_producer.code_templates = [dict(name='Multi Line', code_template=CODE_TEMPLATE_MULTILINE),\n                                           dict(name='Single Line', code_template=CODE_TEMPLATE_SINGLELINE)]\n\n        dc.figure_output = eu.AttrDict()  # ipywidgets.Output parameters\n\n        return dc\n\n\n    def __init__(self, experiment_data, experiment_descriptions=None, config=None, **kwargs):\n\n        super().__init__(experiment_data,\n                         experiment_descriptions=experiment_descriptions,\n                         config=config,\n                         **kwargs)\n\n        # add a figure output below the selection\n        self.figure_output = None\n\n        #########################\n        # handle config input if not a state backup was loaded\n        if not hasattr(self, '_plot_function_key') and not hasattr(self, '_plot_function') and not hasattr(self, '_plot_function_configs'):\n\n            # use first plot function in plot_fuctions dictionary if non is provided\n            if self.config.plot_function == '' or self.config.plot_function is None:\n                plot_function = list(self.config.plot_functions.keys())[0]\n            else:\n                plot_function = self.config.plot_function\n\n            if isinstance(plot_function, str):\n                # config.plot_function is a key for the config.plot_functions dictionary\n\n                if self.config.plot_function not in self.config.plot_functions:\n                    raise ValueError('If config.plot_function is a string then it must be a key for the config.plot_functions dictionary!')\n\n                self._plot_function_key = plot_function\n                self._plot_function = self.config.plot_functions[self._plot_function_key]\n\n            elif callable(plot_function):\n                # if the config.plotfunction is a function handle\n                self._plot_function_key = 'NONE'\n                self._plot_function = plot_function\n\n            else:\n                raise TypeError('Unsupported type for config.plot_fuction! Only strings or function handles are valid.')\n\n            # handle self._plot_function_configs\n            self._plot_function_configs = self.config.plot_function_configs.copy()\n            plot_function_config = self.config.plot_function_config\n            if plot_function_config == '' or plot_function_config is None:\n                # if no config.plot_function_config is given, then use the one from the config.plot_function_configs dictionary\n                # create a new entry in _plot_function_configs if non exists for this plot_function_key\n                if self._plot_function_key not in self._plot_function_configs:\n                    self._plot_function_configs[self._plot_function_key] = None\n            else:\n                # if a config is given, then override the _plot_functions_config with it\n                self._plot_function_configs[self._plot_function_key] = _config_obj_to_dict(plot_function_config)\n\n            # if the config is invalid and the user can not change it anymore, then raise an exception\n            if not self.config.is_plot_function_config_editor \\\n                    and isinstance(self._plot_function_configs[self._plot_function_key], BaseException):\n                raise self._plot_function_config[self._plot_function_key]\n\n            if self._plot_function_key == 'NONE' and self.config.is_plot_function_selection:\n                raise ValueError('If plot_function_selection is active, then the config.plot_function must be a key for the config.plot_functions dictionary!')\n\n        ########################\n        # add gui components\n        selection_children = []\n\n        # only allow selection of a plot function if the defined intial plot_function is not a function handle\n        if self.config.is_plot_function_selection and callable(self.config.plot_function):\n            self.config.is_plot_function_selection = False\n\n        # selection of plot function\n        if self.config.is_plot_function_selection:\n\n            self.plot_function_selection_label_widget = ipywidgets.Label(**self.config.plot_function_selection.label)\n\n            self.plot_function_selection_dropdown_widget = ipywidgets.Dropdown(\n                options=list(self.config.plot_functions.keys()),\n                value=self._plot_function_key,\n                **self.config.plot_function_selection.dropdown)\n\n            self.plot_function_selection_hbox_widget = ipywidgets.HBox(\n                [self.plot_function_selection_label_widget, self.plot_function_selection_dropdown_widget],\n                **self.config.plot_function_selection.hbox)\n\n            selection_children.append(self.plot_function_selection_hbox_widget)\n\n            # register event to know when a new plot function was selected\n            self.plot_function_selection_dropdown_widget.observe(\n                self._on_plot_function_selection_dropdown_widget_value_change,\n                names='value')\n\n        if self.config.is_plot_function_config_editor:\n\n            self.plot_function_config_editor_textarea = ipywidgets.Textarea(\n                value=self._plot_function_configs[self._plot_function_key],\n                **self.config.plot_function_config_editor.textarea)\n\n            self.plot_function_config_editor_accordion = ipywidgets.Accordion(\n                children=[self.plot_function_config_editor_textarea],\n                **self.config.plot_function_config_editor.accordion)\n            self.plot_function_config_editor_accordion.set_title(0, self.config.plot_function_config_editor.title)\n\n            selection_children.append(self.plot_function_config_editor_accordion)\n\n            # register event to know when a new config was edited\n            self.plot_function_config_editor_textarea.observe(\n                self._on_plot_function_config_editor_value_change,\n                names='value')\n\n        # add selection items befor the box for the buttons\n        eu.gui.jupyter.add_children_to_widget(self, selection_children, idx=-1)\n\n        # add plotting button\n        if self.config.is_plot_button:\n            self.plot_button = ipywidgets.Button(**self.config.plot_button)\n            self.plot_button.on_click(self._plot_button_on_click_handler)\n\n            # append button to start of button box\n            eu.gui.jupyter.add_children_to_widget(self.activity_hbox, self.plot_button, idx=0)\n\n\n    def _on_plot_function_selection_dropdown_widget_value_change(self, event_descr):\n        self._plot_function_key = event_descr['new']\n        self._plot_function = self.config.plot_functions[self._plot_function_key]\n        self.plot_function_config = self._plot_function_configs.get(self._plot_function_key, None)\n\n\n    def _on_plot_function_config_editor_value_change(self, event_descr):\n        self._plot_function_configs[self._plot_function_key] = event_descr['new']\n\n\n    @property\n    def plot_function(self):\n        return self._plot_function\n\n\n    @plot_function.setter\n    def plot_function(self, plot_function):\n\n        if isinstance(plot_function, str):\n            # config.plot_function is a key for the config.plot_functions dictionary\n\n            if plot_function not in self.config.plot_functions:\n                raise ValueError(\n                    'If plot_function is a string then it must be a key for the config.plot_functions dictionary!')\n\n            self._plot_function_key = plot_function\n            self._plot_function = self.config.plot_functions[self._plot_function_key]\n\n            # also the config.plot_function_configs dict will be used\n            self.plot_function_config = self._plot_function_configs[self._plot_function_key]\n\n        elif callable(plot_function):\n            # if the config.plotfunction is a function handle\n\n            # try to find function in configured functions\n            plot_function_key = 'NONE'\n            for func_str, func in self.config.plot_functions.items():\n                if func == plot_function:\n                    plot_function_key = func_str\n                    break\n\n            self._plot_function_key = plot_function_key\n            self._plot_function = plot_function\n            if self._plot_function_key not in self._plot_function_configs:\n                self._plot_function_configs[self._plot_function_key] = None\n\n    @property\n    def plot_function_config(self):\n        return _config_obj_to_dict(self._plot_function_configs[self._plot_function_key])\n\n\n    @plot_function_config.setter\n    def plot_function_config(self, plot_function_config):\n\n        if self.config.is_plot_function_config_editor:\n\n            if not isinstance(plot_function_config, str):\n                raise ValueError('If the plot_function_config_editor is activated, then the given plot_function_config must be a string!')\n\n            # was the gui element already created?\n            if hasattr(self, 'plot_function_config_editor_textarea'):\n                self.plot_function_config_editor_textarea.value = plot_function_config\n\n        self._plot_function_configs[self._plot_function_key] = plot_function_config\n\n\n    def _plot_button_on_click_handler(self, _):\n        self.plot_data()\n\n\n    @property\n    def selection(self):\n        '''AttrDict (dict) with the selected experiment data options.'''\n        selection = super().selection\n        selection.plot_function = self.plot_function\n        selection.plot_function_config = self.plot_function_config\n        return selection\n\n\n    @selection.setter\n    def selection(self, selection):\n        super(self.__class__, self.__class__).selection.fset(self, selection)\n        if 'plot_function' in selection: self.plot_function = selection.plot_function\n        if 'plot_function_config' in selection: self.plot_function_config = selection.plot_function_config\n\n\n    def get_widget_state(self):\n        state = super().get_widget_state()\n\n        if self._plot_function_key == 'NONE':\n            state.plot_function = self.plot_function\n        else:\n            state.plot_function = self._plot_function_key\n        state._plot_function_configs = self._plot_function_configs\n        return state\n\n\n    def set_widget_state(self, state):\n\n        if '_plot_function_configs' in state:\n            self._plot_function_configs = state._plot_function_configs  # set all gui configs\n\n        if 'plot_function' in state:\n            self.plot_function = state.plot_function\n\n        if '_plot_function_configs' in state:\n            self.plot_function_config = self._plot_function_configs[self._plot_function_key]  # update the view\n\n        return super().set_widget_state(state)\n\n\n    def plot_data(self):\n\n        # display the figure\n        # must be created here so that the display is created below the selection gui\n        if self.figure_output is None:\n            self.figure_output = ipywidgets.Output(**self.config.figure_output)\n            IPython.display.display(self.figure_output)\n        else:\n            self.figure_output.clear_output(wait=True)\n\n        with self.figure_output:\n            print('Plotting ...')\n\n            # load experimental data before plotting\n            self.select_experiment_data()\n\n            plot_config = self.plot_function_config\n            if isinstance(plot_config, BaseException):\n                raise plot_config\n            else:\n                display_obiect = self.plot_function(\n                    self.selected_data,\n                    labels=self.selected_data_labels,\n                    config=plot_config)\n\n                self.figure_output.clear_output(wait=True)\n                IPython.display.display(display_obiect)\n\n\n    def get_code_producer_variables(self):\n\n        variables = super().get_code_producer_variables()\n\n        plot_function_handle = self.plot_function\n        variables.plot_function = plot_function_handle.__name__\n\n        if plot_function_handle.__module__ == '__main__' or plot_function_handle.__module__ == 'builtins':\n            # no extra imports\n            variables.import_statements = '\\n'\n        else:\n            variables.import_statements = 'from {} import {}'.format(plot_function_handle.__module__, variables.plot_function)\n\n        # plot configuration as a dictionary\n        if self.config.is_plot_function_config_editor:\n            plot_function_config_str = 'eu.AttrDict(\\n{})'.format(self.plot_function_config_editor_textarea.value)\n        else:\n            plot_function_config_dict = self.plot_function_config\n            plot_function_config_str = 'eu.' + str(eu.AttrDict(plot_function_config_dict))\n\n        variables.plot_function_config = plot_function_config_str\n\n        return variables\n</code></pre>"},{"location":"reference/visualization/#plotting-functions","title":"Plotting Functions","text":""},{"location":"reference/visualization/#exputils.gui.jupyter.plotly_meanstd_scatter.plotly_meanstd_scatter","title":"<code>plotly_meanstd_scatter</code>","text":"<p>Interactive line plot that shows the mean and std over all repetitions of each experiment or to show the individual repetitions.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>Data to plot. Should be in the following forms:</p> <ul> <li>subplot_idx:list[elems_per_trace:numpy.ndarray]</li> <li>trace_idx:list</li> <li>[elems_per_trace:numpy.ndarray]</li> </ul> <code>None</code> <code>config</code> <code>dict</code> <p>Dictionary with configuration of plot.</p> <code>None</code> <p>Configuration:</p> <ul> <li><code>layout</code> (<code>dict</code>): See Plotly layout for all possible options.<ul> <li><code>xaxis</code> (<code>dict</code>):<ul> <li><code>title</code> (<code>str</code>): Title of the x-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of x-axis. Default is <code>[None, None]</code>.</li> </ul> </li> <li><code>yaxis</code> (<code>dict</code>)<ul> <li><code>title</code> (<code>str</code>): Title of the y-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of y-axis. Default is <code>[None, None]</code>.</li> </ul> </li> </ul> </li> <li><code>moving_average</code> (<code>dict</code>):<ul> <li><code>n</code> (<code>int</code>): Number of elements (over the x-axis) over which a moving average should be     computed. Default is <code>1</code>.</li> </ul> </li> <li><code>data_filter</code> (<code>dict</code>):<ul> <li><code>every_nth_step</code> (<code>int</code>, <code>dict</code>):     Either an integer with the number of steps or a dictionary.     In case of a dictionary:<ul> <li><code>step</code> (<code>int</code>): Number of steps between taken values. Default is <code>None</code>.</li> <li><code>include_final_step</code> (<code>bool</code>):     Should the final step (the final value) also be included even if outside the stepping.     Default is <code>False</code>.</li> </ul> </li> </ul> </li> </ul> <p>Returns:</p> Name Type Description <code>fig</code> <code>figure</code> <p>Plotly figure object that can be displayed using <code>display(fig)</code>.</p> <p>The plot is based on Plotly scatter.</p> Source code in <code>exputils/gui/jupyter/plotly_meanstd_scatter.py</code> <pre><code>def plotly_meanstd_scatter(data: Optional[list] = None,\n                           config: Optional[dict] = None,\n                           **kwargs):\n    \"\"\"\n    Interactive line plot that shows the mean and std over all repetitions of each experiment or to\n    show the individual repetitions.\n\n    &lt;figure markdown=\"span\"&gt;\n          ![plotly_meanstd_scatter](../assets/images/plotly_meanstd_scatter_2.png)\n    &lt;/figure&gt;\n\n    Parameters:\n        data (list): Data to plot. Should be in the following forms:\n\n            - [subplot_idx:list][trace_idx:list][elems_per_trace:numpy.ndarray]\n            - [trace_idx:list][elems_per_trace:numpy.ndarray]\n            - [elems_per_trace:numpy.ndarray]\n        config (dict): Dictionary with configuration of plot.\n\n    __Configuration__:\n\n    - `layout` (`dict`): See [Plotly layout](https://plotly.com/python/reference/layout/) for all possible options.\n        - `xaxis` (`dict`):\n            - `title` (`str`): Title of the x-axis.\n            - `range` (`tuple`): Tuple with min and max values of x-axis. Default is `[None, None]`.\n        - `yaxis` (`dict`)\n            - `title` (`str`): Title of the y-axis.\n            - `range` (`tuple`): Tuple with min and max values of y-axis. Default is `[None, None]`.\n    -  `moving_average` (`dict`):\n        - `n` (`int`): Number of elements (over the x-axis) over which a moving average should be\n            computed. Default is `1`.\n    - `data_filter` (`dict`):\n        - `every_nth_step` (`int`, `dict`):\n            Either an integer with the number of steps or a dictionary.\n            In case of a dictionary:\n            - `step` (`int`): Number of steps between taken values. Default is `None`.\n            - `include_final_step` (`bool`):\n                Should the final step (the final value) also be included even if outside the stepping.\n                Default is `False`.\n\n    Returns:\n        fig (figure): Plotly figure object that can be displayed using `display(fig)`.\n\n    The plot is based on [Plotly scatter](https://plotly.com/python/line-and-scatter/).\n    \"\"\"\n    default_config = eu.AttrDict(\n\n        # allows to display the moving average per element over n steps\n        moving_average=eu.AttrDict(\n            n=1,\n            mode='fill_start'\n        ),\n\n        data_filter=eu.AttrDict(\n            every_nth_step=eu.AttrDict(\n                step=None,\n                include_final_step=False),\n        ),\n\n        subplots=eu.AttrDict(  # paramters for the 'plotly.subplots.make_subplots' function\n            rows=None,\n            cols=None,\n            print_grid=False\n        ),\n        std=eu.AttrDict(\n            style='shaded',  # or errorbar\n            steps=1,\n            visible=True\n        ),\n        init_mode='mean_std',  # mean_std, mean, elements\n        plotly_format='webgl',  # webgl or svg\n        error_type='std', # std or sem (standard error of the mean)\n        layout=eu.AttrDict(\n\n            default_xaxis=eu.AttrDict(),\n            # if several subplots, then these are the default values for all xaxis config in fig.layout\n            default_yaxis=eu.AttrDict(),\n            # if several subplots, then these are the default values for all yaxis config in fig.layout\n\n            xaxis=eu.AttrDict(),\n            yaxis=eu.AttrDict(),\n\n            updatemenus=[\n                eu.AttrDict(type=\"buttons\",\n                         active=0,\n                         buttons=[\n                             eu.AttrDict(label='mean + std',\n                                      method='restyle',\n                                      args=[{'visible': []}]),\n                             eu.AttrDict(label='mean',\n                                      method='restyle',\n                                      args=[{'visible': []}]),\n                             eu.AttrDict(label='elements',\n                                      method='restyle',\n                                      args=[{'visible': []}]),\n                         ],\n                         direction='right',\n                         pad={'t': 70},\n                         x=1,\n                         xanchor='right',\n                         y=0,\n                         yanchor='top'\n                         ),\n            ]\n        ),\n\n        default_trace=eu.AttrDict(),\n\n        default_mean_trace=eu.AttrDict(\n            legendgroup='&lt;subplot_idx&gt;-&lt;trace_idx&gt;',  # subplot_idx, trace_idx\n            hoverinfo='text+x',\n        ),\n        default_subplot_mean_traces=[],  # default config of traces per subplot\n        mean_traces=[],\n\n        default_std_trace=eu.AttrDict(\n            legendgroup='&lt;mean_trace_legendgroup&gt;',  # subplot_idx, trace_idx, mean_trace_legendgroup\n            hoverinfo='none',\n            showlegend=False,\n        ),\n        default_subplot_std_traces=[],  # default config of traces per subplot\n        std_traces=[],\n\n        default_element_trace=eu.AttrDict(  # overall default\n            legendgroup=None,\n            # subplot_idx, trace_idx, elem_idx, subelem_idx, mean_trace_legendgroup, std_trace_legendgroup\n        ),\n        default_subplot_element_traces=[],  # default per subplot\n        default_data_element_traces=[],  # default per data item\n        element_traces=[],  # individual items\n\n        # label configurations\n\n        labels=[],  # holds all labels in a specific structure\n\n        default_mean_label='&lt;trace_idx&gt;',\n        mean_labels=[],\n\n        default_element_label='&lt;mean_label&gt; - &lt;subelem_idx&gt;',\n        # possible replacements: &lt;mean_label&gt;, &lt;subelem_idx&gt;, &lt;elem_idx&gt;, &lt;trace_idx&gt;\n        element_labels=[],\n\n        default_colors=plotly.colors.DEFAULT_PLOTLY_COLORS,\n    )\n    config = eu.combine_dicts(kwargs, config, default_config)\n\n    if data is None:\n        data = np.array([])\n\n    # format data in form [subplot_idx:list][trace_idx:list][elems_per_trace:numpy.ndarray]\n    if isinstance(data, np.ndarray):\n        data = [[data]]\n    elif isinstance(data, list) and isinstance(data[0], np.ndarray):\n        data = [data]\n    elif not isinstance(data, list) and not isinstance(data[0], list) and not isinstance(data[0][0], np.ndarray):\n        raise ValueError('Unsupported type of data!')\n\n    # handle different input formats of labels\n    if config.labels:\n        # if only labels for mean-traces are given, then add an empty label for the sub figure\n        if isinstance(config.labels, list) and not isinstance(config.labels[0], tuple):\n            config.labels = [('', config.labels)]\n\n        # if no labels are given for elements, then create an empty list for element labels\n        for ds_idx in range(len(config.labels)):\n            for trace_idx in range(len(config.labels[ds_idx][1])):\n                if not isinstance(config.labels[ds_idx][1][trace_idx], tuple):\n                    config.labels[ds_idx][1][trace_idx] = (config.labels[ds_idx][1][trace_idx], [])\n\n    # subplot_titles\n    if config.labels and ('subplot_titles' not in config.subplots or config.subplots.subplot_titles == []):\n        config.subplots.subplot_titles = [subplot_labels[0] for subplot_labels in config.labels]\n\n    # identify the number of subplots\n    n_subplots = len(data)\n\n    # if not defined, set rows and cols of subplots\n    if config.subplots.rows is None and config.subplots.cols is None:\n        config.subplots.rows = n_subplots\n        config.subplots.cols = 1\n    elif config.subplots.rows is not None and config.subplots.cols is None:\n        config.subplots.cols = int(np.ceil(n_subplots / config.subplots.rows))\n    elif config.subplots.rows is None and config.subplots.cols is not None:\n        config.subplots.rows = int(np.ceil(n_subplots / config.subplots.cols))\n\n    if config.plotly_format.lower() == 'webgl':\n        plotly_scatter_plotter = plotly.graph_objs.Scattergl\n    elif config.plotly_format.lower() == 'svg':\n        plotly_scatter_plotter = plotly.graph_objs.Scatter\n    else:\n        raise ValueError('Unknown config {!r} for plotly_format! Allowed values: \\'webgl\\', \\'svg\\'.')\n\n    # make figure with subplots\n    fig = plotly.subplots.make_subplots(**config.subplots)\n\n    mean_traces = []\n    elem_traces = []\n\n    elem_idx = 0\n\n    # interate over subplots\n    for subplot_idx, subplot_data in enumerate(data):\n\n        subplot_mean_traces = []\n        subplot_elem_traces = []\n\n        # iterate over traces\n        for trace_idx, cur_data in enumerate(subplot_data):\n\n            # do not plot data, if it does not exits\n            if cur_data is not None:\n\n                # in case the data is only 1 point, add an extra dimension\n                if np.ndim(cur_data) == 1:\n                    cur_data = np.array([cur_data]).transpose()\n\n                # create a moving average over the data if requested\n                if config.moving_average is not None and config.moving_average.n != 1:\n                    cur_data = eu.misc.moving_average(\n                        cur_data,\n                        config.moving_average.n,\n                        config.moving_average.mode)\n\n                # define standard x_values\n                x_values = list(range(cur_data.shape[1]))\n\n                # filter the data if requested\n                if config.data_filter.every_nth_step is not None:\n\n                    if isinstance(config.data_filter.every_nth_step, dict):\n                        step = config.data_filter.every_nth_step.step\n                        is_include_final_step = config.data_filter.every_nth_step.include_final_step\n                    else:\n                        step = config.data_filter.every_nth_step\n                        is_include_final_step = False\n\n                    # detect if the final step was not in the selection\n                    if is_include_final_step and cur_data.shape[1] % step == 0:\n                        inds = np.zeros(cur_data.shape[1], dtype=bool)\n                        inds[::step] = True\n                        inds[-1] = True\n\n                        cur_data = cur_data[:, inds]\n                        x_values = x_values[::step] + [x_values[-1]]\n                    else:\n                        cur_data = cur_data[:, ::step]\n                        x_values = x_values[::step]\n\n                mean_data = np.nanmean(cur_data, axis=0)\n\n                if config.error_type == 'std':\n                    std_data = np.nanstd(cur_data, axis=0)\n                elif config.error_type == 'sem':\n                    std_data = np.nanstd(cur_data, axis=0, ddof=1) / np.sqrt(np.shape(cur_data)[0])\n                else:\n                    raise ValueError('Unknown error_type!')\n\n                info_text = ['{} \u00b1 {}'.format(mean_data[idx], std_data[idx]) for idx in range(len(mean_data))]\n\n                # define label of the trace\n                if config.labels:\n                    mean_label = config.labels[subplot_idx][1][trace_idx][0]\n                else:\n                    mean_label = config.default_mean_label\n                    if len(config.mean_labels) &gt; trace_idx:\n                        mean_label = config.mean_labels[trace_idx]\n                mean_label = eu.misc.replace_str_from_dict(str(mean_label), {'&lt;trace_idx&gt;': trace_idx})\n\n                mean_trace_params = dict(\n                    x=x_values,\n                    y=mean_data,\n                    line=dict(color=config.default_colors[trace_idx % len(config.default_colors)]),\n                    name=mean_label,\n                    text=info_text,\n                )\n\n                mean_trace_config = eu.combine_dicts(config.default_mean_trace, config.default_trace)\n                if len(config.default_subplot_mean_traces) &gt; subplot_idx:\n                    mean_trace_config = eu.combine_dicts(config.default_subplot_mean_traces[subplot_idx], mean_trace_config)\n                if len(config.mean_traces) &gt; trace_idx:\n                    mean_trace_config = eu.combine_dicts(config.mean_traces[trace_idx], mean_trace_config)\n\n                mean_trace_params = eu.combine_dicts(mean_trace_config, mean_trace_params)\n\n                # handle legendgroup\n                mean_trace_legendgroup = mean_trace_params.legendgroup\n                if isinstance(mean_trace_legendgroup, str):\n                    mean_trace_legendgroup = eu.misc.replace_str_from_dict(mean_trace_legendgroup,\n                                                                           {'&lt;trace_idx&gt;': trace_idx,\n                                                                            '&lt;subplot_idx&gt;': subplot_idx})\n                mean_trace_params.legendgroup = mean_trace_legendgroup\n\n                cur_mean_trace = plotly_scatter_plotter(**mean_trace_params)\n                subplot_mean_traces.append(cur_mean_trace)\n\n                # handle trace for std values\n\n                if config.std.style.lower() == 'shaded':\n\n                    fill_color = config.default_colors[trace_idx % len(config.default_colors)]\n                    fill_color = fill_color.replace('rgb', 'rgba')\n                    fill_color = fill_color.replace(')', ', 0.2)')\n\n                    std_trace_params = dict(\n                        x=x_values + x_values[::-1],\n                        y=np.hstack((mean_data + std_data, mean_data[::-1] - std_data[::-1])),\n                        fill='tozerox',\n                        line=dict(color='rgba(255,255,255,0)'),\n                        fillcolor=fill_color,\n                    )\n\n                elif config.std.style.lower() == 'errorbar':\n\n                    std_trace_params = dict(\n                        x=x_values[::config.std.steps],\n                        y=mean_data[::config.std.steps],\n                        error_y=dict(type='data', array=std_data, visible=True),\n                        mode='markers',\n                        line=dict(color=config.default_colors[trace_idx % len(config.default_colors)]),\n                        marker=dict(size=0, opacity=0),\n                    )\n\n                else:\n                    raise ValueError(\n                        'Unknown config.std.style ({!r})! Options: \\'shaded\\', \\'errorbar\\''.format(config.std.type))\n\n                std_trace_config = eu.combine_dicts(config.default_std_trace, config.default_trace)\n                if len(config.default_subplot_std_traces) &gt; subplot_idx:\n                    std_trace_config = eu.combine_dicts(config.default_subplot_std_traces[subplot_idx], std_trace_config)\n                if len(config.std_traces) &gt; trace_idx:\n                    std_trace_config = eu.combine_dicts(config.std_traces[trace_idx], std_trace_config)\n                std_trace_params = eu.combine_dicts(std_trace_config, std_trace_params)\n\n                # handle legendgroup\n                std_trace_legendgroup = std_trace_params.legendgroup\n                if isinstance(std_trace_legendgroup, str):\n                    std_trace_legendgroup = eu.misc.replace_str_from_dict(std_trace_legendgroup,\n                                                                          {'&lt;trace_idx&gt;': trace_idx,\n                                                                           '&lt;subplot_idx&gt;': subplot_idx,\n                                                                           '&lt;mean_trace_legendgroup&gt;': mean_trace_legendgroup})\n                std_trace_params.legendgroup = std_trace_legendgroup\n\n                cur_std_trace = plotly_scatter_plotter(**std_trace_params)\n                subplot_mean_traces.append(cur_std_trace)\n\n                # traces for each data element\n                n_elems = cur_data.shape[0]\n                color_coeff_step = 1 / n_elems\n                cur_color_coeff = 0 + color_coeff_step\n                for cur_elem_idx in range(n_elems):\n\n                    if config.labels and len(config.labels[subplot_idx][1][trace_idx][1]) &gt; cur_elem_idx:\n                        element_label = config.labels[subplot_idx][1][trace_idx][1][cur_elem_idx]\n                    else:\n                        element_label = config.default_element_label\n                    if len(config.element_labels) &gt; trace_idx:\n                        element_label = config.element_labels[trace_idx]\n                    element_label = eu.misc.replace_str_from_dict(str(element_label),\n                                                                  {'&lt;trace_idx&gt;': trace_idx,\n                                                                   '&lt;subelem_idx&gt;': cur_elem_idx,\n                                                                   '&lt;elem_idx&gt;': elem_idx,\n                                                                   '&lt;mean_label&gt;': mean_label})\n\n                    color = eu.gui.misc.transform_color_str_to_tuple(\n                        config.default_colors[trace_idx % len(config.default_colors)])\n                    color = (color[0],\n                             int(color[1] * cur_color_coeff),\n                             int(color[2] * cur_color_coeff),\n                             int(color[3] * cur_color_coeff))\n                    color = eu.gui.misc.transform_color_tuple_to_str(color)\n                    cur_color_coeff += color_coeff_step\n\n                    element_trace_params = dict(\n                        x=x_values,\n                        y=cur_data[cur_elem_idx, :],\n                        line=dict(color=color),\n                        name=element_label,\n                        visible=True,\n                    )\n\n                    element_trace_config = eu.combine_dicts(config.default_element_trace, config.default_trace)\n                    if len(config.default_subplot_element_traces) &gt; subplot_idx:\n                        element_trace_config = eu.combine_dicts(config.default_subplot_element_traces[subplot_idx],\n                                                                element_trace_config)\n                    if len(config.default_data_element_traces) &gt; cur_elem_idx:\n                        element_trace_config = eu.combine_dicts(config.default_data_element_traces[cur_elem_idx],\n                                                                element_trace_config)\n                    if len(config.element_traces) &gt; elem_idx:\n                        element_trace_config = eu.combine_dicts(config.element_traces[elem_idx], element_trace_config)\n\n                    element_trace_params = eu.combine_dicts(element_trace_config, element_trace_params)\n\n                    # handle legendgroup\n                    element_trace_legendgroup = element_trace_params.legendgroup\n                    if isinstance(element_trace_legendgroup, str):\n                        element_trace_legendgroup = eu.misc.replace_str_from_dict(\n                            element_trace_legendgroup,\n                            {'&lt;subelem_idx&gt;': cur_elem_idx,\n                             '&lt;elem_idx&gt;': elem_idx,\n                             '&lt;trace_idx&gt;': trace_idx,\n                             '&lt;subplot_idx&gt;': subplot_idx,\n                             '&lt;mean_trace_legendgroup&gt;': mean_trace_legendgroup,\n                             '&lt;std_trace_legendgroup&gt;': std_trace_legendgroup})\n                    element_trace_params.legendgroup = element_trace_legendgroup\n\n                    cur_elem_trace = plotly_scatter_plotter(**element_trace_params)\n                    subplot_elem_traces.append(cur_elem_trace)\n\n                    elem_idx += 1\n\n        mean_traces.append(subplot_mean_traces)\n        elem_traces.append(subplot_elem_traces)\n\n    # set for the std toggle buttons which traces should be hidden and which ones should be shown\n    layout = config.layout\n\n    # set default values for all layouts\n    def set_axis_properties_by_default(axis_name, fig_layout, config_layout):\n        # sets the axis properties to default values\n\n        def set_single_axis_property_default(cur_axis_name, default_name):\n            if cur_axis_name in fig_layout or cur_axis_name in config_layout:\n                cur_config = config_layout[cur_axis_name] if cur_axis_name in config_layout else dict()\n                config_layout[cur_axis_name] = eu.combine_dicts(cur_config, config_layout[default_name])\n\n        default_name = 'default_' + axis_name\n\n        set_single_axis_property_default(axis_name, default_name)\n        set_single_axis_property_default(axis_name + '1', default_name)\n        axis_idx = 2\n        while True:\n            cur_axis_name = axis_name + str(axis_idx)\n\n            if cur_axis_name not in fig_layout and cur_axis_name not in config_layout:\n                break\n\n            set_single_axis_property_default(cur_axis_name, default_name)\n            axis_idx += 1\n\n    set_axis_properties_by_default('xaxis', fig['layout'], layout)\n    set_axis_properties_by_default('yaxis', fig['layout'], layout)\n\n    # remove default fields, because they are not true proerties of the plotly layout\n    del (layout['default_xaxis'])\n    del (layout['default_yaxis'])\n\n    update_menus_visible_meanstd = []\n    update_menus_visible_mean = []\n    update_menus_visible_elements = []\n\n    for subplot_idx in range(len(mean_traces)):\n        update_menus_visible_meanstd.extend(\n            [True, True] * int(len(mean_traces[subplot_idx]) / 2) + [False] * int(len(elem_traces[subplot_idx])))\n        update_menus_visible_mean.extend(\n            [True, False] * int(len(mean_traces[subplot_idx]) / 2) + [False] * int(len(elem_traces[subplot_idx])))\n\n        element_default_visibility = [elem_trace['visible'] for elem_trace in elem_traces[subplot_idx]]\n        update_menus_visible_elements.extend(\n            [False, False] * int(len(mean_traces[subplot_idx]) / 2) + element_default_visibility)\n\n    if layout.updatemenus:\n\n        layout.updatemenus[0]['buttons'][0]['args'][0]['visible'] = update_menus_visible_meanstd\n        layout.updatemenus[0]['buttons'][1]['args'][0]['visible'] = update_menus_visible_mean\n        layout.updatemenus[0]['buttons'][2]['args'][0]['visible'] = update_menus_visible_elements\n\n        if config.init_mode == 'mean_std':\n            config.layout.updatemenus[0]['active'] = 0\n        elif config.init_mode == 'mean':\n            config.layout.updatemenus[0]['active'] = 1\n        elif config.init_mode == 'elements':\n            config.layout.updatemenus[0]['active'] = 2\n        else:\n            raise ValueError(\n                'Value {!r} for \\'config.init_mode\\' is not supported! Only \\'mean_std\\',\\'mean\\',\\'elements\\'.'.format(\n                    config.init_mode))\n\n    if config.init_mode == 'mean_std':\n        trace_visibility = update_menus_visible_meanstd\n    elif config.init_mode == 'mean':\n        trace_visibility = update_menus_visible_mean\n    elif config.init_mode == 'elements':\n        trace_visibility = update_menus_visible_elements\n    else:\n        raise ValueError(\n            'Value {!r} for \\'config.init_mode\\' is not supported! Only \\'mean_std\\',\\'mean\\',\\'elements\\'.'.format(\n                config.init_mode))\n\n    cur_row = 1\n    cur_col = 1\n    for subplot_idx in range(n_subplots):\n\n        n_traces = len(mean_traces[subplot_idx]) + len(elem_traces[subplot_idx])\n\n        fig.add_traces(mean_traces[subplot_idx] + elem_traces[subplot_idx],\n                       rows=[cur_row] * n_traces,\n                       cols=[cur_col] * n_traces)\n\n        if cur_col &lt; config.subplots.cols:\n            cur_col += 1\n        else:\n            cur_col = 1\n            cur_row += 1\n\n    for trace_idx in range(len(fig['data'])):\n        fig['data'][trace_idx]['visible'] = trace_visibility[trace_idx]\n\n    fig['layout'].update(layout)\n\n    return fig\n</code></pre>"},{"location":"reference/visualization/#exputils.gui.jupyter.plotly_box.plotly_box","title":"<code>plotly_box</code>","text":"<p>Interactive box plot that shows several statistics such as the mean, std and range of scalars  over all repetitions of each experiment.</p> <p>Parameters:      data (list): Data to plot.      config (dict): Dictionary with configuration of plot.</p> <p>Configuration:</p> <ul> <li><code>layout</code> (<code>dict</code>): See Plotly layout for all possible options.<ul> <li><code>xaxis</code> (<code>dict</code>):<ul> <li><code>title</code> (<code>str</code>): Title of the x-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of x-axis. Default is <code>[None, None]</code>.</li> </ul> </li> <li><code>yaxis</code> (<code>dict</code>)<ul> <li><code>title</code> (<code>str</code>): Title of the y-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of y-axis. Default is <code>[None, None]</code>.</li> </ul> </li> </ul> </li> </ul> <p>Returns:      fig (figure): Plotly figure object that can be displayed using <code>display(fig)</code>.</p> <p>The plot is based on Plotly box plots.</p> Source code in <code>exputils/gui/jupyter/plotly_box.py</code> <pre><code>def plotly_box(data: Optional[list] = None,\n               config: Optional[dict] = None,\n               **kwargs):\n    \"\"\"\n     Interactive box plot that shows several statistics such as the mean, std and range of scalars\n     over all repetitions of each experiment.\n\n    &lt;figure markdown=\"span\"&gt;\n          ![plotly_box](../assets/images/plotly_box.png)\n    &lt;/figure&gt;\n\n     Parameters:\n         data (list): Data to plot.\n         config (dict): Dictionary with configuration of plot.\n\n     __Configuration__:\n\n     - `layout` (`dict`): See [Plotly layout](https://plotly.com/python/reference/layout/) for all possible options.\n         - `xaxis` (`dict`):\n             - `title` (`str`): Title of the x-axis.\n             - `range` (`tuple`): Tuple with min and max values of x-axis. Default is `[None, None]`.\n         - `yaxis` (`dict`)\n             - `title` (`str`): Title of the y-axis.\n             - `range` (`tuple`): Tuple with min and max values of y-axis. Default is `[None, None]`.\n\n     Returns:\n         fig (figure): Plotly figure object that can be displayed using `display(fig)`.\n\n     The plot is based on [Plotly box plots](https://plotly.com/python/box-plots/).\n     \"\"\"\n\n    default_config = eu.AttrDict(\n        subplots=eu.AttrDict(\n            rows=None,\n            cols=None,\n            print_grid=False\n        ),\n        init_mode='mean_std',  # mean_std, mean, elements\n        layout=eu.AttrDict(\n\n            default_xaxis=eu.AttrDict(),  # if several subplots, then these are the default values for all xaxis config in fig.layout\n            default_yaxis=eu.AttrDict(),  # if several subplots, then these are the default values for all yaxis config in fig.layout\n\n            xaxis=eu.AttrDict(),\n            yaxis=eu.AttrDict(),\n\n            boxmode='group',\n\n            updatemenus=[\n                eu.AttrDict(\n                    type=\"buttons\",\n                    active=0,\n                    buttons=[\n                         eu.AttrDict(label='normal',\n                                     method='restyle',\n                                     args=[{'boxpoints': False}]),\n                         eu.AttrDict(label='all',\n                              method='restyle',\n                              args=[{'boxpoints': 'all'}]),\n                         eu.AttrDict(label='suspectedoutliers',\n                              method='restyle',\n                              args=[{'boxpoints': 'suspectedoutliers'}]),\n                         eu.AttrDict(label='outliers',\n                              method='restyle',\n                              args=[{'boxpoints': 'outliers'}]),\n                     ],\n                     direction='right',\n                     pad={'t': 70},\n                     x=1,\n                     xanchor='right',\n                     y=0,\n                     yanchor='top'\n                     ),\n            ]\n        ),\n\n        default_trace=eu.AttrDict(\n            legendgroup=None,\n            boxmean='sd',\n        ),\n        default_subplot_traces=[],\n        traces=[],\n\n        labels=[],  # holds all labels in a specific structure\n\n        default_trace_label='&lt;trace_idx&gt;',\n        trace_labels=[],\n\n        default_group_label='&lt;group_idx&gt;',\n        group_labels=[],\n\n        default_colors=plotly.colors.DEFAULT_PLOTLY_COLORS,\n    )\n    config = eu.combine_dicts(kwargs, config, default_config)\n\n    if data is None:\n        data = np.array([])\n\n    # format data in form [subplot_idx:list][trace_idx:list][elems_per_trace:numpy.ndarray]\n    if isinstance(data, np.ndarray):\n        data = [[data]]\n    elif isinstance(data, list) and isinstance(data[0], np.ndarray):\n        data = [data]\n    elif not isinstance(data, list) and not isinstance(data[0], list) and not isinstance(data[0][0], np.ndarray):\n        raise ValueError('Unsupported type of data!')\n\n    # handle different input formats of labels\n    if config.labels:\n        # if only labels for mean-traces are given, then add an empty label for the sub figure\n        if isinstance(config.labels, list) and not isinstance(config.labels[0], tuple):\n            config.labels = [('', config.labels)]\n        # if no labels are given for elements, then create an empty list for element labels\n        for ds_idx in range(len(config.labels)):\n            for trace_idx in range(len(config.labels[ds_idx][1])):\n                if not isinstance(config.labels[ds_idx][1][trace_idx], tuple):\n                    config.labels[ds_idx][1][trace_idx] = (config.labels[ds_idx][1][trace_idx], [])\n\n    # subplot_titles\n    if config.labels and ('subplot_titles' not in config.subplots or config.subplots.subplot_titles == []):\n        config.subplots.subplot_titles = [subplot_labels[0] for subplot_labels in config.labels]\n\n    # identify the number of subplots\n    n_subplots = len(data)\n\n    # if not defined, set rows and cols of subplots\n    if config.subplots.rows is None and config.subplots.cols is None:\n        config.subplots.rows = n_subplots\n        config.subplots.cols = 1\n    elif config.subplots.rows is not None and config.subplots.cols is None:\n        config.subplots.cols = int(np.ceil(n_subplots / config.subplots.rows))\n    elif config.subplots.rows is None and config.subplots.cols is not None:\n        config.subplots.rows = int(np.ceil(n_subplots / config.subplots.cols))\n\n    # handle init mode\n    if config.init_mode == 'normal':\n        if len(config.layout.updatemenus) &gt; 0:\n            config.layout.updatemenus[0]['active'] = 0\n        config.default_trace.boxpoints = False\n    elif config.init_mode == 'all':\n        if len(config.layout.updatemenus) &gt; 0:\n            config.layout.updatemenus[0]['active'] = 1\n        config.default_trace.boxpoints = 'all'\n    elif config.init_mode == 'suspectedoutliers':\n        if len(config.layout.updatemenus) &gt; 0:\n            config.layout.updatemenus[0]['active'] = 2\n        config.default_trace.boxpoints = 'suspectedoutliers'\n    elif config.init_mode == 'outliers':\n        if len(config.layout.updatemenus) &gt; 0:\n            config.layout.updatemenus[0]['active'] = 3\n        config.default_trace.boxpoints = 'outliers'\n\n    # make figure with subplots\n    fig = plotly.subplots.make_subplots(**config.subplots)\n\n    traces = []\n\n    # interate over subplots\n    for subplot_idx, subplot_data in enumerate(data):\n\n        subplot_traces = []\n\n        # create for each experiment a trace\n        for trace_idx, cur_data in enumerate(subplot_data):\n\n            data_points = np.array([])\n            elem_labels = []\n\n            if np.ndim(cur_data) == 0:\n                data_points = np.array([cur_data])\n                elem_labels = ['']\n            elif np.ndim(cur_data) == 1:\n                data_points = cur_data\n                elem_labels = [''] * len(data_points)\n            else:\n                # collect data over elements\n                for elem_idx, elem_data in enumerate(cur_data):  # data elements\n\n                    # get element data which could be in matrix format or array format\n                    if np.ndim(elem_data) == 0:\n                        cur_elem_data = np.array([elem_data])\n                    elif np.ndim(elem_data) == 1:\n                        cur_elem_data = elem_data\n                    elif np.ndim(elem_data) == 2:\n                        if elem_data.shape[0] == 1:\n                            cur_elem_data = elem_data[0, :]\n                        elif elem_data.shape[1] == 1:\n                            cur_elem_data = elem_data[1, 0]\n                        else:\n                            raise ValueError('Invalid data format!')\n                    else:\n                        raise ValueError('Invalid data format!')\n\n                    data_points = np.hstack((data_points, cur_elem_data))\n\n                    # handle trace for mean values\n                    group_label = config.default_group_label\n                    if len(config.group_labels) &gt; elem_idx:\n                        group_label = config.group_labels[elem_idx]\n                    group_label = eu.misc.replace_str_from_dict(str(group_label), {'&lt;group_idx&gt;': elem_idx})\n\n                    elem_labels.extend([group_label] * len(cur_elem_data))\n\n            # handle trace for mean values\n            if config.labels:\n                trace_label = config.labels[subplot_idx][1][trace_idx][0]\n            else:\n                trace_label = config.default_trace_label\n                if len(config.trace_labels) &gt; trace_idx:\n                    trace_label = config.trace_labels[trace_idx]\n            trace_label = eu.misc.replace_str_from_dict(str(trace_label), {'&lt;trace_idx&gt;': trace_idx})\n\n            trace_params = eu.AttrDict(\n                x=elem_labels,\n                y=data_points,\n                name=trace_label,\n                marker_color=config.default_colors[trace_idx % len(config.default_colors)])\n\n            trace_config = config.default_trace.copy()\n            if len(config.default_subplot_traces) &gt; subplot_idx:\n                trace_config = eu.combine_dicts(config.default_subplot_traces[subplot_idx], trace_config)\n            if len(config.traces) &gt; trace_idx:\n                trace_config = eu.combine_dicts(config.traces[trace_idx], trace_config)\n\n            trace_params = eu.combine_dicts(trace_config, trace_params)\n\n            # handle legendgroup\n            trace_legendgroup = trace_params.legendgroup\n            if isinstance(trace_legendgroup, str):\n                trace_legendgroup = eu.misc.replace_str_from_dict(trace_legendgroup,\n                                                                  {'&lt;trace_idx&gt;': trace_idx,\n                                                                   '&lt;subplot_idx&gt;': subplot_idx})\n            trace_params.legendgroup = trace_legendgroup\n\n            cur_trace = plotly.graph_objs.Box(**trace_params)\n            subplot_traces.append(cur_trace)\n\n        traces.append(subplot_traces)\n\n    # set for the std toggle buttons which traces should be hidden and which ones should be shown\n    layout = config.layout\n\n    # set default values for all layouts\n    def set_axis_properties_by_default(axis_name, fig_layout, config_layout):\n        # sets the axis properties to default values\n\n        def set_single_axis_property_default(cur_axis_name, default_name):\n            if cur_axis_name in fig_layout or cur_axis_name in config_layout:\n                cur_config = config_layout[cur_axis_name] if cur_axis_name in config_layout else dict()\n                config_layout[cur_axis_name] = eu.combine_dicts(cur_config, config_layout[default_name])\n\n        default_name = 'default_' + axis_name\n\n        set_single_axis_property_default(axis_name, default_name)\n        set_single_axis_property_default(axis_name + '1', default_name)\n        axis_idx = 2\n        while True:\n            cur_axis_name = axis_name + str(axis_idx)\n\n            if cur_axis_name not in fig_layout and cur_axis_name not in config_layout:\n                break\n\n            set_single_axis_property_default(cur_axis_name, default_name)\n            axis_idx += 1\n\n    set_axis_properties_by_default('xaxis', fig['layout'], layout)\n    set_axis_properties_by_default('yaxis', fig['layout'], layout)\n\n    # remove default fields, because they are not true proerties of the plotly layout\n    del (layout['default_xaxis'])\n    del (layout['default_yaxis'])\n\n    cur_row = 1\n    cur_col = 1\n    for subplot_idx in range(n_subplots):\n        n_traces = len(traces[subplot_idx])\n\n        fig.add_traces(traces[subplot_idx],\n                       rows=[cur_row] * n_traces,\n                       cols=[cur_col] * n_traces)\n\n        if cur_col &lt; config.subplots.cols:\n            cur_col += 1\n        else:\n            cur_col = 1\n            cur_row += 1\n\n    fig['layout'].update(layout)\n\n    return fig\n</code></pre>"},{"location":"reference/visualization/#exputils.gui.jupyter.plotly_meanstd_bar.plotly_meanstd_bar","title":"<code>plotly_meanstd_bar</code>","text":"<p>Interactive bar plot that shows the mean and std of scalars over all repetitions of each experiment.</p> <p>Parameters:      data (list): Data to plot.      config (dict): Dictionary with configuration of plot.</p> <p>Configuration:</p> <ul> <li><code>layout</code> (<code>dict</code>): See Plotly layout for all possible options.<ul> <li><code>xaxis</code> (<code>dict</code>):<ul> <li><code>title</code> (<code>str</code>): Title of the x-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of x-axis. Default is <code>[None, None]</code>.</li> </ul> </li> <li><code>yaxis</code> (<code>dict</code>)<ul> <li><code>title</code> (<code>str</code>): Title of the y-axis.</li> <li><code>range</code> (<code>tuple</code>): Tuple with min and max values of y-axis. Default is <code>[None, None]</code>.</li> </ul> </li> </ul> </li> </ul> <p>Returns:      fig (figure): Plotly figure object that can be displayed using <code>display(fig)</code>.</p> <p>The plot is based on Plotly bar charts.</p> Source code in <code>exputils/gui/jupyter/plotly_meanstd_bar.py</code> <pre><code>def plotly_meanstd_bar(data: Optional[list] = None,\n                       config: Optional[dict] = None,\n                       **kwargs):\n    \"\"\"\n     Interactive bar plot that shows the mean and std of scalars over all repetitions of each experiment.\n\n    &lt;figure markdown=\"span\"&gt;\n          ![plotly_meanstd_bar](../assets/images/plotly_meanstd_bar.png)\n    &lt;/figure&gt;\n\n     Parameters:\n         data (list): Data to plot.\n         config (dict): Dictionary with configuration of plot.\n\n     __Configuration__:\n\n     - `layout` (`dict`): See [Plotly layout](https://plotly.com/python/reference/layout/) for all possible options.\n         - `xaxis` (`dict`):\n             - `title` (`str`): Title of the x-axis.\n             - `range` (`tuple`): Tuple with min and max values of x-axis. Default is `[None, None]`.\n         - `yaxis` (`dict`)\n             - `title` (`str`): Title of the y-axis.\n             - `range` (`tuple`): Tuple with min and max values of y-axis. Default is `[None, None]`.\n\n     Returns:\n         fig (figure): Plotly figure object that can be displayed using `display(fig)`.\n\n     The plot is based on [Plotly bar charts](https://plotly.com/python/bar-charts/).\n     \"\"\"\n    default_config = eu.AttrDict(\n        subplots=eu.AttrDict(\n            rows=None,\n            cols=None,\n            print_grid=False\n        ),\n        init_mode='mean_std',  # mean_std, mean, elements\n        layout=eu.AttrDict(\n\n            default_xaxis=eu.AttrDict(),  # if several subplots, then these are the default values for all xaxis config in fig.layout\n            default_yaxis=eu.AttrDict(),  # if several subplots, then these are the default values for all yaxis config in fig.layout\n\n            xaxis=eu.AttrDict(),\n            yaxis=eu.AttrDict(),\n\n            boxmode='group',\n\n            updatemenus=[\n                dict(type=\"buttons\",\n                     active=0,\n                     buttons=[\n                         eu.AttrDict(\n                             label='with std',\n                             method='restyle',\n                             args=[{'error_y.visible': True}]),\n                         eu.AttrDict(\n                             label='without std',\n                             method='restyle',\n                             args=[{'error_y.visible': False}]),\n                     ],\n                     direction='right',\n                     pad={'t': 70},\n                     x=1,\n                     xanchor='right',\n                     y=0,\n                     yanchor='top'\n                     ),\n            ]\n        ),\n\n        default_trace=eu.AttrDict(\n            legendgroup=None,\n            error_y=eu.AttrDict(visible=True),\n        ),\n        default_subplot_traces=[],\n        traces=[],\n\n        labels=[],  # holds all labels in a specific structure\n\n        default_trace_label='&lt;trace_idx&gt;',\n        trace_labels=[],\n\n        default_group_label='&lt;group_idx&gt;',\n        group_labels=[],\n\n        default_colors=plotly.colors.DEFAULT_PLOTLY_COLORS,\n    )\n    config = eu.combine_dicts(kwargs, config, default_config)\n\n    default_string_replace_pattern = '&lt;{}&gt;'\n\n    if data is None:\n        data = np.array([])\n\n    # format data in form [subplot_idx:list][trace_idx:list][elems_per_trace:numpy.ndarray]\n    if isinstance(data, np.ndarray):\n        data = [[data]]\n    elif isinstance(data, list) and isinstance(data[0], np.ndarray):\n        data = [data]\n    elif not isinstance(data, list) and not isinstance(data[0], list) and not isinstance(data[0][0], np.ndarray):\n        raise ValueError('Unsupported type of data!')\n\n    # handle different input formats of labels\n    if config.labels:\n        # if only labels for mean-traces are given, then add an empty label for the sub figure\n        if isinstance(config.labels, list) and not isinstance(config.labels[0], tuple):\n            config.labels = [('', config.labels)]\n        # if no labels are given for elements, then create an empty list for element labels\n        for ds_idx in range(len(config.labels)):\n            for trace_idx in range(len(config.labels[ds_idx][1])):\n                if not isinstance(config.labels[ds_idx][1][trace_idx], tuple):\n                    config.labels[ds_idx][1][trace_idx] = (config.labels[ds_idx][1][trace_idx], [])\n\n    # subplot_titles\n    if config.labels and ('subplot_titles' not in config.subplots or config.subplots.subplot_titles == []):\n        config.subplots.subplot_titles = [subplot_labels[0] for subplot_labels in config.labels]\n\n    # identify the number of subplots\n    n_subplots = len(data)\n\n    # if not defined, set rows and cols of subplots\n    if config.subplots.rows is None and config.subplots.cols is None:\n        config.subplots.rows = n_subplots\n        config.subplots.cols = 1\n    elif config.subplots.rows is not None and config.subplots.cols is None:\n        config.subplots.cols = int(np.ceil(n_subplots / config.subplots.rows))\n    elif config.subplots.rows is None and config.subplots.cols is not None:\n        config.subplots.rows = int(np.ceil(n_subplots / config.subplots.cols))\n\n    # handle init mode\n    if config.init_mode == 'mean_std':\n        config.layout.updatemenus[0]['active'] = 0\n        config.default_trace.error_y.visible = True\n    elif config.init_mode == 'mean':\n        config.layout.updatemenus[0]['active'] = 1\n        config.default_trace.error_y.visible = False\n\n    # make figure with subplots\n    fig = plotly.subplots.make_subplots(**config.subplots)\n\n    traces = []\n\n    # interate over subplots\n    for subplot_idx, subplot_data in enumerate(data):\n\n        subplot_traces = []\n\n        # create for each experiment a trace\n        for trace_idx, cur_data in enumerate(subplot_data):  # data source\n\n            means = []\n            stds = []\n            group_labels = []\n\n            if np.ndim(cur_data) == 0 or np.ndim(cur_data) == 1:\n                means.append(np.nanmean(cur_data))\n                stds.append(np.nanstd(cur_data))\n                group_labels.append('')\n            else:\n                # collect data over elements\n                for elem_idx, elem_data in enumerate(cur_data):  # data elements\n\n                    # get element data which could be in matrix format or array format\n                    if np.ndim(elem_data) == 1:\n                        cur_elem_data = elem_data\n                    elif np.ndim(elem_data) == 2:\n                        if elem_data.shape[0] == 1:\n                            cur_elem_data = elem_data[0, :]\n                        elif elem_data.shape[1] == 1:\n                            cur_elem_data = elem_data[1, 0]\n                        else:\n                            raise ValueError('Invalid data format!')\n                    else:\n                        raise ValueError('Invalid data format!')\n\n                    means.append(np.nanmean(cur_elem_data))\n                    stds.append(np.nanstd(cur_elem_data))\n\n                    # handle trace for mean values\n                    group_label = config.default_group_label\n                    if len(config.group_labels) &gt; elem_idx:\n                        group_label = config.group_labels[elem_idx]\n                    group_label = eu.misc.replace_str_from_dict(str(group_label), {'&lt;group_idx&gt;': elem_idx})\n\n                    group_labels.append(group_label)\n\n            # handle trace for mean values\n            if config.labels:\n                trace_label = config.labels[subplot_idx][1][trace_idx][0]\n            else:\n                trace_label = config.default_trace_label\n                if len(config.trace_labels) &gt; trace_idx:\n                    trace_label = config.trace_labels[trace_idx]\n            trace_label = eu.misc.replace_str_from_dict(str(trace_label), {'&lt;trace_idx&gt;': trace_idx})\n\n            trace_params = dict(\n                x=group_labels,\n                y=means,\n                error_y=dict(type='data', array=stds),\n                name=trace_label,\n                marker_color=config.default_colors[trace_idx % len(config.default_colors)])\n\n            trace_config = config.default_trace.copy()\n            if len(config.default_subplot_traces) &gt; subplot_idx:\n                trace_config = eu.combine_dicts(config.default_subplot_traces[subplot_idx], trace_config)\n            if len(config.traces) &gt; trace_idx:\n                trace_config = eu.combine_dicts(config.traces[trace_idx], trace_config)\n\n            trace_params = eu.combine_dicts(trace_config, trace_params)\n\n            # handle legendgroup\n            trace_legendgroup = trace_params.legendgroup\n            if isinstance(trace_legendgroup, str):\n                trace_legendgroup = eu.misc.replace_str_from_dict(\n                    trace_legendgroup,\n                    {'&lt;trace_idx&gt;': trace_idx,\n                     '&lt;subplot_idx&gt;': subplot_idx})\n            trace_params.legendgroup = trace_legendgroup\n\n            cur_trace = plotly.graph_objs.Bar(**trace_params)\n            subplot_traces.append(cur_trace)\n\n        traces.append(subplot_traces)\n\n    # set for the std toggle buttons which traces should be hidden and which ones should be shown\n    layout = config.layout\n\n    # set default values for all layouts\n    def set_axis_properties_by_default(axis_name, fig_layout, config_layout):\n        # sets the axis properties to default values\n\n        def set_single_axis_property_default(cur_axis_name, default_name):\n            if cur_axis_name in fig_layout or cur_axis_name in config_layout:\n                cur_config = config_layout[cur_axis_name] if cur_axis_name in config_layout else dict()\n                config_layout[cur_axis_name] = eu.combine_dicts(cur_config, config_layout[default_name])\n\n        default_name = 'default_' + axis_name\n\n        set_single_axis_property_default(axis_name, default_name)\n        set_single_axis_property_default(axis_name + '1', default_name)\n        axis_idx = 2\n        while True:\n            cur_axis_name = axis_name + str(axis_idx)\n\n            if cur_axis_name not in fig_layout and cur_axis_name not in config_layout:\n                break\n\n            set_single_axis_property_default(cur_axis_name, default_name)\n            axis_idx += 1\n\n    set_axis_properties_by_default('xaxis', fig['layout'], layout)\n    set_axis_properties_by_default('yaxis', fig['layout'], layout)\n\n    # remove default fields, because they are not true proerties of the plotly layout\n    del (layout['default_xaxis'])\n    del (layout['default_yaxis'])\n\n    cur_row = 1\n    cur_col = 1\n    for subplot_idx in range(n_subplots):\n        n_traces = len(traces[subplot_idx])\n\n        fig.add_traces(traces[subplot_idx],\n                       rows=[cur_row] * n_traces,\n                       cols=[cur_col] * n_traces)\n\n        if cur_col &lt; config.subplots.cols:\n            cur_col += 1\n        else:\n            cur_col = 1\n            cur_row += 1\n\n    fig['layout'].update(layout)\n\n    return fig\n</code></pre>"},{"location":"reference/visualization/#exputils.gui.jupyter.tabulate_meanstd.tabulate_meanstd","title":"<code>tabulate_meanstd</code>","text":"<p>Table that shows the mean and std of scalars over all repetitions of each experiment. Can be used to display several datasources.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>Data to plot.</p> <code>None</code> <code>config</code> <code>dict</code> <p>Dictionary with configuration of plot.</p> <code>None</code> <p>Configuration:</p> <ul> <li> <p><code>primary_content_function</code> (<code>function</code>):         Handle to function that computes the first value of a cell.         Function format: <code>func(data: nparray) -&gt; scalar</code>.         Default is <code>numpy.nanmean</code>.</p> </li> <li> <p><code>secondary_content_function</code> (<code>function</code>):         Handle to function that computes the first value of a cell.         Function format: <code>func(data: nparray) -&gt; scalar</code>.         Default is <code>numpy.nanstd</code>.</p> </li> <li> <p><code>tabulate</code> (<code>dict</code>): Parameters for the tabulate function that plots the table.         See tabulate for all possible parameters.         Some important ones:</p> <ul> <li><code>tablefmt</code> (<code>str</code>):     Format of the table such as <code>'html'</code>, <code>'latex'</code>, or <code>'simple'</code>.     Default is <code>'html'</code>.</li> <li> <p><code>numalign</code> (<code>str</code>): Alignment of numbers in the table (<code>'right'</code>, <code>'center'</code>, or <code>'left'</code>).     Default is <code>'right'</code>.</p> </li> <li> <p><code>cell_format</code> (<code>str</code>):     Format of the cell content. The format can take up to 2 numbers which are by default the     mean and the std.     Default is <code>'{:.3f} ({:.3f})'</code>.</p> </li> </ul> </li> <li> <p><code>flip_rows_and_cols</code> (<code>bool</code>): Should the content of rows and columns be flipped.         Default is <code>False</code>.</p> </li> <li> <p><code>top_left_cell_content</code> (<code>str</code>): Content of the top left cell which can be used as a label for the table.         Default is <code>''</code>.</p> </li> </ul> <p>Returns:</p> Name Type Description <code>fig</code> <code>figure</code> <p>Plotly figure object that can be displayed using <code>display(fig)</code>.</p> <p>The plot is based on tabulate.</p> Source code in <code>exputils/gui/jupyter/tabulate_meanstd.py</code> <pre><code>def tabulate_meanstd(data: Optional[list] = None,\n                     config: Optional[dict] = None,\n                     **kwargs):\n    \"\"\"\n    Table that shows the mean and std of scalars over all repetitions of each experiment.\n    Can be used to display several datasources.\n\n    &lt;figure markdown=\"span\"&gt;\n          ![tabulate_meanstd](../assets/images/tabulate_meanstd.png){width=\"500\"}\n    &lt;/figure&gt;\n\n    Parameters:\n        data (list): Data to plot.\n        config (dict): Dictionary with configuration of plot.\n\n    __Configuration__:\n\n    - `primary_content_function` (`function`):\n            Handle to function that computes the first value of a cell.\n            Function format: `func(data: nparray) -&gt; scalar`.\n            Default is [`numpy.nanmean`](https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html).\n\n    - `secondary_content_function` (`function`):\n            Handle to function that computes the first value of a cell.\n            Function format: `func(data: nparray) -&gt; scalar`.\n            Default is [`numpy.nanstd`](https://numpy.org/doc/stable/reference/generated/numpy.nanstd.html).\n\n    - `tabulate` (`dict`): Parameters for the tabulate function that plots the table.\n            See [tabulate](https://pypi.org/project/tabulate/) for all possible parameters.\n            Some important ones:\n        -  `tablefmt` (`str`):\n            Format of the table such as `'html'`, `'latex'`, or `'simple'`.\n            Default is `'html'`.\n        - `numalign` (`str`): Alignment of numbers in the table (`'right'`, `'center'`, or `'left'`).\n            Default is `'right'`.\n\n        - `cell_format` (`str`):\n            Format of the cell content. The format can take up to 2 numbers which are by default the\n            mean and the std.\n            Default is `'{:.3f} ({:.3f})'`.\n\n    - `flip_rows_and_cols` (`bool`): Should the content of rows and columns be flipped.\n            Default is `False`.\n\n    - `top_left_cell_content` (`str`): Content of the top left cell which can be used as a label for the table.\n            Default is `''`.\n\n    Returns:\n        fig (figure): Plotly figure object that can be displayed using `display(fig)`.\n\n    The plot is based on [tabulate](https://pypi.org/project/tabulate/).\n    \"\"\"\n\n    default_config = eu.AttrDict(\n\n        primary_content_function = np.nanmean,\n\n        secondary_content_function = np.nanstd,\n\n        flip_rows_and_cols = False,\n\n        tabulate=eu.AttrDict(\n            tablefmt='html', #\n            numalign='right',\n        ),\n\n        cell_format = '{:.3f} ({:.3f})',\n\n        top_left_cell_content = '',\n\n        default_row_label = '&lt;row_idx&gt;',\n        default_column_label = '&lt;column_idx&gt;',\n\n        labels=[],  # holds all labels in a specific structure\n\n    )\n    config = eu.combine_dicts(kwargs, config, default_config)\n\n    # remove the secondary information from the cell_format if the secondary information is set to None and the cell_format was not changed\n    if config.secondary_content_function is None and config.cell_format == default_config.cell_format:\n        config.cell_format = '{}'\n\n    if data is None:\n        data = np.array([])\n\n    # format data in form [rows][columns][elems_per_trace:numpy.ndarray]\n    # subplot is a single table\n    if isinstance(data, np.ndarray):\n        data = [[data]]\n    elif isinstance(data, list) and isinstance(data[0], np.ndarray):\n        data = [data]\n    elif not isinstance(data, list) and not isinstance(data[0], list) and not isinstance(data[0][0], np.ndarray):\n        raise ValueError('Unsupported type of data!')\n\n    # handle different input formats of labels\n    if config.labels:\n        # if only labels for columns are given, then add an empty label for the sub figure\n        if isinstance(config.labels, list) and not isinstance(config.labels[0], tuple):\n            config.labels = [('', config.labels)]\n\n    row_headers = []\n    column_headers = []\n\n    primary_data = []\n    secondary_data = []\n\n    # interate over rows (subplots)\n    for row_idx, row_data in enumerate(data):\n\n        primary_data.append([])\n        secondary_data.append([])\n\n        # define label of the row\n        if config.labels:\n            row_label = config.labels[row_idx][0]\n        else:\n            row_label = config.default_row_label\n        row_label = eu.misc.replace_str_from_dict(str(row_label), {'&lt;row_idx&gt;': row_idx})\n        row_headers.append(row_label)\n\n        # collect the data and labels for each trace\n        for column_idx, cur_data in enumerate(row_data):\n\n            # get column_header from labels of first column\n            if row_idx == 0:\n\n                # define label of the row\n                if config.labels:\n                    column_label = config.labels[row_idx][1][column_idx]\n                    if isinstance(column_label, tuple):\n                        column_label = column_label[0]\n                else:\n                    column_label = config.default_column_label\n                column_label = eu.misc.replace_str_from_dict(str(column_label), {'&lt;column_idx&gt;': column_idx})\n                column_headers.append(column_label)\n\n            data_points = np.array([])\n\n            if np.ndim(cur_data) == 0:\n                data_points = np.array([cur_data])\n            elif np.ndim(cur_data) == 1:\n                data_points = cur_data\n            else:\n                # collect data over elements\n                for elem_idx, elem_data in enumerate(cur_data):  # data elements\n\n                    # get element data which could be in matrix format or array format\n                    if np.ndim(elem_data) == 0:\n                        cur_elem_data = np.array([elem_data])\n                    elif np.ndim(elem_data) == 1:\n                        cur_elem_data = elem_data\n                    elif np.ndim(elem_data) == 2:\n                        if elem_data.shape[0] == 1:\n                            cur_elem_data = elem_data[0, :]\n                        elif elem_data.shape[1] == 1:\n                            cur_elem_data = elem_data[1, 0]\n                        else:\n                            raise ValueError('Invalid data format!')\n                    else:\n                        raise ValueError('Invalid data format!')\n\n                    data_points = np.hstack((data_points, cur_elem_data))\n\n            # try:\n            if data_points[0] is not None:\n                primary_data[row_idx].append(config.primary_content_function(data_points))\n\n                if config.secondary_content_function:\n                    secondary_data[row_idx].append(config.secondary_content_function(data_points))\n                else:\n                    secondary_data[row_idx].append(None)\n            else:\n                primary_data[row_idx].append(None)\n                secondary_data[row_idx].append(None)\n\n\n\n    # plot the results\n    n_rows = len(primary_data)\n    n_columns = len(primary_data[0])\n    if config.flip_rows_and_cols:\n        n_rows = len(primary_data[0])\n        n_columns = len(primary_data)\n        tmp = row_headers\n        row_headers = column_headers\n        column_headers = tmp\n\n    table_content = [[None] * (n_columns + 1) for _ in range(n_rows + 1)]\n    table_content[0][0] = config.top_left_cell_content\n\n\n    # set row and column headers\n    for row_idx in range(n_rows):\n        table_content[row_idx + 1][0] = row_headers[row_idx]\n    for column_idx in range(n_columns):\n        table_content[0][column_idx + 1] = column_headers[column_idx]\n\n    # fill table\n    for row_idx in range(n_rows):\n        for column_idx in range(n_columns):\n\n            data_1_idx = row_idx\n            data_2_idx = column_idx\n            if config.flip_rows_and_cols:\n                data_1_idx = column_idx\n                data_2_idx = row_idx\n\n            if primary_data[data_1_idx][data_2_idx] is None:\n                cell_data = ''\n            else:\n                if isinstance(config.cell_format, str):\n                    cell_data = config.cell_format.format(\n                        primary_data[data_1_idx][data_2_idx],\n                        secondary_data[data_1_idx][data_2_idx])\n                else:\n                    cell_data = eu.misc.call_function_from_config(\n                        config.cell_format,\n                        primary_data[data_1_idx][data_2_idx],\n                        secondary_data[data_1_idx][data_2_idx])\n\n            table_content[row_idx + 1][column_idx + 1] = cell_data\n\n    table = original_tabulate(\n        table_content,\n        headers='firstrow',\n        **config.tabulate)\n\n    return table\n</code></pre>"},{"location":"reference/visualization/#exputils.gui.jupyter.tabulate_pairwise.tabulate_pairwise","title":"<code>tabulate_pairwise</code>","text":"<p>Plots a pairwise comparison between data from experiments based on a pairwise function d = f(exp_a, exp_b). By default it performs a Mann-WhitneyU P-Value test to identify significant differences between experiments.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list</code> <p>Data to plot.</p> <code>None</code> <code>config</code> <code>dict</code> <p>Dictionary with configuration of plot.</p> <code>None</code> <p>Configuration:</p> <ul> <li> <p><code>pairwise_function</code> (<code>function</code>):         Handle to function that computes the difference between the data of two experiments.         Function format: <code>func(exp1_data: nparray, exp2_data: nparray) -&gt; scalar</code>.         Default is <code>eu.misc.mannwhitneyu_pvalue</code>.</p> </li> <li> <p><code>pairwise_mode</code> (<code>str</code>):         Which pairs of experiments are compared?         Possible values are <code>'full'</code>, <code>'full_not_identity'</code>, <code>'upper_triangle'</code>, <code>'upper_triangle_not_identiy'</code>, <code>'lower_triangle'</code>, <code>'lower_triangle_not_identiy'</code>.         Default is <code>'full'</code>.</p> </li> <li> <p><code>tabulate</code> (<code>dict</code>): Parameters for the tabulate function that plots the table.         See tabulate for all possible parameters.         Some important ones:</p> <ul> <li><code>tablefmt</code> (<code>str</code>):     Format of the table such as <code>'html'</code>, <code>'latex'</code>, or <code>'simple'</code>.     Default is <code>'html'</code>.</li> <li> <p><code>numalign</code> (<code>str</code>): Alignment of numbers in the table (<code>'right'</code>, <code>'center'</code>, or <code>'left'</code>).     Default is <code>'right'</code>.</p> </li> <li> <p><code>cell_format</code> (<code>str</code>):     Format of the cell content. The format can take 1 number.     Default is <code>'{}'</code>.</p> </li> </ul> </li> <li> <p><code>top_left_cell_content</code> (<code>str</code>): Content of the top left cell which can be used as a label for the table.         Default is <code>''</code>.</p> </li> </ul> <p>Returns:</p> Name Type Description <code>fig</code> <code>figure</code> <p>Plotly figure object that can be displayed using <code>display(fig)</code>.</p> <p>The plot is based on tabulate.</p> Source code in <code>exputils/gui/jupyter/tabulate_pairwise.py</code> <pre><code>def tabulate_pairwise(data: Optional[list] = None,\n                     config: Optional[dict] = None,\n                     **kwargs):\n    \"\"\"\n    Plots a pairwise comparison between data from experiments based on a pairwise function d = f(exp_a, exp_b).\n    By default it performs a Mann-WhitneyU P-Value test to identify significant differences between experiments.\n\n    &lt;figure markdown=\"span\"&gt;\n          ![tabulate_pairwise](../assets/images/tabulate_pairwise.png){width=\"550\"}\n    &lt;/figure&gt;\n\n    Parameters:\n        data (list): Data to plot.\n        config (dict): Dictionary with configuration of plot.\n\n    __Configuration__:\n\n    - `pairwise_function` (`function`):\n            Handle to function that computes the difference between the data of two experiments.\n            Function format: `func(exp1_data: nparray, exp2_data: nparray) -&gt; scalar`.\n            Default is `eu.misc.mannwhitneyu_pvalue`.\n\n    - `pairwise_mode` (`str`):\n            Which pairs of experiments are compared?\n            Possible values are `'full'`, `'full_not_identity'`, `'upper_triangle'`, `'upper_triangle_not_identiy'`, `'lower_triangle'`, `'lower_triangle_not_identiy'`.\n            Default is `'full'`.\n\n    - `tabulate` (`dict`): Parameters for the tabulate function that plots the table.\n            See [tabulate](https://pypi.org/project/tabulate/) for all possible parameters.\n            Some important ones:\n        -  `tablefmt` (`str`):\n            Format of the table such as `'html'`, `'latex'`, or `'simple'`.\n            Default is `'html'`.\n        - `numalign` (`str`): Alignment of numbers in the table (`'right'`, `'center'`, or `'left'`).\n            Default is `'right'`.\n\n        - `cell_format` (`str`):\n            Format of the cell content. The format can take 1 number.\n            Default is `'{}'`.\n\n    - `top_left_cell_content` (`str`): Content of the top left cell which can be used as a label for the table.\n            Default is `''`.\n\n    Returns:\n        fig (figure): Plotly figure object that can be displayed using `display(fig)`.\n\n    The plot is based on [tabulate](https://pypi.org/project/tabulate/).\n    \"\"\"\n\n    default_config = eu.AttrDict(\n\n        pairwise_function = eu.misc.mannwhitneyu_pvalue,\n\n        pairwise_mode = 'full',    # which pairs are compared? 'full', 'full_not_identity', 'upper_triangle', 'upper_triangle_not_identiy', 'lower_triangle', 'lower_triangle_not_identiy'\n\n        tabulate=eu.AttrDict(\n            tablefmt='html', #\n            numalign='right',\n        ),\n\n        cell_format = '{}',\n\n        top_left_cell_content = '',\n\n        labels=[],  # holds all labels in a specific structure\n\n    )\n    config = eu.combine_dicts(kwargs, config, default_config)\n\n    allowed_pairwise_modes = ['full', 'full_not_identity', 'upper_triangle', 'upper_triangle_not_identity', 'lower_triangle', 'lower_triangle_not_identity']\n    if config.pairwise_mode not in allowed_pairwise_modes:\n        raise ValueError('Unknown configuration {!r} for pairwise_mode! Allowed values: {}'.format(config.pairwise_mode, allowed_pairwise_modes))\n\n    if data is None:\n        data = np.array([])\n\n    # format data in form [subplot_idx:list][trace_idx:list][elems_per_trace:numpy.ndarray]\n    # subplot is a single table\n    if isinstance(data, np.ndarray):\n        data = [[data]]\n    elif isinstance(data, list) and isinstance(data[0], np.ndarray):\n        data = [data]\n    elif not isinstance(data, list) and not isinstance(data[0], list) and not isinstance(data[0][0], np.ndarray):\n        raise ValueError('Unsupported type of data!')\n\n    # handle different input formats of labels\n    if config.labels:\n        # if only labels for mean-traces are given, then add an empty label for the sub figure\n        if isinstance(config.labels, list) and not isinstance(config.labels[0], tuple):\n            config.labels = [('', config.labels)]\n        # if no labels are given for elements, then create an empty list for element labels\n        for ds_idx in range(len(config.labels)):\n            for trace_idx in range(len(config.labels[ds_idx][1])):\n                if not isinstance(config.labels[ds_idx][1][trace_idx], tuple):\n                    config.labels[ds_idx][1][trace_idx] = (config.labels[ds_idx][1][trace_idx], [])\n\n    # identify the number of subplots\n    n_subplots = len(data)\n\n    if n_subplots &gt; 1:\n        raise NotImplementedError('Only supports 1 subplot!')\n\n    # interate over subplots\n    for subplot_idx, subplot_data in enumerate(data):\n\n        trace_labels = []\n        data_per_trace = []\n\n        # collect the data and labels for each trace\n        for trace_idx, cur_data in enumerate(subplot_data):\n\n            # handle trace for mean values\n            if config.labels:\n                trace_label = config.labels[subplot_idx][1][trace_idx][0]\n            else:\n                trace_label = config.default_trace_label\n                if len(config.trace_labels) &gt; trace_idx:\n                    trace_label = config.trace_labels[trace_idx]\n            trace_label = eu.misc.replace_str_from_dict(str(trace_label), {'&lt;trace_idx&gt;': trace_idx})\n            trace_labels.append(trace_label)\n\n            data_points = np.array([])\n\n            if np.ndim(cur_data) == 0:\n                data_points = np.array([cur_data])\n            elif np.ndim(cur_data) == 1:\n                data_points = cur_data\n            else:\n                # collect data over elements\n                for elem_idx, elem_data in enumerate(cur_data):  # data elements\n\n                    # get element data which could be in matrix format or array format\n                    if np.ndim(elem_data) == 0:\n                        cur_elem_data = np.array([elem_data])\n                    elif np.ndim(elem_data) == 1:\n                        cur_elem_data = elem_data\n                    elif np.ndim(elem_data) == 2:\n                        if elem_data.shape[0] == 1:\n                            cur_elem_data = elem_data[0, :]\n                        elif elem_data.shape[1] == 1:\n                            cur_elem_data = elem_data[1, 0]\n                        else:\n                            raise ValueError('Invalid data format!')\n                    else:\n                        raise ValueError('Invalid data format!')\n\n                    data_points = np.hstack((data_points, cur_elem_data))\n\n            data_per_trace.append(data_points)\n\n\n        n_traces = len(data_per_trace)\n\n        # compute the pairwise function of all needed combinations\n        pairwise_data = np.full((n_traces,n_traces), np.nan)\n        for first_trace_idx in range(n_traces):\n            for second_trace_idx in range(n_traces):\n                # decide if data has to be compared based on the config.pairwise_mode\n                if _is_needed_pairwise_combination(first_trace_idx, second_trace_idx, config.pairwise_mode):\n                    pairwise_data[first_trace_idx, second_trace_idx] = eu.misc.call_function_from_config(\n                        config.pairwise_function,\n                        data_per_trace[first_trace_idx],\n                        data_per_trace[second_trace_idx],\n                    )\n\n        # plot the results\n        row_shift = 1\n        col_shift = 1\n        n_rows_and_cols = n_traces + 1\n        # we leave some header out for these two cases\n        if config.pairwise_mode == 'upper_triangle_not_identity':\n            col_shift = 0\n            n_rows_and_cols = n_traces\n        elif config.pairwise_mode == 'lower_triangle_not_identity':\n            row_shift = 0\n            n_rows_and_cols = n_traces\n\n        table_content = [[None] * (n_rows_and_cols) for _ in range(n_rows_and_cols)]\n\n        table_content[0][0] = config.top_left_cell_content\n\n        # set top and side header\n        for trace_idx in range(n_traces):\n            if config.pairwise_mode == 'upper_triangle_not_identity':\n                # top header\n                if trace_idx &gt; 0:\n                    table_content[0][trace_idx + col_shift] = trace_labels[trace_idx]\n                # side header\n                if trace_idx &lt; n_traces - 1:\n                    table_content[trace_idx + row_shift][0] = trace_labels[trace_idx]\n\n            elif config.pairwise_mode == 'lower_triangle_not_identity':\n                # top header\n                if trace_idx &lt; n_traces - 1:\n                    table_content[0][trace_idx + col_shift] = trace_labels[trace_idx]\n                # side header\n                if trace_idx &gt; 0:\n                    table_content[trace_idx + row_shift][0] = trace_labels[trace_idx]\n\n            else:\n                # top header\n                table_content[0][trace_idx + col_shift] = trace_labels[trace_idx]\n                # side header\n                table_content[trace_idx + row_shift][0] = trace_labels[trace_idx]\n\n        # fill table\n        for first_trace_idx in range(n_traces):\n            for second_trace_idx in range(n_traces):\n                if _is_needed_pairwise_combination(first_trace_idx, second_trace_idx, config.pairwise_mode):\n\n                    if isinstance(config.cell_format, str):\n                        cell_data = config.cell_format.format(pairwise_data[first_trace_idx, second_trace_idx])\n                    else:\n                        cell_data = eu.misc.call_function_from_config(\n                            config.cell_format,\n                            pairwise_data[first_trace_idx, second_trace_idx])\n\n                    table_content[first_trace_idx + row_shift][second_trace_idx + col_shift] = cell_data\n\n        table = original_tabulate(\n            table_content,\n            headers='firstrow',\n            **config.tabulate)\n\n        return table\n</code></pre>"}]}